<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>DANL 200 Lecture 22</title>
    <meta charset="utf-8" />
    <meta name="author" content="Byeong-Hak Choe" />
    <meta name="date" content="2023-04-27" />
    <script src="libs/header-attrs-2.20/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <link href="libs/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.2.6/panelset.js"></script>
    <script src="libs/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <script src="libs/xaringanExtra-webcam-0.0.1/webcam.js"></script>
    <script id="xaringanExtra-webcam-options" type="application/json">{"width":"200","height":"200","margin":"1em"}</script>
    <script src="libs/js-cookie-3.0.0/js.cookie.js"></script>
    <script src="libs/peerjs-1.3.1/peerjs.min.js"></script>
    <script src="libs/tiny.toast-1.0.0/toast.min.js"></script>
    <link href="libs/xaringanExtra-broadcast-0.2.6/broadcast.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-broadcast-0.2.6/broadcast.js"></script>
    <link href="libs/shareon-1.4.1/shareon.min.css" rel="stylesheet" />
    <script src="libs/shareon-1.4.1/shareon.min.js"></script>
    <link href="libs/xaringanExtra-shareagain-0.2.6/shareagain.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-shareagain-0.2.6/shareagain.js"></script>
    <link href="libs/xaringanExtra-extra-styles-0.2.6/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/nhsr.css" type="text/css" />
    <link rel="stylesheet" href="css/nhsr-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




class: title-slide, left, bottom

# DANL 200 Lecture 22
----
## **DANL 200: Introduction to Data Analytics**
### Byeong-Hak Choe
### April 27, 2023



---
class: inverse, center, middle

# Linear Regression Model with Multiple Explanatory Variables
&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=796px&gt;&lt;/html&gt;


---
# Multivariate Regression
### &lt;p style="color:#00449E"&gt;

- What if the regression were missing something? 
  - Maybe prices are not just about size, but maybe there are certain parts of NYC that are categorically more expensive than other parts of NYC. 
  - Maybe Manhattan is just more expensive than Bronx. 
  - Maybe apartments are different than non-apartments.
  - Maybe old houses are different than new houses.


- It is often helpful to bring in multiple explanatory variables—a **Multivariate Regression**.



---
# Multivariate Regression 
### &lt;p style="color:#00449E"&gt; Models and Assumptions

.panelset[
.panel[.panel-name[multiple regression]
- Linear regression assumes a __linear relationship__ for `\(Y = f(X_{1}, X_{2})\)`:

`$$Y_{i} \,=\, \beta_{0} \,+\, \beta_{1} X_{1, i} \,+\,\beta_{2} X_{2, i} \,+\, \epsilon_{i}$$`
for `\(i \,=\, 1, 2, \dots, n\)`, where `\(i\)` is the `\(i\)`-th observation in data.


- `\(\beta_0\)` is an unknown __true__ value of an __intercept__: average value for `\(Y\)` if `\(X_{1} = 0\)` and `\(X_{2} = 0\)`

- `\(\beta_1\)` is an unknown __true__ value of a __slope__: increase in average value for `\(Y\)` for each one-unit increase in `\(X_{1}\)`

- `\(\beta_2\)` is an unknown __true__ value of a __slope__: increase in average value for `\(Y\)` for each one-unit increase in `\(X_{2}\)`

]


.panel[.panel-name[random noise]
- Linear regression assumes a __linear relationship__ for `\(Y = f(X_{1})\)`:

`$$Y_{i} \,=\, \beta_{0} \,+\, \beta_{1} X_{1, i} \,+\, \epsilon_{i}$$`
for `\(i \,=\, 1, 2, \dots, n\)`, where `\(i\)` is the `\(i\)`-th observation in data.



- `\(\epsilon_i\)` is a random noise, or a statistical error:

$$
\epsilon_i \sim N(0, \sigma^2) 
$$
  
  - Errors have a mean value of 0 with constant variance `\(\sigma^2\)`.
  - Errors are *uncorrelated* with `\(X_{1, i}\)` and with `\(X_{2, i}\)`.

]

.panel[.panel-name[best fitting plane]
- Linear regression finds the beta estimates `\(( \hat{\beta}_{0}, \hat{\beta}_{1}, \hat{\beta}_{2} )\)` such that:

  – The linear function `\(f(X_{1}, X_{2}) = \hat{\beta}_{0} + \hat{\beta}_{1}X_{1} + \hat{\beta}_{2}X_{2}\)` is as near as possible to `\(Y\)` for all `\((X_{1, i}\,,\,X_{2, i}\,,\, Y_{i})\)` pairs in the data.
  
  - It is the **best fitting** plane, or the **predicted outcome**, `\(\hat{Y} = \hat{\beta}_{0} + \hat{\beta}_{1}X_{1} + \hat{\beta}_{2}X_{2}\)`
  

]

.panel[.panel-name[residual errors]
- The estimated beta coefficients are chosen to minimize the sum of squares of the **residual errors** `\((SSR)\)`:

  - `\(SSR = (\texttt{Residual_Error}_{1})^{2} \,+\, (\texttt{Residual_Error}_{2})^{2} \,+\, \cdots + (\texttt{Residual_Error}_{n})^{2}\)`
  
  - `\(\texttt{Residual_Error}_{i} \,=\, Y_{i} \,-\, \hat{Y}_{i}\)`.
  
  - `\(\texttt{Predicted_Outcome}_{i}\)`: `\(\hat{Y}_{i} \,=\, \hat{\beta}_{0} \,+\, \hat{\beta}_{1}X_{1, i} \,+\, \hat{\beta}_{2}X_{2, i}\)`

]

]


---
# Multivariate Regression using R
### &lt;p style="color:#00449E"&gt; Splitting Data into Training and Testing Data


.panelset[

.panel[.panel-name[Step 1. set.seed()]

```r
# Importing the cleaned small sample of data
sale_df &lt;- read_csv("https://bcdanl.github.io/data/home_sales_nyc.csv")

# Making the random sampling reproducible by setting the random seed.
set.seed(123) # 123 is just any number.
# The set.seed() function sets the starting number 
# used to generate a sequence of random numbers.

# With set.seed(), we can replicate the random number generation:
# If we start with that same seed number in the set.seed() each time, 
# we run the same random process, 
# so that we can replicate the same random numbers.
```

]

.panel[.panel-name[Step 2. runif()]

```r
# How many random numbers do we need?
gp &lt;- runif(nrow(sale_df)) 
# a number generation from a random variable that follows Unif(0,1)

# Splits 50-50 into training and test sets 
# using filter() and gp

# sale_df$gp &lt;- gp
dtrain &lt;- filter(sale_df, gp &gt;= .5) 
dtest &lt;- filter(sale_df,  gp &lt; .5)
# A vector can be used for CONDITION in the filter(data.frame, CONDITION) 
# if the length of the vector is the same as that of the data.frame.
```
]

]


---
# Multivariate Regression using R
### &lt;p style="color:#00449E"&gt; 


- We can have more than two explanatory variables `\((\,X_{1}, X_{2}, X_{3}, \cdots\,)\)` in the linear regression model.



```r
model &lt;- lm(formula = sale.price ~ gross.square.feet + age + borough_name, 
            data = dtrain)
dtest$pred &lt;-  predict(model, 
                       newdata = dtest)
summary(model)   
```

- What happened?


---
# Multivariate Regression using R
### &lt;p style="color:#00449E"&gt; Dummy variables

.panelset[
.panel[.panel-name[(1)]
- `lm()` function handles a categorical variable with `m` possible levels by converting it to `m-1` dummy variables, and the rest `1` category, the first level of the categorical variable, becomes a reference level.
  - The value of a dummy variable is either 0 or 1.

- E.g., the dummy variable, `borough_nameBrooklyn`, is follows: 

$$
\texttt{borough_nameBrooklyn[i] }\\
= \begin{cases}
\texttt{1} &amp; \text{if a property } \texttt{i} \text{ is in } \texttt{Brooklyn};\\\\
\texttt{0} &amp; \text{otherwise}.\qquad\qquad\quad\,
\end{cases}
$$

]

.panel[.panel-name[(2)]

- Using the `model.matrix()` function on our linear model object, we can get the data matrix of explanatory variables.
  - Since `model.matrix()` returns matrix, we can convert it to data.frame using `as.data.frame()`:


```r
X &lt;- as.data.frame( model.matrix(model_3) )
```

]


.panel[.panel-name[(3)]
The model equation is 
`$$\begin{align}
\texttt{sale.price[i]} \;=\;\, &amp;\texttt{b0} \,+\,\\ &amp;\texttt{b1*gross.square.feet[i]} \,+\,\texttt{b2*age[i]} \,+\,\\&amp;\texttt{b3*Brooklyn[i]}\,+\,\texttt{b4*Manhattan[i]} \,+\,\\&amp;\texttt{b5*Queens[i]} \,+\,\texttt{b6*Staten Island[i]}\,+\,\\ &amp;\texttt{e[i]}
\end{align}$$`

]

.panel[.panel-name[(4)]


- The model does not include `borough_nameBronx`, because `\(\texttt{borough_nameBronx[i]}\)` is represented by a combination of `\(\texttt{borough}\)` variables:

  - `\(\texttt{borough_nameBronx[i]} = 0\)` if any of the `\(\texttt{borough_name}\)` variables is 1.
  
  - `\(\texttt{borough_nameBronx[i]} = 1\)` if all of the `\(\texttt{borough_name}\)` variables are 0.
  
  
  
- The level `Bronx` is a reference level when interpreting the beta estimate for the `borough_name` variables.

]

]


---
# Multivariate Regression using **R**
### &lt;p style="color:#00449E"&gt; Setting a reference level


.panelset[
.panel[.panel-name[(1)]
- If a linear regression model includes a **categorical** variable (`factor` or `character` variable), we can consider setting a reference level of a `factor` variable using `relevel(VARIABLE, ref = "LEVEL")`.


```r
dtrain &lt;- dtrain %&gt;% 
  mutate(borough_name = factor(borough_name), # borough_name is given as character type.
         borough_name = relevel(borough_name,
                                "Manhattan") )
model_2 &lt;- lm(sale.price ~ gross.square.feet + age + borough_name, 
              data = dtrain)
summary(model_2)   
```

- The level `Manhattan` now becomes a reference level.
  - Accordingly, the interpretation of beta estimates for `borough_name` variables change.

]

.panel[.panel-name[(2)]
- Changing a reference level of a factor variable does not change the regression result.

```r
dtest$pred_2 &lt;-  predict(model, newdata = dtest)
```

- Compare `pred` with `pred_2`.

]

]



---
## Interpreting the output of `summary()`
### &lt;p style="color:#00449E"&gt; Estimated Beta Coefficients

.panelset[
.panel[.panel-name[model]
The model equation is now then
`$$\begin{align}
\texttt{sale.price[i]} \;=\;\, &amp;\texttt{b0} \,+\,\\ &amp;\texttt{b1*gross.square.feet[i]} \,+\,\texttt{b2*age[i]}\,+\,\\ &amp;\texttt{b3*Bronx[i]} \,+\,\texttt{b4*Brooklyn[i]} \,+\,\\&amp;\texttt{b5*Queens[i]} \,+\,\texttt{b6*Staten Island[i]}\,+\,\\ &amp;\texttt{e[i]}
\end{align}$$`
- The reference level of `borough_name` variables is `Manhattan`.
]

.panel[.panel-name[`gross.square.feet`]

- All else being equal, an increase in `gross.square.feet` by one unit is associated with an increase in `sale.price` by `b1`.


]

.panel[.panel-name[`borough_nameBronx`]

- All else being equal, an increase in `borough_nameBronx` by one unit is associated with an increase in `sale.price` by `b3`.

- All else being equal, being in `Bronx` relative to being a in `Manhattan` is associated with a decrease in `sale.price` by `|b3|`.

]

]


---
# Interpreting Estimated Beta Coefficients
### &lt;p style="color:#00449E"&gt; 
Consider the predicted sales prices of the two houses, `A` and `B`.
  - Both `A` and `B`'s `age` are the same. 
  - Both `A` and `B` are in `Bronx`. 
  - Both `A` and `B`'s `gross.square.feet` are 2001 and 2000 respectively.



`$$\begin{align}\widehat{\texttt{sale.price[A]}} \;=\quad&amp; \hat{\texttt{b0}} \,+\, \hat{\texttt{b1}}\texttt{*gross.square.feet[A]} \,+\, \hat{\texttt{b2}}\texttt{*age[A]} \,+\, \hat{\texttt{b3}}\texttt{*Bronx[A]}\,+\,\\
&amp;\hat{\texttt{b4}}\texttt{*Brooklyn[A]} \,+\, \hat{\texttt{b5}}\texttt{*Queens[A]}\,+\, \hat{\texttt{b6}}\texttt{*Staten Island[A]}\\
\widehat{\texttt{sale.price[B]}} \;=\quad&amp; \hat{\texttt{b0}} \,+\, \hat{\texttt{b1}}\texttt{*gross.square.feet[B]} \,+\, \hat{\texttt{b2}}\texttt{*age[B]}\,+\,\hat{\texttt{b3}}\texttt{*Bronx[B]}\,+\,\\
&amp;\hat{\texttt{b4}}\texttt{*Brooklyn[B]} \,+\, \hat{\texttt{b5}}\texttt{*Queens[B]}\,+\, \hat{\texttt{b6}}\texttt{*Staten Island[B]} \end{align}$$`

`$$\begin{align}\Leftrightarrow\qquad&amp;\widehat{\texttt{sale.price[A]}} \,-\, \widehat{\texttt{sale.price[B]}}\qquad  \\
\;=\quad &amp;\hat{\texttt{b1}}\texttt{*}(\texttt{gross.square.feet[A]} - \texttt{gross.square.feet[B]})\\
\;=\quad &amp;\hat{\texttt{b1}}\texttt{*}\texttt{(2001 - 2000)}\qquad\qquad\quad\;\;\\
\;=\quad &amp;\hat{\texttt{b1}}\qquad\qquad\qquad\qquad\quad\;\;\;\,\end{align}$$`





---
# Interpreting Estimated Beta Coefficients
### &lt;p style="color:#00449E"&gt; 
Consider the predicted sales prices of the two houses, `A` and `C`.
  - Both `A` and `C`'s `age` are the same. 
  - Both `A` and `C`'s `gross.square.feet` are the same. 
  - `A` is in `Bronx`, and `C` is in `Manhattan`. 
  
  
`$$\begin{align}\widehat{\texttt{sale.price[A]}} \;=\quad&amp; \hat{\texttt{b0}} \,+\, \hat{\texttt{b1}}\texttt{*gross.square.feet[A]} \,+\, \hat{\texttt{b2}}\texttt{*age[A]} \,+\, \hat{\texttt{b3}}\texttt{*Bronx[A]}\,+\,\\
&amp;\hat{\texttt{b4}}\texttt{*Brooklyn[A]} \,+\, \hat{\texttt{b5}}\texttt{*Queens[A]}\,+\, \hat{\texttt{b6}}\texttt{*Staten Island[A]}\\
\widehat{\texttt{sale.price[C]}} \;=\quad&amp; \hat{\texttt{b0}} \,+\, \hat{\texttt{b1}}\texttt{*gross.square.feet[C]} \,+\, \hat{\texttt{b2}}\texttt{*age[C]}\,+\,\hat{\texttt{b3}}\texttt{*Bronx[C]}\,+\,\\
&amp;\hat{\texttt{b4}}\texttt{*Brooklyn[C]} \,+\, \hat{\texttt{b5}}\texttt{*Queens[C]}\,+\, \hat{\texttt{b6}}\texttt{*Staten Island[C]} \end{align}$$`

`$$\begin{align}\Leftrightarrow\qquad&amp;\widehat{\texttt{sale.price[A]}} \,-\, \widehat{\texttt{sale.price[C]}}\qquad  \\
\;=\quad &amp;\hat{\texttt{b3}}\texttt{*}\texttt{Bronx[A]} \\
\;=\quad &amp;\hat{\texttt{b3}}\qquad\qquad\qquad\qquad\quad\;\;\;\,\end{align}$$`




---
# Interpreting Estimated Beta Coefficients
### &lt;p style="color:#00449E"&gt; 

- What does it mean for a beta estimate `\(\hat{\beta}\)` to be statistically significant at 5% level?

  - It means that the null hypothesis `\(H_{0}: \beta = 0\)` is rejected for a given significance level 5%.
  
  - "2 standard error rule" of thumb: The true value of `\(\beta\)` is 95% likely to be in the confidence interval `\((\, \hat{\beta} - 2 * \texttt{Std. Error}\;,\; \hat{\beta} + 2 * \texttt{Std. Error} \,)\)`.
  
  - The standard error tells us how uncertain our estimate of the coefficient `b` is.
 
  - We should look for the stars!



---
class: inverse, center, middle

# Model Evaluation
&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=796px&gt;&lt;/html&gt;



---
# Model Evaluation
### &lt;p style="color:#00449E"&gt;  Model summary with `stargazer`

- `stargazer::stargazer()` is useful when comparing several regression results.

```r
# install.packages("stargazer")
stargazer(model, model_2, 
          type = 'text')  # from the stargazer package
```



---
# Model Evaluation
### &lt;p style="color:#00449E"&gt; F-statistic
- F-statistic is the value of F-test statistic for the hypothesis for overall significance of beta estimates:
`$$H_{0}: \beta_{1} = \beta_{2} = \cdots = \beta_{p} = 0$$`
- It is possible for all individual coefficients to be insignificant while jointly they are significant.


---
# Model Evaluation
### &lt;p style="color:#00449E"&gt; R-squared

- **R-squared** is a measure of how well the model “fits” the data, or its “goodness of fit.”
  - **R-squared** can be thought of as *what fraction of the `y`'s variation is explained by the explanatory variables*.


- We want **R-squared** to be *fairly* large and **R-squareds** that are similar on testing and training.


- **Caution**: R-squared will be higher for models with more explanatory variables, regardless of whether the additional explanatory variables actually improve the model or not.



---
# Model Evaluation
### &lt;p style="color:#00449E"&gt;  Model summary with `broom::tidy()`
- The `broom::tidy()` is useful when plotting beta estimates with their confidence intervals.


```r
# install.packages("broom")
sum_model &lt;- tidy(model)  # from the broom package

ggplot(sum_model) +
  geom_pointrange( aes(x = term, 
                       y = estimate,
                       ymin = estimate - 2*std.error,
                       ymax = estimate + 2*std.error ) ) +
  coord_flip()
```


---
# Model Evaluation
### &lt;p style="color:#00449E"&gt;  Residual Plots


.panelset[
.panel[.panel-name[(1)]
- Residual plot is a scatterplot of fitted values and residuals.
  - A variable of fitted values on x-axis
  - A variable of residuals on y-axis
-  A residual plot can be used to diagnose the quality of model results.

```r
ggplot(data = dtest, aes(x = pred, y = sale.price - pred)) +
  geom_point(alpha = 0.2, color = "darkgray") +
  geom_smooth(color = "darkblue") +   
  geom_hline(aes(yintercept = 0),  # perfect prediction 
            color = "red", linetype = 2) 
```

]

.panel[.panel-name[(2)]
- Model equation: `\(Y_{i} \,=\, \beta_{0} \,+\, \beta_{1}X_{1,i}\)`
  - `\(\epsilon_i\)` is a random noise, or a statistical error:

$$
\epsilon_i \sim N(0, \sigma^2) 
$$
  - Errors have a mean value of 0 with constant variance `\(\sigma^2\)`.
  - Errors are *uncorrelated* with `\(X_{1,i}\)`


]


.panel[.panel-name[(3)]
- If we re-arrange the simple regression equation,
`$$\begin{align}
{\epsilon}_{i} \,=\, Y_{i} \,-\, (\, {\beta}_{0} \,+\, {\beta}_{1}X_{1} \,).
\end{align}$$`

- `\(\texttt{residual_error}_{i}\)` can be thought of as the expected value of `\(\epsilon_{i}\)`, denoted by `\(\hat{\epsilon}_{i}\)`. 
`$$\begin{align}
\hat{\epsilon}_{i} \,=\, Y_{i} \,-\, (\, \hat{\beta}_{0} \,+\, \hat{\beta}_{1}X_{1} \,)
\end{align}$$`

- Because we assume that `\(\epsilon_{i}\)` have a mean value of 0 with constant variance `\(\sigma^2\)`, a well-behaved residual plot should bounce *randomly* and form a cloud roughly around the perfect prediction line. 

]

.panel[.panel-name[(4)]

- From the residual plot, we should ask the following the two questions ourselves:
  - On average, are the predictions correct?
  - Are there systematic errors?


- A well-behaved plot will bounce *randomly* and form a cloud roughly around the perfect prediction line. 

]

.panel[.panel-name[(5)]
.pull-left[
&lt;img src="lec_figs/residual_hetero2.png" width="100%" style="display: block; margin: auto;" /&gt;
]
.pull-right[
- On average, are the predictions correct?

- Are there systematic errors?
]
]

.panel[.panel-name[(6)]
- We would like have a residual plot to be
  - **Unbiased**: have an average value of zero in any thin vertical strip;
  - **Homoskedastic**, which means "same stretch": it is ideal to have the same spread of the residuals in any thin vertical strip.

]

.panel[.panel-name[(7)]

&lt;img src="lec_figs/resid-plots.gif" width="50%" style="display: block; margin: auto;" /&gt;

]

]




---
# Model Evaluation
### &lt;p style="color:#00449E"&gt; Mean squared error (MSE)

.panelset[
.panel[.panel-name[(1)]
- One of the most common metrics used to measure the **prediction accuracy** of a linear regression model is **MSE**, which stands for **mean squared error**. 
  - `\(MSE\)` is `\(SSR\)` divided by `\(n\)` (the number of observations in the data that are used in making predictions).

`$$MSE = SSR / n$$`
  - `\(SSR = \texttt{Residual_Error}_{1}^{2} \,+\, \texttt{Residual_Error}_{2}^{2} \,+\, \cdots + \texttt{Residual_Error}_{n}^{2}\)`
  
  - `\(\texttt{Residual_Error}_{i} \,=\, Y_{i} \,-\, \hat{Y}_{i}\)`.

]
.panel[.panel-name[(2)]


```r
MSE &lt;- dtest %&gt;% 
  mutate(resid = sale.price - pred,
         resid_sq = resid^2) %&gt;% 
  summarize(mse = mean(resid_sq),
            rmse = sqrt(mse))
```

- The lower MSE, the higher accuracy of the model.  

- The root MSE (RMSE) is the square root of MSE.

]


.panel[.panel-name[(3)]

.left-column[
- The root MSE (RMSE) represents the overall deviation of `\(Y_{i}\)` from the best fitting regression line.

]

.right-column[

&lt;img src="lec_figs/best_fit_resid.png" width="75%" style="display: block; margin: auto;" /&gt;
]



]

]


---
class: inverse, center, middle

# Linear Regression with Log-transformed Variables
&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=796px&gt;&lt;/html&gt;




---
# A Little Bit of Math for `log()` and `exp()`
### &lt;p style="color:#00449E"&gt; 

.panelset[

.panel[.panel-name[log functions]

- The logarithm function, `\(y = \log_{b}\,(\,x\,)\)`, looks like ....

&lt;img src="lec_figs/logarithm_plots.png" width="50%" style="display: block; margin: auto;" /&gt;
]

.panel[.panel-name[log examples]
- `\(\log_{10}\,(\,100\,)\)`: the base `\(10\)` logarithm of `\(100\)` is `\(2\)`, because `\(10^{2} = 100\)`

- `\(\log_{e}\,(\,x\,)\)`: the base `\(e\)` logarithm is called the natural log, where `\(e = 2.718\cdots\)` is the mathematical constant,  the Euler's number.

- `\(\log\,(\,x\,)\)` or `\(\ln\,(\,x\,)\)`: the natural log of `\(x\)` .

- `\(\log_{e}\,(\,7.389\cdots\,)\)`: the natural log of `\(7.389\cdots\)` is `\(2\)`, because `\(e^{2} = 7.389\cdots\)`.
]

]

 
---
# A Little Bit of Math for `log()` and `exp()`
### &lt;p style="color:#00449E"&gt;  

.panelset[
.panel[.panel-name[(1)]
.pull-left[

&lt;img src="DANL200_Lec22_20230427_files/figure-html/unnamed-chunk-15-1.png" style="display: block; margin: auto;" /&gt;

]


.pull-right[
- Rule 1: 
`$$\begin{align}
\texttt{y} &amp;\,=\, \texttt{log(x)}\\
\qquad\Leftrightarrow\qquad \texttt{exp(y)} &amp;\,=\, \texttt{exp(log(x))}\\
\qquad\Leftrightarrow\qquad \texttt{exp(y)} &amp;\,=\, \texttt{x}.
\end{align}$$`


- Rule 2: 

`$$\texttt{log(x)} \,-\, \texttt{log(z)} \,=\, \texttt{log}\,\left(\,\frac{\texttt{x}}{\texttt{z}}\,\right).$$`
]

]

.panel[.panel-name[(2)]

- By these rules,
$$
\texttt{log(x)} \,-\, \texttt{log(z)} \,=\, \texttt{b}\qquad\Leftrightarrow\qquad \frac{\texttt{x}}{\texttt{z}} \,=\,\texttt{exp(b)}.
$$

- This is because
`$$\begin{align}
\texttt{log(x)} \,-\, \texttt{log(z)} &amp;\,=\, \texttt{b}\\
\Leftrightarrow\qquad\qquad\qquad \texttt{log}\,\left(\,\frac{\texttt{x}}{\texttt{z}}\,\right) &amp;\,=\, \texttt{b}\\
\Leftrightarrow\qquad\;\;\, \texttt{exp}\left(\,\texttt{log}\,\left(\,\frac{\texttt{x}}{\texttt{z}}\,\right)\,\right) &amp;\,=\, \texttt{exp(b)}\\
\Leftrightarrow\qquad\qquad\qquad\qquad\quad\;\, \frac{\texttt{x}}{\texttt{z}} &amp;\,=\,\texttt{exp(b)}.\end{align}$$`

]
]



---
# When should we consider log-transformation?
### &lt;p style="color:#00449E"&gt;
.panelset[
.panel[.panel-name[(1)]
**1**. We should consider using a logarithmic scale when percent change, or change in orders of magnitude, is more important than changes in absolute units.

  - For small changes in variable `\(x\)` from `\(x_{0}\)` to `\(x_{1}\)`, the following can be shown: 
  
`$$\Delta \log(x) \,= \, \log(x_{1}) \,-\, \log(x_{0}) 
\approx\, \frac{x_{1} \,-\, x_{0}}{x_{0}} 
\,=\, \frac{\Delta\, x}{x_{0}}.$$`

- For example, a difference in `sale.price` of $10,000 means something very different across people with different income/wealth levels.


]

.panel[.panel-name[(2)]
**2**. We should consider using a log scale when a variable is heavily skewed.
  - It reduces the influence of outliers and make the data more normaly distributed.

.pull-left[

```r
ggplot(sale_df, 
       aes(x = sale.price)) +
  geom_density() 
```

]
.pull-right[


```r
ggplot(sale_df, 
       aes(x = log(sale.price))) +
  geom_density()
```

]

]

]







---
# Linear Regression with Log Transformation

The model equation with log-transformed `\(\texttt{sale.price[i]}\)` is 
`$$\begin{align}
\log(\texttt{sale.price[i]}) \;=\;\, &amp;\texttt{b0} \,+\,\\ &amp;\texttt{b1*gross.square.feet[i]} \,+\,\texttt{b2*age[i]}\,+\,\\ &amp;\texttt{b3*Bronx[i]} \,+\,\texttt{b4*Brooklyn[i]} \,+\,\\&amp;\texttt{b5*Queens[i]} \,+\,\texttt{b6*Staten Island[i]}\,+\,\\ &amp;\texttt{e[i]}.
\end{align}$$`

- Note that the reference level for `borough_name` is `Manhattan`.

---
# Linear Regression with Log Transformation
### &lt;p style="color:#00449E"&gt; Interpreting Beta Estimates

.panelset[
.panel[.panel-name[(1)]
- Let's re-consider the two properties `\(\texttt{A}\)` and `\(\texttt{B}\)`.
  - `\(\texttt{gross.square.feet[A]} = 2001\)` and `\(\texttt{gross.square.feet[B]} = 2000\)`.
  - Both are in the same borough.
  - Both properties' ages are the same.

]

.panel[.panel-name[(2)]

- If we apply the rule above for `\(\widehat{\texttt{sale.price}}\texttt{[A]}\)` and `\(\widehat{\texttt{sale.price}}\texttt{[B]}\)`,

`$$\begin{align}&amp;\log(\widehat{\texttt{sale.price}}\texttt{[A]}) - \log(\widehat{\texttt{sale.price}}\texttt{[B]}) \\
\,=\, &amp;\hat{\texttt{b1}}\,*\,(\texttt{gross.square.feet[A]} \,-\, \texttt{gross.square.feet[B]})\\
\,=\, &amp;\hat{\texttt{b1}}\end{align}$$`


So we can have the following:
`$$\Leftrightarrow\qquad\frac{\widehat{\texttt{sale.price[A]}}}{ \widehat{\texttt{sale.price[B]}}} \;=\; \texttt{exp(}\hat{\texttt{b1}}\texttt{)} \quad\Leftrightarrow\quad\widehat{\texttt{sale.price[A]}} \;=\; \widehat{\texttt{sale.price[B]}} * \texttt{exp(}\hat{\texttt{b1}}\texttt{)}$$`
]


.panel[.panel-name[(3)]
- Suppose `\(\texttt{exp(}\hat{\texttt{b2}}\texttt{)} = 1.000431\)`. 

  - Then `\(\widehat{\texttt{sale.price[A]}}\)` is `\(1.000431\times\widehat{\texttt{sale.price[B]}}\)`.
  
  - All else being equal, an increase in `\(\texttt{gross.square.feet}\)` by one unit is associated with an increase in `\(\texttt{sale.price}\)` by 0.0431%.

]


]




---
# Linear Regression with Log Transformation
### &lt;p style="color:#00449E"&gt; Interpreting Beta Estimates

.panelset[
.panel[.panel-name[(1)]
- Let's re-consider the two properties `\(\texttt{A}\)` and `\(\texttt{C}\)`.
  - `A` is in `Bronx`, and `C` is in `Manhattan`. 
  - Both `A` and `C`'s `age` are the same. 
  - Both `A` and `C`'s `gross.square.feet` are the same. 

]

.panel[.panel-name[(2)]

- If we apply the `log()`-`exp()` rules for `\(\widehat{\texttt{sale.price}}\texttt{[A]}\)` and `\(\widehat{\texttt{sale.price}}\texttt{[C]}\)`,

`$$\begin{align}&amp;\log(\widehat{\texttt{sale.price}}\texttt{[A]}) - \log(\widehat{\texttt{sale.price}}\texttt{[C]}) \\
\,=\, &amp;\hat{\texttt{b3}}\,*\,(\texttt{borough_Bronx[A]} \,-\, \texttt{borough_Bronx[C]})\\
\,=\, &amp;\hat{\texttt{b3}}\end{align}$$`


So we can have the following:
`$$\Leftrightarrow\qquad\frac{\widehat{\texttt{sale.price[A]}}}{ \widehat{\texttt{sale.price[C]}}} \;=\; \texttt{exp(}\hat{\texttt{b1}}\texttt{)} \quad\Leftrightarrow\quad\widehat{\texttt{sale.price[A]}} \;=\; \widehat{\texttt{sale.price[C]}} * \texttt{exp(}\hat{\texttt{b3}}\texttt{)}$$`
]


.panel[.panel-name[(3)]
- Suppose `\(\texttt{exp(}\hat{\texttt{b3}}\texttt{)} = 0.2831691\)`. 

  - Then `\(\widehat{\texttt{sale.price[A]}}\)` is `\(0.2831691\times\widehat{\texttt{sale.price[B]}}\)`.
  
  - All else being equal, an increase in `\(\texttt{borough_Bronx}\)` by one unit is associated with a decrease in `\(\texttt{sale.price}\)` by (1 - 0.2831691) = 71.78%.
  
  - All else being equal, being in `Bronx` relative to being in `Manhattan` is associated with a decrease in `\(\texttt{sale.price}\)` by 71.78%.

]


]



  
---
# Linear Regression with Log Transformation
### &lt;p style="color:#00449E"&gt; Interpreting Beta Estimates

- All else being equal, an increase in `gross.square.feet` by one unit is associated with an increase in `log(sale.price)` by `b1`.
  - All else being equal, an increase in `gross.square.feet` by one unit is associated with an increase in `sale.price` by `(exp(b1) - 1) * 100`%.



- All else being equal, an increase in `broughBronx` by one unit is associated with an increase in `log(sale.price)` by `b3`.
  - All else being equal, being in `Bronx` is associated with a decrease in `sale.price` by `|(exp(b3) - 1)| * 100`% relative to being in `Manhattan`.


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "googlecode",
"highlightLines": true,
"highlightLanguage": "r",
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<!--Hat-tip: https://www.garrickadenbuie.com/blog/xaringan-tip-logo-all-slides/-->
<style>
.logo {
  background-image: url(img/logo-blue.png);
  background-size: contain;
  background-repeat: no-repeat;
  position: absolute;
  top: 1em;
  right: 1em;
  width: 55px;
  height: 66px;
  z-index: 0;
}
</style>

<script>
document
  .querySelectorAll(
    '.remark-slide-content' +
    ':not(.title-slide)' +
    // add additional classes to exclude here, e.g.
    ':not(.inverse)' +
    ':not(.hide-logo)'
  )
  .forEach(el => {
    el.innerHTML += '<div class="logo"></div>';
  });
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
