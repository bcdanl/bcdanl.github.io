<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>DANL 200 Lecture 24</title>
    <meta charset="utf-8" />
    <meta name="author" content="Byeong-Hak Choe" />
    <meta name="date" content="2023-05-04" />
    <script src="libs/header-attrs-2.20/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <link href="libs/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.2.6/panelset.js"></script>
    <script src="libs/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <script src="libs/xaringanExtra-webcam-0.0.1/webcam.js"></script>
    <script id="xaringanExtra-webcam-options" type="application/json">{"width":"200","height":"200","margin":"1em"}</script>
    <script src="libs/js-cookie-3.0.0/js.cookie.js"></script>
    <script src="libs/peerjs-1.3.1/peerjs.min.js"></script>
    <script src="libs/tiny.toast-1.0.0/toast.min.js"></script>
    <link href="libs/xaringanExtra-broadcast-0.2.6/broadcast.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-broadcast-0.2.6/broadcast.js"></script>
    <link href="libs/shareon-1.4.1/shareon.min.css" rel="stylesheet" />
    <script src="libs/shareon-1.4.1/shareon.min.js"></script>
    <link href="libs/xaringanExtra-shareagain-0.2.6/shareagain.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-shareagain-0.2.6/shareagain.js"></script>
    <link href="libs/xaringanExtra-extra-styles-0.2.6/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/nhsr.css" type="text/css" />
    <link rel="stylesheet" href="css/nhsr-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




class: title-slide, left, bottom

# DANL 200 Lecture 24
----
## **DANL 200: Introduction to Data Analytics**
### Byeong-Hak Choe
### May 4, 2023



---
class: inverse, center, middle

# Linear Regression with Log-transformed Variables
&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=796px&gt;&lt;/html&gt;



---
# A Little Bit of Math for `log()` and `exp()`
### &lt;p style="color:#00449E"&gt; 

.panelset[

.panel[.panel-name[log functions]

- The logarithm function, `\(y = \log_{b}\,(\,x\,)\)`, looks like ....

&lt;img src="lec_figs/logarithm_plots.png" width="50%" style="display: block; margin: auto;" /&gt;
]

.panel[.panel-name[log examples]
- `\(\log_{10}\,(\,100\,)\)`: the base `\(10\)` logarithm of `\(100\)` is `\(2\)`, because `\(10^{2} = 100\)`

- `\(\log_{e}\,(\,x\,)\)`: the base `\(e\)` logarithm is called the natural log, where `\(e = 2.718\cdots\)` is the mathematical constant,  the Euler's number.

- `\(\log\,(\,x\,)\)` or `\(\ln\,(\,x\,)\)`: the natural log of `\(x\)` .

- `\(\log_{e}\,(\,7.389\cdots\,)\)`: the natural log of `\(7.389\cdots\)` is `\(2\)`, because `\(e^{2} = 7.389\cdots\)`.
]

]

 
---
# A Little Bit of Math for `log()` and `exp()`
### &lt;p style="color:#00449E"&gt;  

.panelset[
.panel[.panel-name[(1)]
.pull-left[

&lt;img src="DANL200_Lec24_20230504_files/figure-html/unnamed-chunk-2-1.png" style="display: block; margin: auto;" /&gt;

]


.pull-right[
- Rule 1: 
`$$\begin{align}
\texttt{y} &amp;\,=\, \texttt{log(x)}\\
\qquad\Leftrightarrow\qquad \texttt{exp(y)} &amp;\,=\, \texttt{exp(log(x))}\\
\qquad\Leftrightarrow\qquad \texttt{exp(y)} &amp;\,=\, \texttt{x}.
\end{align}$$`


- Rule 2: 

`$$\texttt{log(x)} \,-\, \texttt{log(z)} \,=\, \texttt{log}\,\left(\,\frac{\texttt{x}}{\texttt{z}}\,\right).$$`
]

]

.panel[.panel-name[(2)]

- By these rules,
$$
\texttt{log(x)} \,-\, \texttt{log(z)} \,=\, \texttt{b}\qquad\Leftrightarrow\qquad \frac{\texttt{x}}{\texttt{z}} \,=\,\texttt{exp(b)}.
$$

- This is because
`$$\begin{align}
\texttt{log(x)} \,-\, \texttt{log(z)} &amp;\,=\, \texttt{b}\\
\Leftrightarrow\qquad\qquad\qquad \texttt{log}\,\left(\,\frac{\texttt{x}}{\texttt{z}}\,\right) &amp;\,=\, \texttt{b}\\
\Leftrightarrow\qquad\;\;\, \texttt{exp}\left(\,\texttt{log}\,\left(\,\frac{\texttt{x}}{\texttt{z}}\,\right)\,\right) &amp;\,=\, \texttt{exp(b)}\\
\Leftrightarrow\qquad\qquad\qquad\qquad\quad\;\, \frac{\texttt{x}}{\texttt{z}} &amp;\,=\,\texttt{exp(b)}.\end{align}$$`

]
]



---
# When should we consider log-transformation?
### &lt;p style="color:#00449E"&gt;
.panelset[
.panel[.panel-name[(1)]
**1**. We should consider using a logarithmic scale when percent change, or change in orders of magnitude, is more important than changes in absolute units.

  - For small changes in variable `\(x\)` from `\(x_{0}\)` to `\(x_{1}\)`, the following can be shown: 
  
`$$\Delta \log(x) \,= \, \log(x_{1}) \,-\, \log(x_{0}) 
\approx\, \frac{x_{1} \,-\, x_{0}}{x_{0}} 
\,=\, \frac{\Delta\, x}{x_{0}}.$$`

- For example, a difference in `sale.price` of $10,000 means something very different across people with different income/wealth levels.


]

.panel[.panel-name[(2)]
**2**. We should consider using a log scale when a variable is heavily skewed.
  - It reduces the influence of outliers and make the data more normaly distributed.

.pull-left[

```r
ggplot(sale_df, 
       aes(x = sale.price)) +
  geom_density() 
```

]
.pull-right[


```r
ggplot(sale_df, 
       aes(x = log(sale.price))) +
  geom_density()
```

]

]

]



---
# Linear Regression with Log Transformation

The model equation with log-transformed `\(\texttt{sale.price[i]}\)` is 
`$$\begin{align}
\log(\texttt{sale.price[i]}) \;=\;\, &amp;\texttt{b0} \,+\,\\ &amp;\texttt{b1*gross.square.feet[i]} \,+\,\texttt{b2*age[i]}\,+\,\\ &amp;\texttt{b3*Bronx[i]} \,+\,\texttt{b4*Brooklyn[i]} \,+\,\\&amp;\texttt{b5*Queens[i]} \,+\,\texttt{b6*Staten Island[i]}\,+\,\\ &amp;\texttt{e[i]}.
\end{align}$$`

- Note that the reference level for `borough_name` is `Manhattan`.

---
# Linear Regression with Log Transformation
### &lt;p style="color:#00449E"&gt; Interpreting Beta Estimates

.panelset[
.panel[.panel-name[(1)]
- Let's re-consider the two properties `\(\texttt{A}\)` and `\(\texttt{B}\)`.
  - `\(\texttt{gross.square.feet[A]} = 2001\)` and `\(\texttt{gross.square.feet[B]} = 2000\)`.
  - Both are in the same borough.
  - Both properties' ages are the same.

]

.panel[.panel-name[(2)]

- If we apply the rule above for `\(\widehat{\texttt{sale.price}}\texttt{[A]}\)` and `\(\widehat{\texttt{sale.price}}\texttt{[B]}\)`,

`$$\begin{align}&amp;\log(\widehat{\texttt{sale.price}}\texttt{[A]}) - \log(\widehat{\texttt{sale.price}}\texttt{[B]}) \\
\,=\, &amp;\hat{\texttt{b1}}\,*\,(\texttt{gross.square.feet[A]} \,-\, \texttt{gross.square.feet[B]})\\
\,=\, &amp;\hat{\texttt{b1}}\end{align}$$`


So we can have the following:
`$$\Leftrightarrow\qquad\frac{\widehat{\texttt{sale.price[A]}}}{ \widehat{\texttt{sale.price[B]}}} \;=\; \texttt{exp(}\hat{\texttt{b1}}\texttt{)} \quad\Leftrightarrow\quad\widehat{\texttt{sale.price[A]}} \;=\; \widehat{\texttt{sale.price[B]}} * \texttt{exp(}\hat{\texttt{b1}}\texttt{)}$$`
]


.panel[.panel-name[(3)]
- Suppose `\(\texttt{exp(}\hat{\texttt{b2}}\texttt{)} = 1.000431\)`. 

  - Then `\(\widehat{\texttt{sale.price[A]}}\)` is `\(1.000431\times\widehat{\texttt{sale.price[B]}}\)`.
  
  - All else being equal, an increase in `\(\texttt{gross.square.feet}\)` by one unit is associated with an increase in `\(\texttt{sale.price}\)` by 0.0431%.

]


]




---
# Linear Regression with Log Transformation
### &lt;p style="color:#00449E"&gt; Interpreting Beta Estimates

.panelset[
.panel[.panel-name[(1)]
- Let's re-consider the two properties `\(\texttt{A}\)` and `\(\texttt{C}\)`.
  - `A` is in `Bronx`, and `C` is in `Manhattan`. 
  - Both `A` and `C`'s `age` are the same. 
  - Both `A` and `C`'s `gross.square.feet` are the same. 

]

.panel[.panel-name[(2)]

- If we apply the `log()`-`exp()` rules for `\(\widehat{\texttt{sale.price}}\texttt{[A]}\)` and `\(\widehat{\texttt{sale.price}}\texttt{[C]}\)`,

`$$\begin{align}&amp;\log(\widehat{\texttt{sale.price}}\texttt{[A]}) - \log(\widehat{\texttt{sale.price}}\texttt{[C]}) \\
\,=\, &amp;\hat{\texttt{b3}}\,*\,(\texttt{borough_Bronx[A]} \,-\, \texttt{borough_Bronx[C]})\\
\,=\, &amp;\hat{\texttt{b3}}\end{align}$$`


So we can have the following:
`$$\Leftrightarrow\qquad\frac{\widehat{\texttt{sale.price[A]}}}{ \widehat{\texttt{sale.price[C]}}} \;=\; \texttt{exp(}\hat{\texttt{b1}}\texttt{)} \quad\Leftrightarrow\quad\widehat{\texttt{sale.price[A]}} \;=\; \widehat{\texttt{sale.price[C]}} * \texttt{exp(}\hat{\texttt{b3}}\texttt{)}$$`
]


.panel[.panel-name[(3)]
- Suppose `\(\texttt{exp(}\hat{\texttt{b3}}\texttt{)} = 0.2831691\)`. 

  - Then `\(\widehat{\texttt{sale.price[A]}}\)` is `\(0.2831691\times\widehat{\texttt{sale.price[B]}}\)`.
  
  - All else being equal, an increase in `\(\texttt{borough_Bronx}\)` by one unit is associated with a decrease in `\(\texttt{sale.price}\)` by (1 - 0.2831691) = 71.78%.
  
  - All else being equal, being in `Bronx` relative to being in `Manhattan` is associated with a decrease in `\(\texttt{sale.price}\)` by 71.78%.

]


]



  
---
# Linear Regression with Log Transformation
### &lt;p style="color:#00449E"&gt; Interpreting Beta Estimates

- All else being equal, an increase in `gross.square.feet` by one unit is associated with an increase in `log(sale.price)` by `b1`.
  - All else being equal, an increase in `gross.square.feet` by one unit is associated with an increase in `sale.price` by `(exp(b1) - 1) * 100`%.



- All else being equal, an increase in `broughBronx` by one unit is associated with an increase in `log(sale.price)` by `b3`.
  - All else being equal, being in `Bronx` is associated with a decrease in `sale.price` by `|(exp(b3) - 1)| * 100`% relative to being in `Manhattan`.




---
class: inverse, center, middle

# Linear Regression with Interaction Terms
&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=796px&gt;&lt;/html&gt;

---
# Linear Regression with Interaction Terms
### &lt;p style="color:#00449E"&gt; Motivation

- Does the relationship between education and income vary by gender?

  - Suppose we are interested in knowing whether women are being compensated unequally despite having the same levels of education and preparation as men do.

  - How can linear regression address the question above?



---
# Linear Regression with Interaction Terms
### &lt;p style="color:#00449E"&gt; Model

- The linear regression with an interaction between explanatory variables `\(X_{1}\)` and `\(X_{2}\)` are:

`$$Y_{\texttt{i}} \,=\, b_{0} \,+\, b_{1}\,X_{1,\texttt{i}} \,+\, b_{2}\,X_{2,\texttt{i}} \,+\, b_{3}\,X_{1,\texttt{i}}\times \color{Red}{X_{2,\texttt{i}}} \,+\, e_{\texttt{i}},$$`

- where
  - `\(i\;\)`: `\(\;\;i\)`-th observation in the training data.frame, `\(i = 1, 2, 3, \cdots\)`.
  - `\(Y_{i}\,\)`: `\(\;i\)`-th observation of outcome variable `\(Y\)`.
  - `\(X_{p, i}\,\)`: `\(i\)`-th observation of the `\(p\)`-th explanatory variable `\(X_{p}\)`.
  - `\(e_{i}\;\)`: `\(\;i\)`-th observation of statistical error variable.
  
  

---
# Linear Regression with Interaction Terms
### &lt;p style="color:#00449E"&gt; Model

- The linear regression with an interaction between explanatory variables `\(X_{1}\)` and `\(X_{2}\)` are:

`$$Y_{\texttt{i}} \,=\, b_{0} \,+\, b_{1}\,X_{1,\texttt{i}} \,+\, b_{2}\,X_{2,\texttt{i}} \,+\, b_{3}\,X_{1,\texttt{i}}\times \color{Red}{X_{2,\texttt{i}}} \,+\, e_{\texttt{i}}\;.$$`

.panelset[

.panel[.panel-name[Interaction]

- The relationship between `\(X_{1}\)` and `\(Y\)` varies by values of `\(b_{3}\, X_{2}\)`:

`$$\frac{\Delta Y}{\Delta X_{1}} \,=\, b_{1} + b_{3}\, X_{2}$$`.
]


.panel[.panel-name[Example]
- `\(X_{2}\)` is often a dummy variable. If `\(b_{3} \neq 0\)` and `\(X_{2, \texttt{i}} = 1\)`,
  
`$$\frac{\Delta Y}{\Delta X_{1}} \,=\, b_{1} + b_{3}$$`.

]

]



---
# Linear Regression with Interaction Terms
### &lt;p style="color:#00449E"&gt; Interaction with a Dummy Variable

- The linear regression with an interaction between explanatory variables `\(X_{1}\)` and `\(X_{2}\in\{\,0, 1\,\}\)` are:

`$$Y_{\texttt{i}} \,=\, b_{0} \,+\, b_{1}\,X_{1,\texttt{i}} \,+\, b_{2}\,X_{2,\texttt{i}} \,+\, b_{3}\,X_{1,\texttt{i}}\times \color{Red}{X_{2,\texttt{i}}} \,+\, e_{\texttt{i}},$$`
where `\(X_{\,2, \texttt{i}}\)` is either 0 or 1.

- For `\(\texttt{i}\)` such that `\(X_{\,2, \texttt{i}} = 0\)`, the model is
`$$Y_{\texttt{i}} \,=\, b_{0} \,+\, b_{1}\,X_{1,\texttt{i}} \,+\, e_{\texttt{i}}\qquad\qquad\qquad\qquad\qquad\quad\;\;$$`

- For `\(\texttt{i}\)` such that `\(X_{\,2, \texttt{i}} = 1\)`,  the model is

`$$Y_{\texttt{i}} \,=\, (\,b_{0} \,+\, b_{2}\,) \,+\, (\,b_{1}\,+\, b_{3}\,)\,X_{1,\texttt{i}} \,+\, e_{\texttt{i}}\qquad\qquad$$`


---
# Linear Regression with Interaction Terms
### &lt;p style="color:#00449E"&gt; Motivation

- Is `sale.price` related with `gross.square.feet`?


```r
model_log &lt;- lm(log(sale.price) ~ gross.square.feet + age + borough_name, 
              data = dtrain)
```

- Does the relationship between `sale.price` and `gross.square.feet` vary by borough?


```r
model_int &lt;- lm(log(sale.price) ~ gross.square.feet + age + borough_name + gross.square.feet * borough_name, 
              data = dtrain)

# Equivalently,
model_int &lt;- lm( log(sale.price) ~ gross.square.feet * borough_name + age,  # Use this one
                 data = dtrain )
```



---
# Linear Regression with Interaction Terms

- How could we see how the relationship between `sale.price` and `gross.square.feet` vary by `borough_name`?

.panelset[
.panel[.panel-name[Code]

```r
summary(model_int) # check stars
b_int &lt;- coef(model_int)
# the relationship between `gross.square.feet` and `sale.price`
# in Bronx
exp( b_int['gross.square.feet'] ) - 1
# the relationship between `gross.square.feet` and `sale.price`
# in Brooklyn
exp( b_int['gross.square.feet'] + 
       b_int['gross.square.feet:borough_nameBrooklyn'] ) - 1
```
]

.panel[.panel-name[Interpretation]
- All else being equal, an increase in `gross.square.feet` by one unit is associated with an increase in `sale.price` by 3.03% in Bronx.

- All else being equal, an increase in `gross.square.feet` by one unit is associated with an increase in `sale.price` by 5.72% in Brooklyn.
]

]




---
class: inverse, center, middle

# Log-Log Linear Regression
&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=796px&gt;&lt;/html&gt;


---
# Log-Log Linear Regression
### &lt;p style="color:#00449E"&gt; Estimating Price Elasticity

- To estimate the price elasticity of orange juice (OJ), we will use sales data for OJ from Dominick’s grocery stores in the 1990s.
  - Weekly `price` and `sales` (in number of cartons "sold") for three OJ brands---Tropicana, Minute Maid, Dominick's
  - An indicator, `ad`, showing whether each `brand` was advertised (in store or flyer) that week.
  

Variable  | Description
----------|-------------------------------
`sales`   | Quantity of OJ cartons sold
`price`   | Price of OJ
`brand`   | Brand of OJ
`ad`    | Advertisement status



---
# Log-Log Linear Regression
### &lt;p style="color:#00449E"&gt; Estimating Price Elasticity

- Let's prepare the OJ data:

```r
oj &lt;- read_csv('https://bcdanl.github.io/data/dominick_oj.csv')

# Split 70-30 into training and testing data.frames
set.seed(14454)
gp &lt;- runif( nrow(oj) )

dtrain &lt;- filter(oj, [?])
dtest &lt;- filter(oj, [?])
```




---
# Log-Log Linear Regression
### &lt;p style="color:#00449E"&gt; Estimating Price Elasticity

- The following model estimates the price elasticity of demand for a carton of OJ:

`$$\log(\texttt{sales}_{\texttt{i}}) \,=\, \quad\;\; b_{\texttt{intercept}} \,+\, b_{\,\texttt{mm}}\,\texttt{brand}_{\,\texttt{mm}, \texttt{i}} \,+\, b_{\,\texttt{tr}}\,\texttt{brand}_{\,\texttt{tr}, \texttt{i}}\\
 \,+\, b_{\texttt{price}}\,\log(\texttt{price}_{\texttt{i}}) \,+\, e_{\texttt{i}}$$`

- where
  
$$
\texttt{brand}_{\,\texttt{tr}, \texttt{i}}\\
= \begin{cases}
\texttt{1} &amp; \text{ if an orange juice } \texttt{i} \text{ is } \texttt{Tropicana};\\\\
\texttt{0} &amp; \text{otherwise}.\qquad\qquad\quad\,
\end{cases}
$$


  
$$
\texttt{brand}_{\,\texttt{mm}, \texttt{i}}\\
= \begin{cases}
\texttt{1} &amp; \text{ if an orange juice } \texttt{i} \text{ is } \texttt{Minute Maid};\\\\
\texttt{0} &amp; \text{otherwise}.\qquad\qquad\quad\,
\end{cases}
$$


---
# Log-Log Linear Regression
### &lt;p style="color:#00449E"&gt; Estimating Price Elasticity

- The following model estimates the price elasticity of demand for a carton of OJ:

`$$\log(\texttt{sales}_{\texttt{i}}) \,=\, \quad\;\; b_{\texttt{intercept}} \,+\, b_{\,\texttt{mm}}\,\texttt{brand}_{\,\texttt{mm}, \texttt{i}} \,+\, b_{\,\texttt{tr}}\,\texttt{brand}_{\,\texttt{tr}, \texttt{i}}\\
 \,+\, b_{\texttt{price}}\,\log(\texttt{price}_{\texttt{i}}) \,+\, e_{\texttt{i}}$$`

- When `\(\texttt{brand}_{\,\texttt{tr}, \texttt{i}}\,=\,0\)` and `\(\texttt{brand}_{\,\texttt{mm}, \texttt{i}}\,=\,0\)`, the beta coefficient for the intercept `\(b_{\texttt{intercept}}\)` gives the value of Dominick's log sales at `\(\log(\,\texttt{price[i]}\,) = 0\)`.

- The beta coefficient `\(b_{\texttt{price}}\)` is the price elasticity of demand.
  - It measures how sensitive the quantity demanded is to its price.


---
# Log-Log Linear Regression
### &lt;p style="color:#00449E"&gt; Estimating Price Elasticity

- For small changes in variable `\(x\)` from `\(x_{0}\)` to `\(x_{1}\)`, the following equation holds: 
  
`$$\Delta \log(x) \,= \, \log(x_{1}) \,-\, \log(x_{0}) 
\approx\, \frac{x_{1} \,-\, x_{0}}{x_{0}} 
\,=\, \frac{\Delta\, x}{x_{0}}.$$`

- The coefficient on `\(\log(\texttt{price}_{\texttt{i}})\)`, `\(b_{\texttt{price}}\)`, is therefore

`$$b_{\texttt{price}} \,=\, \frac{\Delta \log(\texttt{sales}_{\texttt{i}})}{\Delta \log(\texttt{price}_{\texttt{i}})}\,=\, \frac{\frac{\Delta \texttt{sales}_{\texttt{i}}}{\texttt{sales}_{\texttt{i}}}}{\frac{\Delta \texttt{price}_{\texttt{i}}}{\texttt{price}_{\texttt{i}}}}.$$`

- All else being equal, an increase in `\(\texttt{price}\)` by 1% is associated with a decrease in `\(\texttt{sales}\)` by `\(b_{\texttt{price}}\)`%.




---
# Log-Log Linear Regression
### &lt;p style="color:#00449E"&gt; EDA


.pull-left[
- Describe the relationship between `brand` and `log(price)`.


```r
ggplot(dtrain,
       aes( x = [?], y = [?], 
            fill = [?]) ) +
  geom_boxplot()
```
]


.pull-right[
- Describe the relationship between `log(price)` and `log(sales)` by `brand`.


```r
ggplot(dtrain,
       aes(x = [?], y = [?], 
           color = [?])) +
  geom_point([?]) +
  geom_smooth(method = [?])
```
]



---
# Log-Log Linear Regression
### &lt;p style="color:#00449E"&gt; Estimating Price Elasticity

- Let's train the first model, `model_1`:

`$$\log(\texttt{sales}_{\texttt{i}}) \,=\, \quad\;\; b_{\texttt{intercept}} \,+\, b_{\,\texttt{mm}}\,\texttt{brand}_{\,\texttt{mm}, \texttt{i}} \,+\, b_{\,\texttt{tr}}\,\texttt{brand}_{\,\texttt{tr}, \texttt{i}}\\
 \,+\, b_{\texttt{price}}\,\log(\texttt{price}_{\texttt{i}}) \,+\, e_{\texttt{i}}$$`
 

```r
model_1 &lt;- lm([?], data = dtrain)
```



---
# Log-Log Linear Regression
### &lt;p style="color:#00449E"&gt; Estimating Price Elasticity

- Here is the inverse demand curve for each brand OJ: 

.pull-left[
![](DANL200_Lec24_20230504_files/figure-html/unnamed-chunk-12-1.png)&lt;!-- --&gt;
]

.pull-left[
- The linear demand curve for OJ is determined by its slope and intercept.

- When `\(\texttt{brand}_{\,\texttt{tr}, \texttt{i}}\,=\,0\)` and `\(\texttt{brand}_{\,\texttt{mm}, \texttt{i}}\,=\,0\)`, the beta coefficient `\(b_{\texttt{intercept}}\)` gives the value of Dominick's log sales at `\(\log(\,\texttt{price[i]}\,) = 0\)`.
 
]





---
# Log-Log Linear Regression
### &lt;p style="color:#00449E"&gt; Estimating Price Elasticity

- How does the relationship between `log(sales)` and `log(price)` vary by `brand`?

  - Let's train the second model, `model_2`, that addresses the above question:

`$$\log(\texttt{sales}_{\texttt{i}}) \,=\, \quad b_{\texttt{intercept}} \,+\, b_{\,\texttt{mm}}\,\texttt{brand}_{\,\texttt{mm}, \texttt{i}} \,+\, b_{\,\texttt{tr}}\,\texttt{brand}_{\,\texttt{tr}, \texttt{i}}\\
 \,+\, b_{\texttt{price}}\,\log(\texttt{price}_{\texttt{i}})  \\
 \qquad\qquad\qquad\,+\, b_{\texttt{price*mm}}\,\log(\texttt{price}_{\texttt{i}})\,\times\,\color{Green} {\texttt{brand}_{\,\texttt{mm}, \texttt{i}}} \\
 \qquad\qquad\qquad\qquad +\, b_{\texttt{price*tr}}\,\log(\texttt{price}_{\texttt{i}})\,\times\,\color{Blue} {\texttt{brand}_{\,\texttt{tr}, \texttt{i}}} \,+\, e_{\texttt{i}}$$`
 

```r
model_2 &lt;- lm([?], data = dtrain)
```


---
# Log-Log Linear Regression


- For `\(\texttt{i}\)` such that `\(\color{Green}{\texttt{brand}_{\,\texttt{mm}, \texttt{i}}} = 0\)` and `\(\color{Blue}{\texttt{brand}_{\,\texttt{tr}, \texttt{i}}} = 0\)`, the model equation is:
`$$\log(\texttt{sales}_{\texttt{i}}) \,=\, \; \,b_{\texttt{intercept}}\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\\
\,+\, b_{\texttt{price}} \,\log(\texttt{price}_{\texttt{i}}) \,+\, e_{\texttt{i}}\,.\qquad\qquad\;$$`


- For `\(\texttt{i}\)` such that `\(\color{Green}{\texttt{brand}_{\,\texttt{mm}, \texttt{i}}} = 1\)`, the model equation is:
`$$\log(\texttt{sales}_{\texttt{i}}) \,=\, \; (\,b_{\texttt{intercept}} \,+\, b_{\,\texttt{mm}}\,)\qquad\qquad\qquad\qquad\qquad\qquad\qquad\\
\!\,+\,(\, b_{\texttt{price}} \,+\, \color{Green}{b_{\texttt{price*mm}}}\,)\,\log(\texttt{price}_{\texttt{i}}) \,+\, e_{\texttt{i}}\,.$$`


- For `\(\texttt{i}\)` such that `\(\color{Blue}{\texttt{brand}_{\,\texttt{tr}, \texttt{i}}} = 1\)`, the model equation is:
`$$\log(\texttt{sales}_{\texttt{i}}) \,=\, \; (\,b_{\texttt{intercept}} \,+\, b_{\,\texttt{tr}}\,)\qquad\qquad\qquad\qquad\qquad\qquad\qquad\\
\!\,+\,(\, b_{\texttt{price}} \,+\, \color{Blue}{b_{\texttt{price*tr}}}\,)\,\log(\texttt{price}_{\texttt{i}}) \,+\, e_{\texttt{i}}\,.$$`



---
# Log-Log Linear Regression
### &lt;p style="color:#00449E"&gt; Estimating Price Elasticity

- Here are the inverse demand curves from `model_1` and `model_2`: 

.pull-left[
![](DANL200_Lec24_20230504_files/figure-html/unnamed-chunk-14-1.png)&lt;!-- --&gt;

]

.pull-right[
![](DANL200_Lec24_20230504_files/figure-html/unnamed-chunk-15-1.png)&lt;!-- --&gt;

]

- Model 2 assumes that the price elasticity of OJ can vary by `brand`.




---
# Log-Log Linear Regression

- How does advertisement play a role in the relationship between sales and prices in the OJ market?

  - The ads can increase sales at all prices.

  - They can change price sensitivity.

  - They can do both of these things in a brand-specific manner.

- What would be the formula that address the question above?


---
# Log-Log Linear Regression
- Let's train the second model, `model_3`, that addresses the question in the previous page:

`$$\log(\texttt{sales}_{\texttt{i}}) \,=\, \quad b_{\texttt{intercept}} \,+\, b_{\,\texttt{mm}}\,\texttt{brand}_{\,\texttt{mm}, \texttt{i}} \,+\, b_{\,\texttt{tr}}\,\texttt{brand}_{\,\texttt{tr}, \texttt{i}}  \\
 \quad\,+\; b_{\,\texttt{ad}}\,\texttt{ad}_{\, \texttt{i}} \qquad\qquad\qquad\qquad\quad   \\
\qquad\qquad\qquad\,+\, b_{\texttt{mm*ad}}\,\color{Green} {\texttt{brand}_{\,\texttt{mm}, \texttt{i}}}\,\times\, \color{Violet}{\texttt{ad}_{\,\texttt{i}}}\,+\, b_{\texttt{tr*ad}}\,\color{Blue} {\texttt{brand}_{\,\texttt{tr}, \texttt{i}}}\,\times\, \color{Violet}{\texttt{ad}_{\,\texttt{i}}} \\
\,+\;  b_{\texttt{price}}\,\log(\texttt{price}_{\texttt{i}}) \qquad\qquad\qquad\;\;\;\;\,  \\
 \qquad\qquad\qquad\,+\, b_{\texttt{price*mm}}\,\log(\texttt{price}_{\texttt{i}})\,\times\,\color{Green} {\texttt{brand}_{\,\texttt{mm}, \texttt{i}}}\qquad\qquad\qquad\;\, \\
 \qquad\qquad\qquad\,+\, b_{\texttt{price*tr}}\,\log(\texttt{price}_{\texttt{i}})\,\times\,\color{Blue} {\texttt{brand}_{\,\texttt{tr}, \texttt{i}}}\qquad\qquad\qquad\;\, \\
\qquad\qquad +\, b_{\texttt{price*ad}}\,\log(\texttt{price}_{\texttt{i}})\,\times\,\color{Violet}{\texttt{ad}_{\,\texttt{i}}}\qquad\qquad\qquad\;\;\, \\
 \qquad\qquad\; +\, b_{\texttt{price*mm*ad}}\,\log(\texttt{price}_{\texttt{i}}) \,\times\,\,\color{Green} {\texttt{brand}_{\,\texttt{mm}, \texttt{i}}}\,\times\, \color{Violet}{\texttt{ad}_{\,\texttt{i}}} \\
 \qquad\qquad\qquad\;\;\; +\, b_{\texttt{price*tr*ad}}\,\log(\texttt{price}_{\texttt{i}}) \,\times\,\,\color{Blue} {\texttt{brand}_{\,\texttt{tr}, \texttt{i}}}\,\times\, \color{Violet}{\texttt{ad}_{\,\texttt{i}}}  \,+\, e_{\texttt{i}}$$`

 

---
# Log-Log Linear Regression

- The model with triple interactions can be trained as follows:


```r
model_3 &lt;- lm([?], data = dtrain)
```



---
# Log-Log Linear Regression
### &lt;p style="color:#00449E"&gt; Estimating Price Elasticity


- Here are the inverse demand curves from `model_3`:

.pull-left[
![](DANL200_Lec24_20230504_files/figure-html/unnamed-chunk-17-1.png)&lt;!-- --&gt;

]

.pull-right[
![](DANL200_Lec24_20230504_files/figure-html/unnamed-chunk-18-1.png)&lt;!-- --&gt;

]


---
# Log-Log Linear Regression
### &lt;p style="color:#00449E"&gt; Estimating Price Elasticity

- Describe the relationship between `ad` and `brand` using stacked bar charts.


.pull-left[
![](DANL200_Lec24_20230504_files/figure-html/unnamed-chunk-19-1.png)&lt;!-- --&gt;

]

.pull-right[
![](DANL200_Lec24_20230504_files/figure-html/unnamed-chunk-20-1.png)&lt;!-- --&gt;

]

- Model 3 assumes that the relationship between `price` and `sales` can vary by `ad`.




---
# Log-Log Linear Regression
### &lt;p style="color:#00449E"&gt; Estimating Price Elasticity




- How would you explain different estimation results across different models?

- Which model do you prefer? Why?

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "googlecode",
"highlightLines": true,
"highlightLanguage": "r",
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<!--Hat-tip: https://www.garrickadenbuie.com/blog/xaringan-tip-logo-all-slides/-->
<style>
.logo {
  background-image: url(img/logo-blue.png);
  background-size: contain;
  background-repeat: no-repeat;
  position: absolute;
  top: 1em;
  right: 1em;
  width: 55px;
  height: 66px;
  z-index: 0;
}
</style>

<script>
document
  .querySelectorAll(
    '.remark-slide-content' +
    ':not(.title-slide)' +
    // add additional classes to exclude here, e.g.
    ':not(.inverse)' +
    ':not(.hide-logo)'
  )
  .forEach(el => {
    el.innerHTML += '<div class="logo"></div>';
  });
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
