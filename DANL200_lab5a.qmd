---
title: "R Lab 5 - Linear Regression 1\nExample Answers"
author: "Byeong-Hak Choe"
---

```{r setup, include = FALSE}
library(knitr)
library(kableExtra)
library(ggthemes)
library(hrbrthemes)
library(tidyverse)
library(skimr)
library(stargazer)
library(broom)

knitr::opts_chunk$set(fig.width=8, fig.height=5)  

theme_set(theme_ipsum() +
          theme(strip.background =element_rect(fill="lightgray")))


```

## Loading R packages

```{r, eval = T, echo = T}
library(tidyverse)
library(skimr)
library(stargazer)
library(broom)
```


# Question 1

Read the data file, `bikeshare_cleaned.csv`, as the data.frame object with the name, `bikeshare`, using (1) the `read_csv()` function and (2) its URL, `https://bcdanl.github.io/data/bikeshare_cleaned.csv`.

```{r, message=F, warning=F}
url <- 'https://bcdanl.github.io/data/bikeshare_cleaned.csv'
bikeshare <- read_csv(url)
```

- `bikeshare` data.frame
```{r, result = 'asis', echo = F, message = F, warning = F}
rmarkdown::paged_table(bikeshare, 
                       options = list(cols.print = 5))
```

<br>

## Variable Description
- `cnt`: count of total rental bikes
- `year`: year
- `month`: month
- `date`: date
- `hr`: hours 
- `wkday`: week day
- `holiday`: holiday if `holiday == 1`; non-holiday otherwise
- `seasons`: season
- `weather_cond`: weather condition
- `temp`: temperature, measured in standard deviations from average.
- `hum`: humidity, measured in standard deviations from average.
- `windspeed`: wind speed, measured in standard deviations from average.

<br>

## Q1a
- From the `bikeshare` data.frame, convert variables `year`, `month`, `wkday`, `hr`, `seasons`, and `weather_cond` into factor variables.
  - Set `wkday` in order of '`sunday`', '`monday`', '`tuesday`', and so on.
  - Set `seasons` in order of '`spring`', '`summer`', '`fall`', and '`winter`'

```{r}
bikeshare <- bikeshare %>% 
  mutate( year = factor(year),
          month = factor(month),
          hr = factor(hr),
          weather_cond = factor(weather_cond), 
          wkday = factor(wkday, 
                         levels = c("sunday", "monday", "tuesday", "wednesday", 
                                    "thursday", "friday", "saturday") ),
          seasons = factor(seasons, 
                           levels = c("spring", "summer", "fall", "winter") ) 
  )

# to check the levels of the factor variables
levels(bikeshare$year)
levels(bikeshare$month)
levels(bikeshare$hr)
levels(bikeshare$weather_cond)
levels(bikeshare$wkday)
levels(bikeshare$seasons)
```


<br>

## Q1b
- Randomly divide the `bikeshare` data.frame into training and test data.frames, `dtrain` and `dtest`, respectively.
  - Make sure that you can replicate the randomization.
  - Approximately 70% of observations in `bikeshare` goes to `dtrain`.
  - The rest of observations in `bikeshare` goes to `dtest`.

```{r}
set.seed(2023)
rn <- runif(nrow(bikeshare))
dtrain <- filter(bikeshare, rn >= .3)
dtest <- filter(bikeshare, rn < .3)
```


<br>

## Q1c
- Use `dtrain` to train the five different linear regression models with `formula_1`, `formula_2`, `formula_3`, `formula_4`, and `formula_5`, respectively.

```{r}
formula_1 <- 
  cnt ~ temp + windspeed + weather_cond + hr + year 

formula_2 <- 
  cnt ~ hum + windspeed + weather_cond + hr + year 

formula_3 <- 
  cnt ~ temp + hum + windspeed + weather_cond + hr + year 

formula_4 <- 
  cnt ~ temp + hum + windspeed + weather_cond + hr + month + year

formula_5 <- 
  log(cnt) ~ temp + hum + windspeed + weather_cond + hr + month + year
```


```{r}
model_1 <- lm(formula_1, dtrain)
model_2 <- lm(formula_2, dtrain)
model_3 <- lm(formula_3, dtrain)
model_4 <- lm(formula_4, dtrain)
model_5 <- lm(formula_5, dtrain)

```

- Provide the summary of the regression results.
```{r, results='asis', echo = F}
stargazer(model_1, model_2, model_3, model_4, model_5, type = 'html')
```

```{r, eval = F, echo = F}
stargazer(model_1, model_2, model_3, model_4, model_5, type = 'text')
```


<br>

## Q1d
- In each model, which `hr` is most strongly associated with `cnt`?
- Interpret the beta estimate of that `hr`.

```{r}
sum_model_1 <- tidy(model_1) %>% 
  filter(str_detect(term, "hr")) %>% 
  arrange(-estimate) %>% 
  slice(1) %>% 
  mutate(model = 1) # to denote the model

sum_model_2 <- tidy(model_2) %>% 
  filter(str_detect(term, "hr")) %>% 
  arrange(-estimate) %>% 
  slice(1) %>% 
  mutate(model = 2) # to denote the model

sum_model_3 <- tidy(model_3) %>% 
  filter(str_detect(term, "hr")) %>% 
  arrange(-estimate) %>% 
  slice(1) %>% 
  mutate(model = 3) # to denote the model

sum_model_4 <- tidy(model_4) %>% 
  filter(str_detect(term, "hr")) %>% 
  arrange(-estimate) %>% 
  slice(1) %>% 
  mutate(model = 4) # to denote the model

sum_model_5 <- tidy(model_5) %>% 
  filter(str_detect(term, "hr")) %>% 
  arrange(-estimate) %>% 
  slice(1) %>% 
  mutate(model = 5) # to denote the model

sum_model <- rbind(sum_model_1, sum_model_2, sum_model_3, sum_model_4, sum_model_5)
```


```{r, result = 'asis', echo = F, message = F, warning = F}
rmarkdown::paged_table(sum_model, 
                       options = list(cols.print = 6))
```

- Across all the models, `hr17` is most strongly associated with `cnt`.

```{r}
ggplot(sum_model) +
  geom_pointrange( aes(x = model, 
                       y = estimate,
                       ymin = estimate - 2*std.error,
                       ymax = estimate + 2*std.error ) ) +
  coord_flip()
```

```{r}
ggplot(data = filter(sum_model,
                     model != 5)) +
  geom_pointrange( aes(x = model, 
                       y = estimate,
                       ymin = estimate - 2*std.error,
                       ymax = estimate + 2*std.error ) ) +
  coord_flip()
```

- In Model 4, all else being equal, hour `17` relative to hour `0` is associated with an increase in `cnt` by 380. 

- In Model 5, all else being equal, hour `17` relative to hour `0` is associated with an increase in `log(cnt)` by 2.16. 


<br>

## Q1e
- For each model, make a prediction on the outcome variable using the `dtest`.

```{r}

dtest <- dtest %>% 
  mutate(pred_1 = predict(model_1, dtest),
         pred_2 = predict(model_2, dtest),
         pred_3 = predict(model_3, dtest),
         pred_4 = predict(model_4, dtest),
         pred_5_log = predict(model_5, dtest),
         pred_5 = exp(predict(model_5, dtest))
  )
```


```{r, result = 'asis', echo = F, message = F, warning = F}
rmarkdown::paged_table(select(dtest, cnt, starts_with('pred')), 
                       options = list(cols.print = 8))
```
<br>

## Q1f
- Draw a residual plot for each model.
- Using the residual plots to answer the following questions:
  - On average, are the predictions correct in the models in Q1c?
  - Are there systematic errors?

```{r}
dtest_plot <- dtest %>% 
  select(cnt, starts_with('pred')) %>% 
  pivot_longer(cols = starts_with('pred'),
               names_to = 'model',
               values_to = 'pred')

# resitual plot
ggplot(data = filter(dtest_plot,
               model != 'pred_5_log'), 
       aes(x = pred, y = cnt - pred)) +
  geom_point(alpha = 0.05, color = "darkgray") +
  geom_smooth( color = "darkblue" ) +   
  geom_hline( aes( yintercept = 0 ),  # perfect prediction 
              color = "red", linetype = 2) + 
  geom_vline(aes(xintercept = 0), lty = 'dotted') +
  facet_wrap(. ~ model)
```
- On average, the predictions are correct up to the predicted value below 600.

- There are two systematic errors:
  - All the models have a cone-shape residual plot.
  - All the models except for Model 5 produces the predicted `cnt` below 0.


<br>

## Q1g
- Compare the prediction accuracy across the models in Q1c.
  - Which model do you prefer most and why?

- Here I calculate the root MSE, which is the square root of MSE.
  - RMSE summarizes the overall difference between the predicted and actual outcome values.
```{r}

RMSE <- dtest %>% 
  mutate(pred_1 = predict(model_1, dtest),
         pred_2 = predict(model_2, dtest),
         pred_3 = predict(model_3, dtest),
         pred_4 = predict(model_4, dtest),
         pred_5 = exp(predict(model_5, dtest)),
         resid_1_sq = (cnt - pred_1)^2,
         resid_2_sq = (cnt - pred_2)^2,
         resid_3_sq = (cnt - pred_3)^2,
         resid_4_sq = (cnt - pred_4)^2,
         resid_5_sq = (cnt - pred_5)^2
  ) %>% 
  summarize(rmse_1 = sqrt(mean(resid_1_sq)),
            rmse_2 = sqrt(mean(resid_2_sq)),
            rmse_3 = sqrt(mean(resid_3_sq)),
            rmse_4 = mean(resid_4_sq),
            rmse_5 = sqrt(mean(resid_5_sq))
  )

```
  

```{r, result = 'asis', echo = F, message = F, warning = F}
rmarkdown::paged_table(RMSE, 
                       options = list(cols.print = 8))
```

- I prefer Model 5 most.
  - Model 5 has the lowest MSE/RMSE so.
