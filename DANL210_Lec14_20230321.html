<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>DANL 210 Lecture 14</title>
    <meta charset="utf-8" />
    <meta name="author" content="Byeong-Hak Choe" />
    <meta name="date" content="2023-03-21" />
    <script src="libs/header-attrs-2.20/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <link href="libs/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.2.6/panelset.js"></script>
    <script src="libs/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <script src="libs/xaringanExtra-webcam-0.0.1/webcam.js"></script>
    <script id="xaringanExtra-webcam-options" type="application/json">{"width":"200","height":"200","margin":"1em"}</script>
    <script src="libs/js-cookie-3.0.0/js.cookie.js"></script>
    <script src="libs/peerjs-1.3.1/peerjs.min.js"></script>
    <script src="libs/tiny.toast-1.0.0/toast.min.js"></script>
    <link href="libs/xaringanExtra-broadcast-0.2.6/broadcast.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-broadcast-0.2.6/broadcast.js"></script>
    <link href="libs/shareon-1.4.1/shareon.min.css" rel="stylesheet" />
    <script src="libs/shareon-1.4.1/shareon.min.js"></script>
    <link href="libs/xaringanExtra-shareagain-0.2.6/shareagain.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-shareagain-0.2.6/shareagain.js"></script>
    <link href="libs/xaringanExtra-extra-styles-0.2.6/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <script src="libs/kePrint-0.0.1/kePrint.js"></script>
    <link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/nhsr.css" type="text/css" />
    <link rel="stylesheet" href="css/nhsr-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




class: title-slide, left, bottom

# DANL 210 Lecture 14
----
## **DANL 210: Data Preparation and Management**
### Byeong-Hak Choe
### March 21, 2023


---
# Announcement
### &lt;p style="color:#00449E"&gt; Graduate School Information Session

INTERESTED IN BEING A MORE PROFESSIONALLY QUALIFIED CANDIDATE ENTERING THE WORKFORCE?

Are you interested in pursuing grad school/MBA in the future?  
  - Attend the virtual Graduate School/MBA Information Session and learn more about finding a program suitable for you.
  - Specific information on the MBA and M.S. in Accounting/Finance/HR/Marketing/Data Analytics programs, the grad school application process, deciding whether to go now or later, preparing for and taking the GMAT, etc.
  
  

---
# Announcement
### &lt;p style="color:#00449E"&gt; Graduate School Information Session

Who will be there?  

- Prof. Jassawalla will discuss the application process, studying for the GMAT, different MBA formats (e.g. 4+1 MBA vs traditional 2-year MBA, part-time vs full-time MBA), top 50 MBA programs, etc.


  

---
# Announcement
### &lt;p style="color:#00449E"&gt; Graduate School Information Session

Who will be there?  


- Four guest speakers 
  - Three are currently in grad school (MBA programs in SUNY Binghamton, University of Rochester, and one is in Geneseo’s M.S. in Accounting program)
  - One is a Geneseo senior who has applied to multiple M.S. programs (e.g. M.S. in Human Resource Management at Stony Brook, Fordham, and St. Joseph’s University).  
  - The guest speakers will share their decision process and advice on applying to grad school.


---
# Announcement
### &lt;p style="color:#00449E"&gt; Graduate School Information Session

When and where? 
  - Friday, March 24, 2023, 11:30 a.m. to 12:30 p.m. via Zoom meeting



Join Zoom Meeting
  - [https://geneseo.zoom.us/j/87827705524?pwd=K0M5eHVDS2xldnBiRnNkc0Q3S1F5dz09](https://geneseo.zoom.us/j/87827705524?pwd=K0M5eHVDS2xldnBiRnNkc0Q3S1F5dz09)
  - Meeting ID: 878 2770 5524
  - Passcode: 917236


---
class: inverse, center, middle

# Groupby Operations: Split-Apply-Combine
&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=796px&gt;&lt;/html&gt;



---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt; 


Grouped operations are a powerful way to aggregate, transform, and filter data.:

  1. **Split**: DataFrame is split into separate groups based on values of variables we choose.
  2. **Apply**: A function is applied to each group of the DataFrame.
  3. **Combine**: The results from each group are combined to create a new DataFrame.


The split-apply-combine concept is used in any database management, cloud computing, or any other programming for data analysis.



---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt; Basic One-Variable Grouped Aggregation &lt;/p&gt;

**Aggregation** is the process of taking multiple values and returning a single value.


Aggregation may also be referred to as **summarization**.
  - When we calculate a summary statistic, such as the mean, we are taking multiple values and replacing them with a single value.


Let's consider the `gapminder` data set for practice.


```python
import pandas as pd
df = pd.read_csv('https://bcdanl.github.io/data/gapminder.tsv', sep='\t')
```


---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt; Built-in Aggregation/Transformation Methods &lt;/p&gt;

.panelset[
.panel[.panel-name[(1)]
&lt;table class=" lightable-paper table table-hover table-condensed" style='font-family: "Arial Narrow", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto; font-family: sans-serif, helvetica, arial; margin-left: auto; margin-right: auto;'&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Pandas.Method &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Description &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; .min() &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Minimum values &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; .quantile(q = .25) &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 25th percentile of the values &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; .quantile(q = .5) &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Median values &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; .quantile(q = .75) &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 75th percentile of the values &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; .max() &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Maximum values &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]


.panel[.panel-name[(2)]
&lt;table class=" lightable-paper table table-hover table-condensed" style='font-family: "Arial Narrow", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto; font-family: sans-serif, helvetica, arial; margin-left: auto; margin-right: auto;'&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Pandas.Method &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Description &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; .count() &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Frequency count not including NaN values &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; .size() &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Frequency count with NaN values &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; .sum() &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Sum of the values &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; .mean() &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Mean of the values &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; .std() &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Sample standard deviation &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; .var() &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Variance &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]


.panel[.panel-name[(3)]
&lt;table class=" lightable-paper table table-hover table-condensed" style='font-family: "Arial Narrow", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto; font-family: sans-serif, helvetica, arial; margin-left: auto; margin-right: auto;'&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Pandas.Method &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Description &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; .first() &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Returns the first row &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; .last() &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Returns the last row &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; .nth() &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Returns the n-th row (starting from 0-th) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

.panel[.panel-name[(4)]

We know we can calculate multiple summary statistics simultaneously with `.describe()`.


```python
# group by continent and describe each group
continent_describe = df.groupby('continent')["lifeExp"].describe()
continent_describe
```


]
  
]
---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt;  Aggregation Functions &lt;/p&gt;

####  Functions From Other Libraries

We can also use other libraries' functions that are not listed in the previous tables. (e.g., `numpy`, `scipy`)


```python
# calculate the average life expectancy by continent
# but use the np.mean function
cont_le_agg = df.groupby('continent')["lifeExp"].agg(np.mean)
```

**Q**. Add a new variable, the log of `lifeExp`, using `np.log` to DataFrame `df`.


---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt;  Aggregation Functions &lt;/p&gt;


.panelset[
.panel[.panel-name[(1)]
Sometimes we may want to perform a calculation that is not provided by Pandas or another library.

- Let’s create our own mean function with `def`.

```python
def my_mean(values):
  n = len(values)    # get the total number of numbers for the denominator
  sum = 0   # start the sum at 0
  for value in values:
      sum += value   # add each value to the running sum
  return sum / n   # return the summed values divided by the number of values
```

]


.panel[.panel-name[(2)]

We can pass our custom function straight into the `.agg()` method with `my_mean`.

```python
# use our custom function into agg
agg_my_mean = df.groupby('year')["lifeExp"].agg(my_mean)

agg_my_mean
```

]



.panel[.panel-name[(3)]
We can write functions that take multiple parameters.

```python
def my_mean_diff(values, diff_value):
    """Difference between the mean and diff_value
    """
    n = len(values)
    sum = 0
    for value in values:
        sum += value
    mean = sum / n
    return(mean - diff_value)
```

]


.panel[.panel-name[(4)]
Using `my_mean_diff`, we will calculate the global average life expectancy, `diff_value`, and subtract it from each grouped value.


```python
# custom aggregation function with multiple parameters
agg_mean_diff = (
  df
  .groupby("year")["lifeExp"]
  .agg(my_mean_diff, diff_value = global_mean)
)
```


]


.panel[.panel-name[(5)]

When we want to calculate multiple functions, we can pass the multiple functions into `.agg()`
 

```python
# calculate the count, mean, std of the lifeExp by continent
gdf = (
  df
  .groupby("year")
  ["lifeExp"]
  .agg([np.count_nonzero, np.mean, np.std])
)
```

]

]




---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt;  Use a dict in `.agg()` on a `Series` &lt;/p&gt;

We can also pass `.agg()` a Python dictionary (`{key : value}`). 
  - The results will differ depending on whether we are aggregating directly on a `DataFrame` or on a `Series` object.
    - When specifying a `dict` on a grouped `DataFrame`, the `keys` are the columns of the `DataFrame`, and the `values` are the functions used in the aggregated calculation.


```python
gdf_dict = df.groupby("year").agg(
  {"lifeExp": "mean",
    "pop": "median",
    "gdpPercap": "median"})
```



---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt;  Use a dict in `.agg()` on a `DataFrame` &lt;/p&gt;

To have user-defined column names in the output of a grouped series calculation, we need to rename those columns.

.pull-left[

```python
gdf = (
  df
  .groupby("year")
  ["lifeExp"]
  .agg(
    [
      np.count_nonzero,
      np.mean,
      np.std,
    ]
  )
```

]
.pull-right[

```python
  .rename(
    columns={
      "count_nonzero": "count",
      "mean": "avg",
      "std": "std_dev",
    }
  )
  .reset_index() # return a flat dataframe
)
```

]




---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt; Transform &lt;/p&gt;

When we transform data, we pass values from our dataframe into a function.
  
  - The function then “transforms” the data. 
  
  - Unlike `.agg()`, which can take multiple values and return a single (aggregated) value, `.transform()` takes multiple values and returns a one-to-one transformation of the values. 
  
  - That is, it does not reduce the amount of data.
  

---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt; Transform (cont.) &lt;/p&gt;  
-  Let’s calculate the z-score of our life expectancy data by year.
$$
z = \frac{x - \mu}{\sigma}
$$

  - `\(x\)` is a value in a variable
  - `\(\mu\)` is the average of a variable
  - `\(\sigma\)` is the standard deviation of a variable
  
$$
\sigma = \sqrt{\frac{1}{n}\sum_{i = 1}^{n}(x - \mu)^{2}}
$$





---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt; Transform (cont.) &lt;/p&gt;  

The following is a function, `my_zscore(x)`, that calculates a z-score using Pandas methods.


```python
def my_zscore(x):
  '''Calculates the z-score of provided data
  'x' is a vector or series of values
  '''
  return((x - x.mean()) / x.std())
```



---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt; Transform (cont.) &lt;/p&gt;  

Now we can use this function to `.transform()` our data by group.


```python
transform_z = df.groupby('year')["lifeExp"].transform(my_zscore)
```


- Note that both `df` and `transform_z` have the same number of rows and data.


```python
df.shape
transform_z.shape
```





---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt; `agg`, `transform`, and `apply`: when to use each with a `groupby` &lt;/p&gt;  

With all of the different options available, it can be confusing to know when to use the different functions available for performing `groupby` operations, namely: `.agg`, `.transform`, and `.apply`. 


Here are the key points to remember:
  - Use `.agg` when using a `groupby`, but you want your groups to become the new index.
  - Use `.transform` when using a `groupby`, but you want to retain your original index.
  - Use `.apply` when using a `groupby`, but you want to perform operations that will leave neither the original index nor an index of groups.



---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt; `agg`, `transform`, and `apply`: when to use each with a `groupby` &lt;/p&gt;  

Compare the output from `agg()`, `transform()`, and `apply()`:

.panelset[
.panel[.panel-name[(1)]

```python
# Set seed for random numbers
seed_for_prng = 78557
prng = np.random.default_rng(seed_for_prng)  # prng = random numbers 
data_index = np.repeat( np.arange(0,100,1) , 10 )

s = pd.Series(index= data_index, 
              data = prng.integers(-10, 10, size = 1000 ) )
```


]

.panel[.panel-name[(2)]

```python
s
s_agg = s.groupby(s.index).agg("mean")
s_transform = s.groupby(s.index).transform("mean")
s_apply = s.groupby(s.index).apply("mean")
s_apply2 = s.groupby(s.index).apply(lambda x: x[x&gt;0].cumsum())
```


]



.panel[.panel-name[(3)]


```python
iris = sns.load_dataset("iris")
def f(x):
    print(type(x))
    print(x.head(3))
    return 1

by_species = iris.groupby('species')
by_species_apply = by_species.apply(f)
by_species_agg = by_species.agg(f)
```



]
.panel[.panel-name[(4)]

`.apply()` applies the function to each group (your species). Our function returns 1, so we end up with 1 value for each of 3 groups.

`.agg()` aggregates each column (variable) for each group, so we end up with one value per column per group.

]


]


---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt;   `.filter()` &lt;/p&gt;  

`.filter()` allows us to split our data by keys, and then perform some kind of boolean subsetting on the data.


-  Let’s work with the `tips` data set from `seaborn`:


```python
import seaborn as sns
tips = sns.load_dataset('tips')

# note the number of rows in the original data
tips.shape


# look at the frequency counts for the table size
tips['size'].value_counts()
```




---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt;   `.filter()`  (cont.) &lt;/p&gt;  

Suppose we want each group to consist of 30 or more observations.
  - To accomplish this goal, we can use the `.filter()` method on **a grouped operation**.


```python
# filter the data such that each group has more than 30 observations
tips_filtered = (
  tips
  .groupby("size")
  .filter( lambda x : x["size"].count() &gt;= 30 )
)

tips_filtered.shape
tips_filtered['size'].value_counts()
```


---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt;  Iterating Through Groups &lt;/p&gt; 
- Another benefit of saving just the `groupby` object is that we can then iterate through the groups individually.

- We can iterate through our grouped values just like any other container (e.g., `list`, `dictionary`) in Python using a `for`-loop.


```python
for sex_group in grouped:
    print(sex_group)
    
# we can't really get the 0 element from the grouped object
print(grouped[0])
```


---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt;  Iterating Through Groups (cont.) &lt;/p&gt; 

- Let’s modify the for loop to just show the first element, along with some of the things we get when we loop over the `grouped` object.

.pull-left[

```python
for sex_group in grouped:
    type(sex_group) # tuple
    len(sex_group) # length 

    # get the first element
    first_element = sex_group[0]
    first_element
    type(sex_group[0])
```
]

.pull-right[

```python
    # get the second element
    second_element = sex_group[1]
    second_element
    type(second_element)

    # print what we have
    print(f'what we have:')
    print(sex_group)

    # stop after first iteration
    break
```
]



---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt;  Iterating Through Groups (cont.) &lt;/p&gt; 

- The option of iterating through groups with `for`-loop is available for us if we need to iterate through the groups one at a time.



---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt;  Multiple Groups &lt;/p&gt; 

- We can add multiple variables to the `.groupby()`


```python
import seaborn as sns
tips_10 = sns.load_dataset('tips').sample(10, random_state = 42)

# mean by sex and time
bill_sex_time = tips_10.groupby(['sex', 'time'])

group_avg = bill_sex_time.mean()
```


---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt;   Flattening the Results (`.reset_index()`) &lt;/p&gt; 

-  Let’s look at the type of the `group_avg` we just calculated.


```python
type(group_avg)
```

- If we look at the `columns` and the `index`, we get what we expect.

```python
group_avg.columns
group_avg.index
```


---
# Groupby Operations: Split-Apply-Combine
### &lt;p style="color:#00449E"&gt;   Flattening the Results (`.reset_index()`) &lt;/p&gt; 

- If we want to get a regular flat DataFrame back, we can call the `.reset_index()` method on the results.


```python
group_method = tips_10.groupby(['sex', 'time']).mean().reset_index()
group_method
```

-  Alternatively, we can use the `as_index = False` parameter in the `.groupby()` method (it is `True` by default).


```python
group_param = tips_10.groupby(['sex', 'time'], as_index=False).mean()
group_param
```




---
class: inverse, center, middle

# Tidy Data
&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=796px&gt;&lt;/html&gt;



---
# Tidy Data
### &lt;p style="color:#00449E"&gt;  &lt;/p&gt; 


&lt;img src="lec_figs/tidy-1.png" width="80%" style="display: block; margin: auto;" /&gt;

- In a tidy `data.frame`,
  - A **variable** is in a column.
  - An **observation** is in a row. 
  - A **value** are in a cell.
  
  
Tidy data is a framework to structure data sets so they can be easily analyzed and visualized. 



  
---
# Tidy Data
### &lt;p style="color:#00449E"&gt; Columns Contain Values, Not Variables &lt;/p&gt; 

Data can have columns that contain values instead of variables.

- Let's consider data on income and religion in the United States from the Pew Research Center


```python
import pandas as pd
pew = pd.read_csv('https://bcdanl.github.io/data/pew.csv')
```

- Not every column here is a variable. 
  - The values that relate to income are spread across multiple columns.


For data analysis, the `pew` can be reshaped so that we have `religion`, `income`, and `count` variables.


  
---
# Tidy Data
### &lt;p style="color:#00449E"&gt; Columns Contain Values, Not Variables &lt;/p&gt; 


```python
# Show only the first few columns
pew.iloc[:,0:5]
```


The form of the data like `pew` is known as “wide” data. 
  - To turn it into the “long” tidy data format, we will have to `melt` our DataFrame.
  


---
# Tidy Data
### &lt;p style="color:#00449E"&gt;  &lt;/p&gt; 


Pandas DataFrames have a method called `.melt()` that will reshape the DataFrame into a tidy format and it takes a few parameters:
- `id_vars` is a container (list, tuple, ndarray) that represents the variables that will remain as is.
- `value_vars` identifies the columns you want to melt down (or unpivot). 
  - By default, it will melt all the columns not specified in the `id_vars` parameter.
- `var_name` is a string for the new column name when the `value_vars` is melted down. 
  - By default, it will be called `variable`.
- `value_name` is a string for the new column name that represents the values for the `var_name`. 
  - By default, it will be called `value`.
  
  
  

---
# Tidy Data
### &lt;p style="color:#00449E"&gt; Columns Contain Values, Not Variables &lt;/p&gt; 

.panelset[
.panel[.panel-name[(1)]

```python
# we do not need to specify a value_vars since we want to pivot
# all the columns except for the 'religion' column
pew_long = pew.melt(id_vars='religion')
pew_long

# The .melt() method also exists as a pandas function, pd.melt()
# The below line of code is the equivalent one:
# melt function
pew_long = pd.melt(pew, id_vars='religion')
```

]

.panel[.panel-name[(2)]
- We can change the defaults so that the melted/unpivoted columns are named.

```python
pew_long = pew.melt(
  id_vars ="religion", var_name="income", value_name ="count"
)

pew_long
```
]

]

---
# Tidy Data
### &lt;p style="color:#00449E"&gt;  Keep Multiple Columns Fixed &lt;/p&gt; 

.panelset[
.panel[.panel-name[(1)]
Not every data set will have one column to hold still while we unpivot the rest of the columns. 
  - Let's consider the Billboard data set.


```python
billboard = pd.read_csv('https://bcdanl.github.io/data/billboard.csv')
```

Each week has its own column. 
  - What if we want to create a faceted plot of the weekly ratings?


]

.panel[.panel-name[(2)]

```python
# use a list to reference more than 1 variable
billboard_long = billboard.melt(
  id_vars = ["year", "artist", "track", "time", "date.entered"],
  var_name = "week",
  value_name = "rating",
)
```

**Q**. Describe how the distribution of rating varies across week 1 and week 2 using the faceted histogram.
]

]



---
# Tidy Data
### &lt;p style="color:#00449E"&gt; Columns Contain Multiple Variables &lt;/p&gt; 

.panelset[
.panel[.panel-name[(1)]

Sometimes columns in a data set may represent multiple variables. 
  - Let’s look at the Ebola data set.



```python
ebola = pd.read_csv('https://bcdanl.github.io/data/country_timeseries.csv')
ebola.columns
ebola.iloc[ :5, [0, 1, 2, 10] ]
```




]

.panel[.panel-name[(2)]

The column names `Cases_Guinea` and `Deaths_Guinea` actually contain two variables.
  - The individual status (cases and deaths, respectively) as well as the country name, Guinea. 
- The data is also arranged in a wide format that needs to be reshaped (with the `.melt()` method).
  - First, let’s fix the problem by melting the data into long format.



```python
ebola_long = ebola.melt(id_vars=['Date', 'Day'])
```

]

.panel[.panel-name[(3)]
- In this case, we can split the column of interest based on the underscore, `_`.
  - We can use the `.split()` method that takes a string and “splits” it up based on a given delimiter.
  -  To get access to the string methods, we need to use the `.str.` attribute.
  

```python
# split the column based on a delimiter
variable_split = ebola_long.variable.str.split('_')
variable_split
type(variable_split); type(variable_split[0])
```

]

.panel[.panel-name[(4)]
- Now that the column has been split into various pieces, the next step is to assign those pieces to a new column. 
  - To do so, we can use the `.get()` string method to “get” the index we want for each row.
  

```python
status_values = variable_split.str.get(0)
country_values = variable_split.str.get(1)
```

]
.panel[.panel-name[(5)]
- Now that we have the vectors we want, we can add them to our DataFrame.
  

```python
ebola_long['status'] = status_values
ebola_long['country'] = country_values
ebola_long
```

]

.panel[.panel-name[(6)]
- In the `.split()` method, there is a parameter `expand` that defaults to `False`.
  - When we set it to `True`, it will return a `DataFrame` where each result of the split is in separate columns.

```python
# reset our ebola_long data
ebola_long = ebola.melt(id_vars =['Date', 'Day'])
# split the column by _ into a dataframe using expand
variable_split = ebola_long.variable.str.split('_', expand=True)

ebola_long[['status', 'country']] = variable_split
```


]


]


---
# Tidy Data
### &lt;p style="color:#00449E"&gt; Variables in Both Rows and Columns &lt;/p&gt; 

.panelset[
.panel[.panel-name[(1)]

What happens if a column of data actually holds two variables instead of one variable?
  -  In this case, we will have to `pivot` the variable into separate columns, i.e., go from "long" data to "wide" data.


```python
weather = pd.read_csv('https://bcdanl.github.io/data/weather.csv')
```


]

.panel[.panel-name[(2)]

The weather data include minimum (`tmin`) and maximum (`tmax`) temperatures recorded for each day (`d1`, `d2`, ... , `d31`) of the month (`month`).
  - The `element` column contains variables that may need to be pivoted wider to become new columns, 
  - The day variables may need to be melted into row values.
  

Let’s first fix the day values.

```python
weather_melt = weather.melt(
  id_vars=["id", "year", "month", "element"],
  var_name="day",
  value_name="temp",
)
```

]

.panel[.panel-name[(3)]

Next, we need to pivot up the variables stored in the element column.


```python
weather_tidy = weather_melt.pivot_table(
    index=['id', 'year', 'month', 'day'],
    columns='element',
    values='temp'
)
```

]

.panel[.panel-name[(4)]
We can also flatten the hierarchical columns.

```python
weather_tidy_flat = weather_tidy.reset_index()
```

]

.panel[.panel-name[(5)]
For `day` variable, we can replace 'd' with "". 
  - Then, convert `day` from string to integer.
  - Then, sort `weather_tidy_flat` by `['year', 'month', 'day']`.
  

```python
weather_tidy_flat['day'] = weather_tidy_flat.day.str.replace('d', "")
weather_tidy_flat['day'] = weather_tidy_flat['day'].astype(int)
weather_tidy_flat = weather_tidy_flat.sort_values(by = ['year', 'month', 'day'])
```

]

]


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "googlecode",
"highlightLines": true,
"highlightLanguage": "r",
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<!--Hat-tip: https://www.garrickadenbuie.com/blog/xaringan-tip-logo-all-slides/-->
<style>
.logo {
  background-image: url(img/logo-blue.png);
  background-size: contain;
  background-repeat: no-repeat;
  position: absolute;
  top: 1em;
  right: 1em;
  width: 55px;
  height: 66px;
  z-index: 0;
}
</style>

<script>
document
  .querySelectorAll(
    '.remark-slide-content' +
    ':not(.title-slide)' +
    // add additional classes to exclude here, e.g.
    ':not(.inverse)' +
    ':not(.hide-logo)'
  )
  .forEach(el => {
    el.innerHTML += '<div class="logo"></div>';
  });
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
