<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>DANL 210 Lecture 17</title>
    <meta charset="utf-8" />
    <meta name="author" content="Byeong-Hak Choe" />
    <meta name="date" content="2023-04-11" />
    <script src="libs/header-attrs-2.20/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <link href="libs/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.2.6/panelset.js"></script>
    <script src="libs/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <script src="libs/xaringanExtra-webcam-0.0.1/webcam.js"></script>
    <script id="xaringanExtra-webcam-options" type="application/json">{"width":"200","height":"200","margin":"1em"}</script>
    <script src="libs/js-cookie-3.0.0/js.cookie.js"></script>
    <script src="libs/peerjs-1.3.1/peerjs.min.js"></script>
    <script src="libs/tiny.toast-1.0.0/toast.min.js"></script>
    <link href="libs/xaringanExtra-broadcast-0.2.6/broadcast.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-broadcast-0.2.6/broadcast.js"></script>
    <link href="libs/shareon-1.4.1/shareon.min.css" rel="stylesheet" />
    <script src="libs/shareon-1.4.1/shareon.min.js"></script>
    <link href="libs/xaringanExtra-shareagain-0.2.6/shareagain.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-shareagain-0.2.6/shareagain.js"></script>
    <link href="libs/xaringanExtra-extra-styles-0.2.6/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <script src="libs/kePrint-0.0.1/kePrint.js"></script>
    <link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/nhsr.css" type="text/css" />
    <link rel="stylesheet" href="css/nhsr-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




class: title-slide, left, bottom

# DANL 210 Lecture 17
----
## **DANL 210: Data Preparation and Management**
### Byeong-Hak Choe
### April 11, 2023


---
# Announcement
### &lt;p style="color:#00449E"&gt; Changes in Syllabus  &lt;/p&gt; 

- There will be 3 more homework assignments.
  - The lowest homework score will be dropped when calculating the total homework score.
  - Each homework except for the homework with the lowest score accounts for 25% of the total homework score. 
  - When selecting the homework assignment with the lowest score, the project-type homework assignment is not considered.
  
  
  
- The due for the project-type homework assignment will be around the final week. 



---
class: inverse, center, middle

# Data Assembly
&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=796px&gt;&lt;/html&gt;



---
# Data Assembly
### &lt;p style="color:#00449E"&gt;   &lt;/p&gt; 

Sometimes, we better combine various DataFrames together to analyze a set of data.

  - The data may have been split up into separate DataFrames to reduce the amount of redundant information.

  - e.g., DataFrame for county-level data and DataFrame for geographic information, such as longitude and latitude




---
# Data Concatenation
### &lt;p style="color:#00449E"&gt;  &lt;/p&gt; 

Concatenation can be thought of as appending a row or column to our data. 
  - This approach is possible if our data was split into parts or if we performed a calculation that we want to append to our existing data set.
- Let's consider the following example DataFrames:

```python
df1 = pd.read_csv('https://bcdanl.github.io/data/concat_1.csv')
df2 = pd.read_csv('https://bcdanl.github.io/data/concat_2.csv')
df3 = pd.read_csv('https://bcdanl.github.io/data/concat_3.csv')
```


- We will be working with `.index` and `.columns` in this Section.

```python
df1.index
df1.columns
df1.values
```

---
# Data Concatenation
### &lt;p style="color:#00449E"&gt;  Add Rows &lt;/p&gt; 


Concatenating the DataFrames on top of each other uses the `concat()` function. 
  - All of the DataFrames to be concatenated are passed in a `list`.
  

```python
row_concat = pd.concat([df1, df2, df3])
row_concat
```

-  The row names (i.e., the row indices) are simply a stacked version of the original row indices.

```python
row_concat.iloc[3, :]
```

---
# Data Concatenation
### &lt;p style="color:#00449E"&gt;  Add Rows &lt;/p&gt; 

- Let's consider a new Series and concatenate it with `df1`:

```python
# create a new row of data
new_row_series = pd.Series(['n1', 'n2', 'n3', 'n4'])
new_row_series


# attempt to add the new row to a dataframe
df = pd.concat([df1, new_row_series])
df
```

-  Not only did our code not append the values as a row, but it also created a new column completely misaligned with everything else.
  - Why?


---
# Data Concatenation
### &lt;p style="color:#00449E"&gt;  Add Rows &lt;/p&gt; 


To fix the problem, we need turn our series into a DataFrame. 
  - This data frame contains one row of data, and the column names are the ones the data will bind to.


```python
new_row_df = pd.DataFrame(
  # note the double brackets to create a "row" of data
  data =[["n1", "n2", "n3", "n4"]],
  columns =["A", "B", "C", "D"],
)

df = pd.concat([df1, new_row_df])
```


---
# Data Concatenation
### &lt;p style="color:#00449E"&gt;   Ignore the Index &lt;/p&gt; 

- We can use the `ignore_index` parameter to reset the row index after the concatenation if we simply want to concatenate or append data together.


```python
row_concat_i = pd.concat([df1, df2, df3], ignore_index=True)
```


---
# Data Concatenation
### &lt;p style="color:#00449E"&gt;   Add Columns &lt;/p&gt; 


Concatenating columns is very similar to concatenating rows. 
  - The main difference is the `axis` parameter in the `concat` function. 
  - The default value of `axis` is `0` (or `axis = "index"`), so it will concatenate data in a row-wise fashion. 
  - If we pass `axis = 1` (or `axis = "columns"`) to the function, it will concatenate data in a column-wise manner.
  
  

```python
col_concat = pd.concat([df1, df2, df3], axis = "columns")
```


---
# Data Concatenation
### &lt;p style="color:#00449E"&gt;   Add Columns &lt;/p&gt; 

- Adding a single column to a dataframe can be done directly without using any specific  Pandas function.


```python
col_concat['new_col_list'] = ['n1', 'n2', 'n3', 'n4']
```


- We can reset the column indices so we do not have duplicated column names.


```python
pd.concat([df1, df2, df3], axis="columns", ignore_index=True)
```



---
# Data Concatenation
### &lt;p style="color:#00449E"&gt;  Concatenate with Different Indices &lt;/p&gt; 

What would happen when the row and column indices are not aligned?

- Let’s modify our DataFrames for the next few examples.

```python
# rename the columns of our dataframes
df1.columns = ['A', 'B', 'C', 'D']
df2.columns = ['E', 'F', 'G', 'H']
df3.columns = ['A', 'C', 'F', 'H']
```

-  If we try to concatenate these DataFrames as we did, the DataFrames now do much more than simply stack one on top of the other.

```python
row_concat = pd.concat([df1, df2, df3])
```



---
# Data Concatenation
### &lt;p style="color:#00449E"&gt;  Concatenate with Different Indices &lt;/p&gt; 

- We can set `join = 'inner'` to keep only the columns that are shared among the data sets.

```python
pd.concat([df1, df2, df3], join ='inner')
```


- If we use the DataFrames that have columns in common, only the columns that all of them share will be returned.

```python
pd.concat([df1, df3], join ='inner',  ignore_index =False)
```



---
# Data Concatenation
### &lt;p style="color:#00449E"&gt;  Concatenate with Different Indices &lt;/p&gt; 


- Let’s modify our DataFrames further.

```python
# re-indexing the rows of our dataframes
df1.index = [0, 1, 2, 3]
df2.index = [4, 5, 6, 7]
df3.index = [0, 2, 5, 7]
```



---
# Data Concatenation
### &lt;p style="color:#00449E"&gt;  Concatenate with Different Indices &lt;/p&gt; 


- When we concatenate along `axis="columns"` `(axis=1`), the new DataFrames will be added in a column-wise fashion and matched against their respective row indices.


```python
col_concat = pd.concat([df1, df2, df3], axis="columns")
```


- Just as we did when we concatenated in a row-wise manner, we can choose to keep the results only when there are matching indices by using `join="inner"`.

```python
pd.concat([df1, df3], axis ="columns", join='inner')
```




---
# Relational data
### &lt;p style="color:#00449E"&gt;   &lt;/p&gt; 

Why is one data set sometimes scattered across multiple files?
  - The size of the files can be huge.
  - The data collection process can be scattered across time and space.
 
 
Sometimes we may have two or more DataFrames (tables) that we want to combine based on common data values.
  -  This task is known in the database world as performing a “join.”
  -  We can do this with the `.merge()` method in Pandas.



---
# Relational data
### &lt;p style="color:#00449E"&gt;   &lt;/p&gt; 


-  The variables that are used to connect each pair of tables are called **keys**.

&lt;table class=" lightable-paper table table-hover table-condensed" style='font-family: "Arial Narrow", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto; font-family: sans-serif, helvetica, arial; margin-left: auto; margin-right: auto;'&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Pandas &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; SQL &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Description &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; left &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; left outer &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Keep all the observations from the left &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; right &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; right outer &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Keep all the observations from the right &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; outer &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; full outer &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Keep all the observations from both left and right &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;border-right:1px solid;"&gt; inner &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; inner &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Keep only the observations whose key values exist in both &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;



---
# Relational data
### &lt;p style="color:#00449E"&gt; Merges

&lt;img src="lec_figs/join-setup.png" width="20%" style="display: block; margin: auto;" /&gt;

.pull-left[

```python
x = pd.DataFrame({
    'key': [1, 2, 3],
    'val_x': ['x1', 'x2', 'x3']
})
```
]
.pull-right[

```python
y = pd.DataFrame({
    'key': [1, 2, 4],
    'val_y': ['y1', 'y2', 'y3']
})
```
]

- The colored column represents the "key" variable.
- The grey column represents the "value" column.


---
# Merges
### &lt;p style="color:#00449E"&gt; 

.panelset[
.panel[.panel-name[inner]
- An **inner join** matches pairs of observations whenever their keys are equal:

&lt;img src="lec_figs/join-inner.png" width="50%" style="display: block; margin: auto;" /&gt;


```python
# the default value for 'how' is 'inner'
# so it doesn't actually need to be specified
merge_inner = pd.merge(x, y, on='key', how='inner')
merge_inner_x = x.merge(y, on='key', how='inner')
merge_inner_x_how = x.merge(y, on='key')
```


]

.panel[.panel-name[left]

- A **left join** keeps all observations in `x`.

&lt;img src="lec_figs/join-left.png" width="50%" style="display: block; margin: auto;" /&gt;


```python
merge_left = pd.merge(x, y, on='key', how='left')
merge_left_x = x.merge(y, on='key', how='left')
```

- The most commonly used join is the left join.
]


.panel[.panel-name[right]

- A **right join** keeps all observations in `y`.

&lt;img src="lec_figs/join-right.png" width="50%" style="display: block; margin: auto;" /&gt;


```python
merge_right = pd.merge(x, y, on='key', how='right')
merge_right_x = x.merge(y, on='key', how='right')
```

]


.panel[.panel-name[outer full]

- A **full join** keeps all observations in `x` and `y`.

&lt;img src="lec_figs/join-full.png" width="50%" style="display: block; margin: auto;" /&gt;


```python
merge_outer = pd.merge(x, y, on='key', how='outer')
merge_outer_x = x.merge(y, on='key', how='outer')
```

]

]




---
# Merges
### &lt;p style="color:#00449E"&gt; Duplicate keys

.panelset[
.panel[.panel-name[one-to-many]
- One data frame has duplicate keys (a one-to-many relationship). 
&lt;img src="lec_figs/join-one-to-many.png" width="30%" style="display: block; margin: auto;" /&gt;

.pull-left[

```r
x = pd.DataFrame({
    'key': [1, 2, 3],
    'val_x': ['x1', 'x2', 'x3'] })
```

]
.pull-right[

```r
y = pd.DataFrame({
    'key': [1, 2, 4],
    'val_y': ['y1', 'y2', 'y3'] })
one_to_many = x.merge(y, on='key', how='left')
```

]


]

.panel[.panel-name[many-to-many]
- Both data frames have duplicate keys (many-to-many relationship).
&lt;img src="lec_figs/join-many-to-many.png" width="27.5%" style="display: block; margin: auto;" /&gt;


.pull-left[

```r
x = pd.DataFrame({
  'key': [1, 2, 2, 3],
  'val_x': ['x1', 'x2', 'x3', 'x4'] })
```

]

.pull-right[

```r
y = pd.DataFrame({
  'key': [1, 2, 2, 3],
  'val_y': ['y1', 'y2', 'y3', 'y4'] })
many_to_many = x.merge(y, on='key', how='left')
```
]

]
]




---
# Merges
### &lt;p style="color:#00449E"&gt; Defining the key columns

- If the left and right columns do not have the same name for the key columns, we can use the `left_on` and `right_on` parameters instead.

.pull-left[

```r
x = pd.DataFrame({
  'key_x': [1, 2, 3],
  'val_x': ['x1', 'x2', 'x3']
})
```
]

.pull-right[

```r
y = pd.DataFrame({
  'key_y': [1, 2],
  'val_y': ['y1', 'y2'] })

keys_xy = x.merge(y, 
                  left_on='key_x', 
                  right_on = 'key_y', 
                  how='left')
```
]



---
class:  center, middle

# Attendance Time

Let's have an attendance time.


---
class: inverse, center, middle

# Missing Data 
&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=796px&gt;&lt;/html&gt;


---
# Missing Data 
### &lt;p style="color:#00449E"&gt; 


Rarely will we be given a data set without any missing values.


Pandas usually displays missing values as `NaN`.
  - `NaN` is the actual representation of "Not a Number" values.
  - I would prefer calling it "Not Available" (`NA`), for which some other programming languages as well as Pandas use to represent missing values.
  

---
# Missing Data 
### &lt;p style="color:#00449E"&gt; 

- The `NaN` value in Pandas comes from Numpy.


```python
from numpy import NaN
NaN == True
NaN == 0
NaN == "
NaN == NaN
```


---
# Missing Data 
### &lt;p style="color:#00449E"&gt; 


- Pandas has functions to test for missing values, `isnull()`.
- Pandas also has functions for testing non-missing values, `notnull()`.


```python
import pandas as pd
pd.isnull(NaN)
pd.notnull(NaN)
pd.notnull(210)
pd.notnull('missing')
```



---
#  Where Can Missing Values Come From?
### &lt;p style="color:#00449E"&gt;  Load Data

.panelset[
.panel[.panle-name[read_csv()]
- When we load the data, Pandas automatically finds the missing data cell and give us a DataFrame with the `NaN` value in the appropriate cell. 

- In the `read_csv()` function, three parameters are related to reading missing values: `na_values`, `keep_default_na`, and `na_filter`.



]

.panel[.panle-name[(na_values)]
The `na_values` parameter allows us to specify additional missing or `NaN` values. 


  - We can pass in either a Python `str` (i.e., string) or a list-like object to be automatically coded as missing values when the file is read. 
  
  - E.g., Some health data may code `99` as a missing value; to specify the use of this value, we would set `na_values = [99]`.


]

.panel[.panle-name[(keep_default_na)]
The `keep_default_na` parameter is a `bool` (i.e., `True` or `False` boolean) that allows us to specify whether any additional values need to be considered as missing. 


- This parameter is `True` by default, meaning any additional missing values specified with the `na_values` parameter will be appended to the list of missing values `pd.read_csv` has. 


- `keep_default_na = False` will only use the missing values specified in `na_values`.


]


.panel[.panle-name[example]
- Let's read the CSV file, `survey_visited.csv`.


```python
path = 'https://bcdanl.github.io/data/survey_visited.csv'
survey_visited_0 = pd.read_csv(path)
survey_visited_1 = pd.read_csv(path, na_values = ["MSK-4"])
survey_visited_2 = pd.read_csv(path, keep_default_na = False)

survey_visited_0
survey_visited_1
survey_visited_2
```


]


]





---
#  Where Can Missing Values Come From?
### &lt;p style="color:#00449E"&gt;   Merged Data

- Let's merge `survey_visited_0` with `survey`.

```python
path = 'https://bcdanl.github.io/data/survey_survey.csv'
survey = pd.read_csv(path)
survey

vs = survey_visited_0.merge(survey, left_on='ident', right_on='taken')
vs
```



---
#  Where Can Missing Values Come From?
### &lt;p style="color:#00449E"&gt;  Reindexing


Another way to introduce missing values into our data is to reindex our dataframe. 

  - This is useful when we want to add new indices to your dataframe, but still want to retain its original values. 
  - A common usage is when the index represents some time interval, and we want to add more dates.
  

```python
gapminder = pd.read_csv('https://bcdanl.github.io/data/gapminder.tsv', sep='\t')
life_exp = gapminder.groupby(['year'])['lifeExp'].mean()
```


-  We can reindex the dataframe by using the `.reindex()` method.


```python
# subset
y2000 = life_exp[life_exp.index &gt; 2000]

# reindexing
y2000.reindex(range(2000, 2010))
```





---
#   Working With Missing Data
### &lt;p style="color:#00449E"&gt;  Find and Count Missing Data

.panelset[
.panel[.panel-name[.count()]
One way to look at the number of missing values is to `count()` them.


```python
ebola = pd.read_csv('https://bcdanl.github.io/data/country_timeseries.csv')
# count the number of non-missing values
ebola.count()
```

**Q**. Count the number of non-missing values for each variable in `ebola`.


]

.panel[.panel-name[np.count_nonzero()]
If we want to count the total number of missing values in our DataFrame, or count the number of missing values for a particular column, we can use the `np.count_nonzero()` function from numpy in conjunction with the `.isnull()` method.


```python
np.count_nonzero(ebola.isnull())
np.count_nonzero(ebola['Cases_Guinea'].isnull())
```



]

.panel[.panel-name[.value_counts(dropna=False)]

Another way to get missing data counts is to use the `.value_counts()` method, giving a frequency table of values in a Series. 
  - If we use the `dropna = False`, we can also get a missing value count.


```python
cnts = ebola['Cases_Guinea'].value_counts(dropna=False)
cnts
```

- The results are sorted so we can subset the count vector to just look at the missing values.


```python
cnts.loc[pd.isnull(cnts.index)]
```

]



.panel[.panel-name[.sum()]

- In Python, `True` values equate to the integer value 1, and `False` values equate to the integer value 0. 
  - We can use this behavior to get the number of missing values by summing up a boolean vector with the `.sum()` method.


```python
ebola.Cases_Guinea.isnull().sum()
```

]
]




---
#   Working With Missing Data
### &lt;p style="color:#00449E"&gt;   Clean Missing Data

.panelset[
.panel[.panel-name[Cleaning NaN]

There are many different ways we can deal with missing data. 
  1. We can replace the missing value with another value, 
  2. We can fill in the cells with the missing value using existing value, 
  3. We can drop the observations with missing values from our DataFrame.
]


.panel[.panel-name[.fillna()]
- We can use the `.fillna()` method to recode the missing values to another value.


```python
# fill the missing values to 0
ebola0 = ebola.fillna(0)
```

]


.panel[.panel-name[.fillna(method='ffill')]

- We can use built-in methods to fill forward (`method = ffill`).

  -  When we fill data forward, the last known value (from top to bottom) is used for the next missing value.
  


```python
ebola_f = ebola.fillna(method='ffill')
```

]


.panel[.panel-name[.fillna(method='bfill')]

- We can also use built-in methods to fill backward (`method = bfill`).

  -  When we fill data backward, the newest value (from top to bottom) is used to replace the missing data.


```python
ebola_b = ebola.fillna(method='bfill')
```

]


.panel[.panel-name[.interpolate()]
- Interpolation uses existing values to fill in missing values.
  - By default, `.interpolate()` treats the missing values as if they should be equally spaced apart.

```python
ebola_linear = ebola.interpolate()
```

- The `.interpolate()` method  behaves kind of in a forward fill fashion.

]


.panel[.panel-name[.dropna()]

If we want to keep the observations with only non-missing values, we can use `.dropna()`

```python
ebola_dropna = ebola.dropna()
```

We are left with just one row of data!
]


.panel[.panel-name[Calculation]

Suppose we wanted to look at the case counts for multiple regions. 

.pull-left[

```python
ebola["Cases_multiple"] = (
  ebola["Cases_Guinea"]
  + ebola["Cases_Liberia"]
  + ebola["Cases_SierraLeone"]
)
```
]

.pull-right[

```python
ebola_subset = ebola.loc[:,
    ["Cases_Guinea", 
     "Cases_Liberia", 
     "Cases_SierraLeone",
     "Cases_multiple"] ]
```
]  


]


.panel[.panel-name[skipna]

`.mean()` and `.sum()` can ignore missing values. 
  - These functions will typically have a `skipna` parameter that will still calculate a value by skipping over the missing values.


```python
ebola.Cases_Guinea.sum(skipna = True) # default
ebola.Cases_Guinea.sum(skipna = False)
```




]


]





---
#   Working With Missing Data
### &lt;p style="color:#00449E"&gt;    Pandas Built-In `NA` Missing

Pandas 1.0 introduced a built-in `&lt;NA&gt;` value (`pd.NA`).


```python
economists = pd.DataFrame(
  {
    "Name": ["John Forbes Nash", "William Nordhaus"],
    "Occupation": ["Mathematician", "Climate Economist"],
    "Born": ["1928-06-13", "1941-05-31"],
    "Died": ["2015-05-23", ""],
    "Age": [86, 81]
  }
)

economists.loc[1, "Age"] = pd.NA
```

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "googlecode",
"highlightLines": true,
"highlightLanguage": "r",
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<!--Hat-tip: https://www.garrickadenbuie.com/blog/xaringan-tip-logo-all-slides/-->
<style>
.logo {
  background-image: url(img/logo-blue.png);
  background-size: contain;
  background-repeat: no-repeat;
  position: absolute;
  top: 1em;
  right: 1em;
  width: 55px;
  height: 66px;
  z-index: 0;
}
</style>

<script>
document
  .querySelectorAll(
    '.remark-slide-content' +
    ':not(.title-slide)' +
    // add additional classes to exclude here, e.g.
    ':not(.inverse)' +
    ':not(.hide-logo)'
  )
  .forEach(el => {
    el.innerHTML += '<div class="logo"></div>';
  });
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
