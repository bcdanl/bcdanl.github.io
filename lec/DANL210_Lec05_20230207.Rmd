---
title: "DANL 210 Lecture 5"
subtitle: "DANL 210: Data Preparation and Management"
author: "Byeong-Hak Choe"
institute: "SUNY Geneseo"
date: "Febraury 7, 2023"
output:
  xaringan::moon_reader:
    css: 
      - default
      - css/nhsr.css
      - css/nhsr-fonts.css
    lib_dir: libs
    seal: false
    nature:
      highlightStyle: googlecode
      highlightLines: true
      highlightLanguage: ["r"]
      countIncrementalSlides: false
      ratio: "16:9"
    includes:
      after_body: [css/insert-logo.html]
---

```{r setup, include = FALSE}
library(knitr)
library(kableExtra)
library(tidyverse)
library(NHSRtheme)
library(fontawesome)
# set default options
opts_chunk$set(echo = T, eval = F,
               fig.width = 7.252,
               fig.height = 4,
               comment = "#",
               dpi = 300)

knitr::knit_engines$set("markdown")

xaringanExtra::use_tile_view()
xaringanExtra::use_panelset()
xaringanExtra::use_clipboard()
xaringanExtra::use_webcam()
xaringanExtra::use_broadcast()
xaringanExtra::use_share_again()
xaringanExtra::style_share_again(
  share_buttons = c("twitter", "linkedin", "pocket")
)


xaringanExtra::use_extra_styles(
  hover_code_line = TRUE,         #<<
  mute_unhighlighted_code = TRUE  #<<
)

# uncomment the following lines if you want to use the NHS-R theme colours by default
# scale_fill_continuous <- partial(scale_fill_nhs, discrete = FALSE)
# scale_fill_discrete <- partial(scale_fill_nhs, discrete = TRUE)
# scale_colour_continuous <- partial(scale_colour_nhs, discrete = FALSE)
# scale_colour_discrete <- partial(scale_colour_nhs, discrete = TRUE)
```

class: title-slide, left, bottom

# `r rmarkdown::metadata$title`
----
## **`r rmarkdown::metadata$subtitle`**
### `r rmarkdown::metadata$author`
### `r rmarkdown::metadata$date`


---
# Announcement

### <p style="color:#00449E">Tutoring and TA Hours</p>
.pull-left[
- Jack Gramlich ([jcg14@geneseo.edu](jcg14@geneseo.edu))
  - Friday 2:00 -- 4:00 pm
  - Saturday 2:00 -- 5:00 pm
  - Sunday 12:00 -- 3:00 pm
  

- Marcie Hogan ([mlh29@geneseo.edu](mlh29@geneseo.edu))
  - Sunday 2:00 -- 5:00 pm
]  
 
.pull-right[ 
- Emine Morris, TA ([ekm10@geneseo.edu](ekm10@geneseo.edu))
  - Saturday 1:00 – 3:00 pm
  
  
- Jason Rappazzo ([jjr18@geneseo.edu](jjr18@geneseo.edu))
  - Monday 9:00 – 11:30 am
  - Wednesday 9:00 – 11:30 am 
]  


---
# Workflow
### <p style="color:#00449E"> Shortcuts for Presentation Slides </p>
 
- Use `o` to see the tile view of all the slide pages.

- Use `r fa("arrow-left")` and `r fa("arrow-right")` to turn over the slide pages.


---
# Coding Workflow
### <p style="color:#00449E"> Shortcuts </p>
.pull-left[
### <p style="color:#00449E"> Mac </p>
- **F9** runs a current line (where the blinking cursor is) or selected lines.
- **command + return** runs a current block.
- **command + 1** is the shortcut for #.
- **command + 4** is the shortcut for block comment.
]

.pull-right[
### <p style="color:#00449E"> Windows </p>
- **F9** runs a current line (where the blinking cursor is) or selected lines.
- **Ctrl + Enter** runs a current block.
- **Ctrl + 1** is the shortcut for #.
- **Ctrl + 4** is the shortcut for block comment.
]


---
class: inverse, center, middle

# Getting started with `Pandas`

---
#  `Pandas`

- To give Python these enhanced features, Pandas introduces two new data types to Python: `Series` and `DataFrame`. 

  - The `DataFrame` will represent your entire spreadsheet or rectangular data.
  - The `Series` is like a single column of the `DataFrame`. 


---
#  `Pandas`
### <p style="color:#00449E">  Load Data Sets </p>

- With the library loaded we can use the `read_csv()` function to load a CSV data file.


- In order to access the `read_csv()` function from pandas, we use something called "dot" notation.
  - We write `pd.read_csv()` to say: within the pandas library we just loaded, look inside for the `read_csv()` function.

```{python, echo = T, eval = F}
import pandas as pd
# *.tsv is a file of tab-separated values.
# we can use the sep parameter and indicate a tab with \t
df  = pd.read_csv('https://bcdanl.github.io/data/gapminder.tsv', sep='\t')
df
```




---
# Look at Columns, Rows, and Cells
### <p style="color:#00449E">  Subset Rows </p>

- Rows can be subset in multiple ways, by row name or row index.


```{r, echo = F, eval = T, out.width='100%', fig.align='center'}
text_tbl <- data.frame(
  `Type` = c("df`.`loc[val]",
"df`.`iloc[where]"),
  `Description` = c("Select single row or set of rows",
"Select single row or set of rows by integer position")
  )


kable(text_tbl, format = "html") %>%
  kable_paper(full_width = T) %>%
  column_spec(1, bold = T, border_right = T) %>%
  kable_styling(html_font = 'sans-serif, helvetica, arial',
                bootstrap_options = c("hover", "condensed") )

```




---
# Look at Columns, Rows, and Cells
### <p style="color:#00449E">   Subset Rows by `index` Label: `.loc[]` </p>


.panelset[

.panel[.panel-name[Index]

- Let's take a look at our gapminder data:
```{python}
df
```

- We can see on the left side of the printed `DataFrame`, what appear to be row numbers.
  -  This column-less row of values is the "index" label of the `DataFrame`.


-  By default, Pandas fills in the index labels with the row numbers starting from 0.

]

.panel[.panel-name[`.loc[]`]
- We can use the `.loc[]` attribute on the `DataFrame` to subset rows based on the index label.

.pull-left[
```{python}
# get the first row
df.loc[0]

# get the 100th row
df.loc[99]
```
]
.pull-right[
```{python}
# get the last row
df.loc[ -1]
```
- Does `df.loc[ -1]` work?
]

]


.panel[.panel-name[last row]
- Here, passing -1 to the `.loc[]` causes an error.
  - It is actually looking for the row index label (i.e., row number -1), which does not exist in our example DataFrame.

```{python}
# use the first value given from shape to get the number of rows
number_of_rows = df.shape[0]
# subtract 1 from the value since we want the last index value
last_row_index = number_of_rows - 1

# finally do the subset using the index of the last row
df.loc[last_row_index]
```

]

.panel[.panel-name[.tail()]
- We can use the `.tail()` method to return the last `n = 1` row, instead of the default 5.
```{python}
df.tail(n = 1)
```

- Using `.tail()` and `.loc[]` prints out the results differently.
```{python}
type( df.tail(n = 1) )
type( df.loc[last_row_index] )
```

]


.panel[.panel-name[multiple rows]
- We can filter multiple rows.
```{python}
df.loc[ [0, 99, 999] ]
```


]


]


---
# Look at Columns, Rows, and Cells
### <p style="color:#00449E">  Subset Rows by Row Number: `.iloc[]` </p>

- `.iloc[]` does the same thing as `.loc[]`, but is used to subset by the row index number. 

- In our current example, gapminder DataFrame, `.iloc[]` and `.loc[]` behave exactly the same way because the index labels are the same as the row numbers.

.pull-left[
```{python}
# get the 2nd row
df.iloc[1]

# get the 100th row
df.iloc[99]
```
]
.pull-right[
```{python}
# get the last row
df.iloc[ -1]. # does it work?

# get the first, 100th, and 1000th row
df.iloc[ [0, 99, 999] ]
```
]




---
# Look at Columns, Rows, and Cells
### <p style="color:#00449E">  Mix It Up </p>

- We can use `.loc[]` and `.iloc[]` to obtain rows, columns, or both.
-  The general syntax for `.loc[]` and `.iloc[]` uses square brackets with a comma.
  - `df.loc[ [rows], [columns] ]`
  - `df.iloc[ [rows], [columns] ]`
  
  
- To just subset columns, we can use the slicing methods.
  -  If we are subsetting columns, we are getting all the rows for the specified column.
  -  So, we need a method to capture all the rows.
  -  If we have just a colon (`:`) when using slicing methods, it "slices" all the values in that axis.


---
# Look at Columns, Rows, and Cells
### <p style="color:#00449E">  Selecting Columns </p>

-  We can write `df.loc[:, [columns]]` or `df.iloc[:, [columns]]` to subset the column(s).

```{python}
# subset columns with loc
subset_1 = df.loc[:, ['year', 'pop']]
subset_1

# subset columns with iloc
# iloc will allow us to use integers -1 to select the last column
subset_2 = df.iloc[:, [2, 4, -1]]
subset_2

# do the followings work?
subset = df.loc[:, [2, 4, -1]] 
subset = df.iloc[:, ['year', 'pop']]
```


---
# Look at Columns, Rows, and Cells
### <p style="color:#00449E">   Subsetting with `range()` </p>

- We can use the built-in `range()` function to create a range of integer values. 
  - By default, `range(start, stop)` creates all integer values between the beginning and the end (inclusive left, exclusive right).
  - FYI, we can also pass in a 3rd parameter into `range(start, stop, step)`, `step`, that allows us to change how to increment between the start and stop values (defaults to `step=1`).


```{python}
# create a range of integers from 0 to 4 inclusive
small_range = list( range(5) )   # equivalent to range(0, 5)
small_range
# subset the dataframe with the range
subset = df.iloc[:, small_range]
subset
```




---
# Look at Columns, Rows, and Cells
### <p style="color:#00449E">   Subsetting with `range()` </p>

- Let's consider one more example with `range()`:

```{python}
#  create a range from 3 to 5 inclusive
small_range = list( range(3, 6) )

subset = df.iloc[:, small_range]
subset
```


- **Q**. What happens when you specify a `range()` that’s beyond the number of columns you have?



---
# Look at Columns, Rows, and Cells
### <p style="color:#00449E">   Subsetting with Slicing `:` </p>

- Unlike the `range()` function, the slicing method separates the values with the colon within the square bracket, `[start : end : step ]`.

- Let's see the columns of the DataFrame:
```{python}
df.columns
```

- See how `range()` and `:` are used to slice the first 3 columns.
```{python}
small_range = list( range(3) )
subset_1 = df.iloc[ : , small_range ]

subset_2 = df.iloc[ : , :3 ]
```



---
# Look at Columns, Rows, and Cells
### <p style="color:#00449E">   Subsetting with Slicing `:` </p>

**Q**. Let's slice the columns 3 to 5 inclusive using (1) the `range()` function and (2) the slicing method.


**Q**. What happens if we use the slicing method with 2 colons, but leave a value out? For example:
```{python}
 df.iloc[: , 0 : 6 :   ]
 df.iloc[: , 0 :   : 2 ]
 df.iloc[: ,   : 6 : 2 ]
 df.iloc[: ,   :   : 2 ]
 df.iloc[: ,   :   :   ]
```




---
# Look at Columns, Rows, and Cells
### <p style="color:#00449E">    Subsetting Rows and Columns </p>

- When only using the colon, `:`, in `.loc[]` and `.iloc[]` to the left of the comma, we select all the rows in our DataFrame (i.e., we slice all the values in the first axis of our DataFrame). 

- We can choose to put values to the left of the comma if we want to select specific rows along with specific columns.

```{python}
# using loc
print(df.loc[ 42, 'country' ])

# using iloc
print(df.iloc[42, 0])

# will it cause an error?
print(df.loc[42, 0])
```


---
# Look at Columns, Rows, and Cells
### <p style="color:#00449E">  Subsetting Multiple Rows and Columns </p>

- We can combine the row and column subsetting syntax with the multiple-row and multiple-column subsetting syntax to get various slices of our data.

```{python}
# get the 1st, 100th, and 1000th rows
# from the 1st, 4th, and 6th column
df.iloc[ [0, 99, 999], [0, 3, 5] ]
df.loc[ [0, 99, 999], ['country', 'lifeExp', 'gdpPercap'] ]
```

- Which one do you prefer between `.iloc[]` and `.loc[]`?



---
# Look at Columns, Rows, and Cells
### <p style="color:#00449E">  Subsetting Multiple Rows and Columns </p>

- So, we can use the slicing syntax on the row portion of the `.loc[]` and `.iloc[]` attributes. 
  - `.loc[]` matches on the named value (label);
  - `.iloc[]` slices by integer position.
  
```{python}
df.loc[ 10:13 , : ]
df.iloc[ 10:13 , : ]
```
  


---
# Look at Columns, Rows, and Cells
### <p style="color:#00449E">  Subsetting Multiple Rows and Columns </p>

```{r, echo = F, eval = T, out.width='100%', fig.align='center'}
text_tbl <- data.frame(
  `Type` = c("df[val]",
"df`.`loc[val]",
"df`.`loc[:, val]",
"df`.`loc[val1, val2]",
"df`.`iloc[where]",
"df`.`iloc[:, where]",
"df`.`iloc[w1, w2]"),
  `Description` = c("Select single column or set of columns",
"Select single row or set of rows",
"Select single column or set of columns",
"Select row and column by label",
"Select row or set of rows by integer position",
"Select column or set of columns by integer position",
"Select row and column by integer position")
  )


kable(text_tbl, format = "html") %>%
  kable_paper(full_width = T) %>%
  column_spec(1, bold = T, border_right = T) %>%
  kable_styling(html_font = 'sans-serif, helvetica, arial',
                bootstrap_options = c("hover", "condensed") )

```


---
# Grouped and Aggregated Calculations
### <p style="color:#00449E">  </p>

- Let’s look at our Gapminder data again.
```{python}
df
```

  - **Q**. For each year in our data, what was the average life expectancy? What is the average life expectancy, population, and GDP?
  - **Q**. What if we stratify the data by continent and perform the same calculations?
  - **Q**. How many countries are listed in each continent?
  
  

---
# Grouped and Aggregated Calculations
### <p style="color:#00449E"> Grouped Means </p>
  
**Q**. What was the average life expectancy for each year?
- To answer this question, we need to:
  1. Split our data into parts by `year`
  2. Get the `lifeExp` column
  3. Calculate the mean


- For such tasks, we need to perform a grouped (i.e., aggregate) calculation.
  - We need to perform a calculation, an average or a frequency count, but apply it to each subset/group of a variable. 
  - We can use the `.groupby()` method on `DataFrames`.
  
```{python}
df.groupby('year')['lifeExp'].mean()
```
  



---
# Grouped and Aggregated Calculations
### <p style="color:#00449E"> Grouped Means </p>

- Let’s unpack `df.groupby('year')['lifeExp'].mean()`. 


.panelset[

.panel[.panel-name[Grouped DataFrame]
  - We first create a grouped object.
  
```{python}
grouped_year_df = df.groupby('year')
type(grouped_year_df)
grouped_year_df  # Pandas returns only the memory location of DataFrameGroupBy
```
]

.panel[.panel-name[Grouped Series]

- From the grouped `DataFrame`, we can subset the columns we want.

```{python}
grouped_year_df_lifeExp = grouped_year_df['lifeExp']
type(grouped_year_df_lifeExp)
grouped_year_df_lifeExp  # Pandas returns only the memory location of SeriesGroupBy
```
]

.panel[.panel-name[Calculation]

- We can calculate the mean value of `lifeExp` for each `year`.

```{python}
mean_lifeExp_by_year = grouped_year_df_lifeExp.mean()
mean_lifeExp_by_year
```


]

]

---
# Grouped and Aggregated Calculations
### <p style="color:#00449E"> Grouped Means </p>

**Q**. What was the average life expectancy for each year-continent pair?

.panelset[
.panel[.panel-name[(1)]
- We can use a `list` to group and stratify the data by more than one variable.
```{python}
df.groupby( ['year', 'continent'] )[ 'lifeExp' ].mean()   # Series
df.groupby( ['year', 'continent'] )[ ['lifeExp'] ].mean()   # DataFrame
```

]

.panel[.panel-name[(2)]
- The backslash (`\`) allows us to break up 1 long line of Python code into multiple lines.
```{python}
multi_group = df\
  .groupby( ['year', 'continent'] )\
  [ ['lifeExp'] ]\
  .mean()
```
]

.panel[.panel-name[(3)]

- Instead, we can also wrap the entire statement by round parentheses (`()`) with each **.method()** on a new line.

```{python}
multi_group = (
  df
  .groupby(['year', 'continent'])
  [ ['lifeExp'] ]
  .mean()
)
```

]

]



---
# Grouped and Aggregated Calculations
### <p style="color:#00449E"> Grouped Means </p>

- **Q**  What if we want to perform the same calculation on multiple columns?
  - We can use a list with multiple column names.

.panelset[
.panel[.panel-name[(1)]
```{python}
df.groupby(['year', 'continent'])[ ['lifeExp', 'gdpPercap'] ].mean()  
```
]

.panel[.panel-name[(2)]
```{python}
multi_group_var = df\
  .groupby(['year', 'continent'])\
  [['lifeExp', 'gdpPercap']]\
  .mean()
```
]

.panel[.panel-name[(3)]
```{python}
multi_group_var = (
  df
  .groupby(['year', 'continent'])
  [['lifeExp', 'gdpPercap']]
  .mean()
)
```

]

]

- **Q** Does the order of the list we used to group the data matter?



---
# Grouped and Aggregated Calculations
### <p style="color:#00449E"> Grouped Means </p>

-  Notice the `year` and `continent` column names are not on the same line as the `lifeExp` and `gdpPercap` column names. 

```{python}
multi_group_var
```
  
- We can use the `.reset_index()` method to convert indices into variables.
```{python}
flat = multi_group_var.reset_index()
```

- **Q** Does the order of the list we used to group the data matter?


---
# Grouped and Aggregated Calculations
### <p style="color:#00449E">  Grouped Frequency Counts </p>

- Another common data-related task is to calculate frequencies. 
  - The `.nunique()`  gets counts of unique values on a Pandas Series.
  - The `.value_counts()`  gets frequency counts on a Pandas Series.

- **Q.** How many countries are in each continent in the Gapminder `DataFrame`?
  
  

---
# Basic Plot
### <p style="color:#00449E">   </p>

- Visualizations are extremely important in almost every step of the data process. 
  - They help us identify pattern in data when we are trying to understand and clean the data.
  
- Let’s look at the yearly life expectancy for the world population.

```{python}
global_yearly_life_expectancy = df.groupby('year')['lifeExp'].mean()
global_yearly_life_expectancy
```

- **Q**. Describe the yearly life expectancy for the world population.


---
# Basic Plot
### <p style="color:#00449E">   </p>

- We can use the Pandas' `.plot()` method to describe the yearly life expectancy
```{python}
# matplotlib is the default plotting library
# we need to import first
import matplotlib.pyplot as plt

# use the .plot() DataFrame method
global_yearly_life_expectancy.plot()

# show the plot
plt.show()
```



---
class: inverse, center, middle

# Pandas Data Structures Basics

---


---
# Pandas Data Structures Basics
### <p style="color:#00449E">  Create Your Own Data </p>

- Knowing how to create `Series` or `DataFrames` without loading data from a file is a useful skill.

  
- `Series` is a one-dimensional container.
- A `Series` is very similar to a Python `list`, except that each element must be the same `dtype` (`object`, `int64`, `float64`, or `datetime64`). 
  - This is the same behavior as the NumPy array (`ndarray`).
  - If a column contains the number 1 and the sequence of letters "pizza", the entire `dtype` of the column will be a `string` (which is `object`).


- A `DataFrame` can be thought of as a dictionary of `Series` objects.
  - Each key is the column name and the value is the `Series`.
  
  
---
# Create Your Own Data 
### <p style="color:#00449E">   NumPy Array </p>
- Python library `NumPy` introduces an N-dimensional array object, or `ndarray`.
  - Pandas implicitly uses `ndarray`, so here let's see what `ndarray` is.
  - The easiest way to create an array is to use the `.array()` method.
  
.pull-left[
```{python}
import pandas as np
data1 = [6, 7.5, 8, 0, 1]
arr1 = np.array(data1) 
arr1
arr2.ndim
arr2.shape
```

]  
.pull-right[
```{python}
data2 = [ [1, 2, 3, 4], 
          [5, 6, 7, '8'] ]
arr2 = np.array(data2)
arr2
arr2.ndim
arr2.shape
```

]  
  
---
# Create Your Own Data 
### <p style="color:#00449E">   Create a `Series` </p>
- A `Series` is a data structure in pandas.
  - Containing a sequence of `values` and a corresponding labels, called the `index`,
  - A `Series` displays the `index` on the left and the `values` on the right,
  - The default `index` consists of the integers 0 through N-1.
  
  
- `pd.Series()` creates a one-dimensional container including `values` and an `index`.
```{python}
import pandas as pd
s = pd.Series( ['banana', 42] )
```


---
# Create Your Own Data 
### <p style="color:#00449E">   Create a `Series` </p>

-  The "row number" is shown on the left of the `Series`. 
  - This is actually the `index` for the `Series`.
  -  It is similar to the row name and row index for `DataFrame`.
  
```{python}
# manually assign index values to a series
# by passing a Python list
s = pd.Series(
  data =["Wes McKinney", "Creator of Pandas"],
  index =["Person", "Who"],
)

s
```



---
# Create Your Own Data 
### <p style="color:#00449E">   Create a `Series` </p>

- Pandas Series can also be created from `ndarrys`, `tuples`, and `dictionaries`.

- **Q**. Use `dictdata` to create a Pandas `Series`.
```{python}
dictdata = {
    "Name": ["William Nordhaus", "Ronald Coase"],
    "Occupation": ["Economist", "Economist"],
    "Born": ["1941-05-31", "1910-12-29"],
    "Died": ["", "2013-09-02"],
    "Age": [81, 102],
  }
```



---
# Create Your Own Data 
### <p style="color:#00449E">   Create a `DataFrame` </p>

- A `DataFrame` can be thought of as a dictionary of `Series` objects.
  - `Dictionaries` are one of the most common ways of creating a `DataFrame`.
  - The `key` represents the column name, and the `values` are the contents of the column.
  
```{python}
economists = pd.DataFrame(
 {  "Name": ["William Nordhaus", "Ronald Coase"],
    "Occupation": ["Economist", "Economist"],
    "Born": ["1941-05-31", "1910-12-29"],
    "Died": ["", "2013-09-02"],
    "Age": [81, 102]  } )
```
  


---
# The `Series`
### <p style="color:#00449E">  </p>

- Let’s re-create our example DataFrame.
```{python}
# create our example dataframe with a row index label
economists = pd.DataFrame(
  data = {
    "Occupation": ["Economist", "Economist"],
    "Born": ["1941-05-31", "1910-12-29"],
    "Died": ["", "2013-09-02"],
    "Age": [81, 102],
  },
  index =  ["William Nordhaus", "Ronald Coase"],
  columns =["Occupation", "Born", "Died", "Age"] 
)
```

- **Q**. Select an economist from `economists` by the row index label to get a `Series`.


---
# The `Series`
### <p style="color:#00449E"> `Series` Attributes </p>

- When a series is printed (i.e., the string representation), the `index` is printed as the first “column”, and the `values` are printed as the second “column”.

-  There are many attributes and methods associated with a `Series` object.

```{python}
first_row = economists.loc['William Nordhaus']
type(first_row)
first_row.index
first_row.values
type(first_row.values)
first_row.shape
first_row.size
first_row.dtypes
```
  

---
# The `Series`
### <p style="color:#00449E"> Attributes vs. Methods </p>

- Attributes can be thought of as features of an object (in this example, our object is a Series). 

- Methods can be thought of as some calculation or operation that is performed on an object. 
  - Methods or functions have round parentheses (`()`), while attributes do not.

- The subsetting syntax `.loc[]` and `.iloc[]` consists of all attributes.    




---
# The `Series`
### <p style="color:#00449E"> `Series` Methods </p>

- Let’s first get a series of the `Age` column from our `economists` DataFrame.

```{python}
ages = economists['Age']
```

-  When we have a vector of numbers, there are common calculations we can perform.
```{python}
ages.mean()
ages.min()
ages.max()
ages.std()
```
- `.mean()`, `.min()`, `.max()`, and `.std()` are also methods in `np.ndarray`.


---
# The `Series`
### <p style="color:#00449E"> `Series` Methods </p>

- Let’s load the CSV file, `scientists.csv`, which is in Files section on our Canvas.

```{python}
scientists = pd.read_csv('data/scientists.csv')   # use a proper pathname.
ages = scientists['Age']
```

-  The `.describe()` method calculates multiple descriptive statistics for numeric variables.
```{python}
scientists.describe()
ages.describe()
```



---
# The `Series`
### <p style="color:#00449E"> Boolean Subsetting on `Series` </p>

- We can not only subset values using labels and indices, but also supply a vector of **boolean values**.

- Boolean subsetting of numeric Series works as follows:
  - `Series[ Series > VALUE  ]`
  - `Series[ Series == VALUE  ]`
  - `Series[ Series < VALUE  ]`

- **Q**. What if we wanted to subset our ages by identifying those above the mean?


---
# The `Series`
### <p style="color:#00449E"> Boolean Subsetting on `Series` </p>
- Let’s look at what `ages > ages.mean()` returns.
```{python}
ages > ages.mean()

cond = ages > ages.mean()
ages[cond]
```





---
# The `Series`
### <p style="color:#00449E">  Operations Are Automatically Aligned and Vectorized (Broadcasting) </p>

-  Many of the methods that work on `Series` (and also `DataFrames`) are “vectorized”, meaning that they work on the entire vector simultaneously.

  - `ages > ages.mean()` returns a vector without any `for` loops.


.panelset[

.panel[.panel-name[same length]
- If we perform an operation between two vectors of the same length, the resulting vector will be an **element-by-element calculation** of the vectors.
```{python}
ages + ages
ages * ages
```
]

.panel[.panel-name[w/ scalars]
- When we perform an operation on a vector using a scalar, the scalar will be recycled across all the elements in the vector.

```{python}
ages + 100
ages * 2
```
]

.panel[.panel-name[w/ different length (1)]
- When we are working with vectors of different lengths, the behavior will depend on the `type()` of the vectors.
  -  With a `Series`, the vectors will perform an operation matched by the index.
  - With other `types()`, the shapes must match.
]

]


.panel[.panel-name[w/ different length (2)]
```{python}
ages + pd.Series( [1, 100] )
ages + np.array( [1, 100] )
```
]

]



---
# The `Series`
### <p style="color:#00449E">  Operations Are Automatically Aligned and Vectorized (Broadcasting) </p>

- What’s convenient in Pandas is how data alignment is almost always automatic.   - If possible, things will always align themselves with the index label when actions are performed.


- Let's consider `.sort_index()` method:
  - `Series.sort_index(ascending=False)` sorts Series by index in descending order.
```{python}
rev_ages = ages.sort_index(ascending =False) 
rev_ages
```

- **Q**. What is `ages + rev_ages`?



---
# The `DataFrame`
### <p style="color:#00449E">   </p>

- The `DataFrame` is the most common Pandas object. 
  - It can be thought of as Python’s way of storing spreadsheet-like data. 
  - Many of the features of the `Series` data structure carry over into the `DataFrame`.



---
# The `DataFrame`
### <p style="color:#00449E"> Parts of a `DataFrame` </p>

- There are 3 main parts to a Pandas `DataFrame` object: 
  - `.index`
  - `.columns` 
  - `.values`
  
```{python}
scientists.index
scientists.columns
scientists.values
```
  


---
# The `DataFrame`
### <p style="color:#00449E">  Boolean Subsetting on `DataFrames` </p>


- Boolean subsetting of `DataFrames` works like boolean subsetting a `Series`.
  - `DataFrame[ DataFrame['VARIABLE_NAME'] > VALUE  ]`
  - `DataFrame[ DataFrame['VARIABLE_NAME'] == VALUE  ]`
  - `DataFrame[ DataFrame['VARIABLE_NAME'] < VALUE  ]`

```{python}
# boolean vectors will subset rows
scientists.loc[ scientists['Age'] > scientists['Age'].mean() ]
```


---
# The `DataFrame`
### <p style="color:#00449E">  Subsetting Multiple Rows and Columns </p>

```{r, echo = F, eval = T, out.width='100%', fig.align='center'}
text_tbl <- data.frame(
  `Type` = c("df[val]",
"df`.`loc[val]",
"df`.`loc[:, val]",
"df`.`loc[val1, val2]",
"df`.`iloc[where]",
"df`.`iloc[:, where]",
"df`.`iloc[w1, w2]"),
  `Description` = c("Select single column or set of columns",
"Select single row or set of rows",
"Select single column or set of columns",
"Select row and column by label",
"Select row or set of rows by integer position",
"Select column or set of columns by integer position",
"Select row and column by integer position")
  )


kable(text_tbl, format = "html") %>%
  kable_paper(full_width = T) %>%
  column_spec(1, bold = T, border_right = T) %>%
  kable_styling(html_font = 'sans-serif, helvetica, arial',
                bootstrap_options = c("hover", "condensed") )

```



---
# The `DataFrame`
### <p style="color:#00449E">  Operations Are Automatically Aligned and Vectorized (Broadcasting) </p>

- Pandas supports *broadcasting* because the `Series` and `DataFrame` objects are built on top of the `numpy` library. 
  - Broadcasting describes what happens when performing operations between array-like objects. 
  - These behaviors depend on the type of object, its length, and any labels associated with the object.
  


---
# The `DataFrame`
### <p style="color:#00449E">  Operations Are Automatically Aligned and Vectorized (Broadcasting) </p>


.panelset[

.panel[.panel-name[w/ scalars]
- When we perform an action on a dataframe with a scalar, it will try to apply the operation on each cell of the dataframe.
```{python}
scientists * 2
```


]



.panel[.panel-name[w/ Series]

- By default, arithmetic operations between DataFrames and Series
match the index of the Series on the DataFrame’s columns,

- The operations will be broadcasted along the rows.
```{python}
pd.Series([10]) + scientists[['Age']]
pd.Series([10], index = ['Age']) + scientists[['Age']]
```


]

]