---
title: "DANL 210 Lecture 8"
subtitle: "DANL 210: Data Preparation and Management"
author: "Byeong-Hak Choe"
institute: "SUNY Geneseo"
date: "Febraury 16, 2023"
output:
  xaringan::moon_reader:
    css: 
      - default
      - css/nhsr.css
      - css/nhsr-fonts.css
    lib_dir: libs
    seal: false
    nature:
      highlightStyle: googlecode
      highlightLines: true
      highlightLanguage: ["r"]
      countIncrementalSlides: false
      ratio: "16:9"
    includes:
      after_body: [css/insert-logo.html]
---

```{r setup, include = FALSE}
library(knitr)
library(kableExtra)
library(tidyverse)
library(NHSRtheme)
library(fontawesome)
# set default options
opts_chunk$set(echo = T, eval = F,
               fig.width = 7.252,
               fig.height = 4,
               comment = "#",
               dpi = 300)

knitr::knit_engines$set("markdown")

xaringanExtra::use_tile_view()
xaringanExtra::use_panelset()
xaringanExtra::use_clipboard()
xaringanExtra::use_webcam()
xaringanExtra::use_broadcast()
xaringanExtra::use_share_again()
xaringanExtra::style_share_again(
  share_buttons = c("twitter", "linkedin", "pocket")
)


xaringanExtra::use_extra_styles(
  hover_code_line = TRUE,         #<<
  mute_unhighlighted_code = TRUE  #<<
)

# uncomment the following lines if you want to use the NHS-R theme colours by default
# scale_fill_continuous <- partial(scale_fill_nhs, discrete = FALSE)
# scale_fill_discrete <- partial(scale_fill_nhs, discrete = TRUE)
# scale_colour_continuous <- partial(scale_colour_nhs, discrete = FALSE)
# scale_colour_discrete <- partial(scale_colour_nhs, discrete = TRUE)
```

class: title-slide, left, bottom

# `r rmarkdown::metadata$title`
----
## **`r rmarkdown::metadata$subtitle`**
### `r rmarkdown::metadata$author`
### `r rmarkdown::metadata$date`



---
# Announcement
### <p style="color:#00449E">  Guideline for Homework Assignments </p>

- You are encouraged to 
  - Work together with classmates.
  - Use office hours and tutoring/TA sessions.


- At the beginning of the homework, please mention 
  - Who you work with for the homework.
  - Whether or not getting help from a tutor 
  - Whether or not using ChatGPT


- If you use ChatGPT for your homework, please paraphrase, quote, and cite it.
  - ChatGPT is good at adding comments on the code.
  - ChatGPT is good at correcting errors in the code.

---
# The `DataFrame`
### <p style="color:#00449E">  Subsetting Multiple Rows and Columns </p>

```{r, echo = F, eval = T, out.width='100%', fig.align='center'}
text_tbl <- data.frame(
  `Type` = c("df[val]",
"df`.`loc[val]",
"df`.`loc[:, val]",
"df`.`loc[val1, val2]",
"df`.`iloc[where]",
"df`.`iloc[:, where]",
"df`.`iloc[w1, w2]",
"df`.`query(CONDITION)"),
  `Description` = c("Select single column or set of columns",
"Select single row or set of rows",
"Select single column or set of columns",
"Select row and column by label",
"Select row or set of rows by integer position",
"Select column or set of columns by integer position",
"Select row and column by integer position",
"Select row by a condition")
  )


kable(text_tbl, format = "html") %>%
  kable_paper(full_width = T) %>%
  column_spec(1, bold = T, border_right = T) %>%
  kable_styling(html_font = 'sans-serif, helvetica, arial',
                bootstrap_options = c("hover", "condensed") )

```



---
# The `DataFrame`
### <p style="color:#00449E">  Boolean Subsetting </p>

.panelset[
.panel[.panel-name[Series]

- We can not only subset values using labels and indices, but also supply a vector of **boolean values**.

- Boolean subsetting of numeric Series works as follows:
  - `Series[ Series > VALUE  ]`
  - `Series[ Series == VALUE  ]`
  - `Series[ Series < VALUE  ]`

]

.panel[.panel-name[DataFrame]
- Boolean subsetting of `DataFrames` works like boolean subsetting a `Series`.
  - `DataFrame[ DataFrame['VARIABLE_NAME'] > VALUE  ]`
  - `DataFrame[ DataFrame['VARIABLE_NAME'] == VALUE  ]`
  - `DataFrame[ DataFrame['VARIABLE_NAME'] < VALUE  ]`

```{python}
import pandas as pd
scientists = read_csv('data/scientists.csv')  

# What if we want to subset our ages by identifying those above the mean?
scientists.loc[ scientists['Age'] > scientists['Age'].mean() ]
```
]


.panel[.panel-name[Q.]
- Consider the two Series, `area` and `pop`:
```{python}
area = pd.Series({'California': 423967, 'Texas': 695662,
                  'New York': 141297, 'Florida': 170312,
                  'Illinois': 149995})
pop = pd.Series({'California': 38332521, 'Texas': 26448193,
                 'New York': 19651127, 'Florida': 19552860,
                 'Illinois': 12882135})
```

- Use boolean subsetting to find states whose population density is greater than 100 or less than 50.

]


]


---
# The `DataFrame`
### <p style="color:#00449E">  Subsetting Rows with `.query()` </p>

- We can also subset rows based on a condition using `DataFrame.query()`:

.panelset[
.panel[.panel-name[Data]
```{python}
df = pd.DataFrame(
    # array with numbers from 0 to 35, 6 rows and 6 columns
    data = np.reshape( range(36), (6, 6) ),
    index = ["a", "b", "c", "d", "e", "f"],
    columns = ["col" + str(i) for i in range(6)],
    dtype = float,
)
df["col6"] = ["apple", "orange", "pineapple", "mango", "kiwi", "lemon"]
df
```
]

.panel[.panel-name[.query() (1)]
- Select rows if a value of `col6` is "kiwi" or "pineapple": 
```{python}
df.query("col6 == 'kiwi' or col6 == 'pineapple'")
```

- Select rows if a value of `col0` is greater than 6:
```{python}
df.query("col0 > 6")
```

]


.panel[.panel-name[(2)]
- Select flights that departed on January 1:
```{python}
# download NY_flights.csv from the Files section in Canvas
flights = pd.read_csv("data/NY_flights.csv")
flights.head()

flights.query("month == 1 and day == 1")
```


]

.panel[.panel-name[(3)]
- Select penguins whose `bill_length_mm` is smaller than `1.8 * bill_depth_mm`.
```{python}
import seaborn as sns
penguins = sns.load_dataset("penguins")
penguins.head()

penguins.query('bill_length_mm < bill_depth_mm*1.8')
```

]

.panel[.panel-name[(4)]
- Objects not in DataFrame can be referenced with an `@` character like` @a + b`.


```{python}
outside_var = 21
penguins.query('bill_depth_mm > @outside_var')
```

]


]


---
# The `Series` and the `DataFrame`
### <p style="color:#00449E">  Sorting and Ranking </p>

- Let's consider `.sort_index()` and `.sort_values()` methods:

.panelset[

.panel[.panel-name[Series]
  - `Series.sort_index(ascending=False)` sorts `Series` by index in descending order.
  - `Series.sort_values(ascending=False)` sorts `Series` by value in descending order.
```{python}
rev_ages = ages.sort_index(ascending =False) 
sorted_ages = ages.sort_values(ascending =False) 
```
]
.panel[.panel-name[DataFrame]
  - `DataFrame.sort_index(ascending=False)` sorts `DataFrame` by index in descending order.
  - `DataFrame.sort_values(by = "VAR", ascending=False)` sorts `DataFrame` by value of `VAR` in descending order.
```{python}
rev_ages = scientists.sort_index(ascending =False) 
sorted_df = scientists.sort_values(by = 'Age', 
                                   ascending =False) 
```


]

]



---
# The `Series` and the `DataFrame`
### <p style="color:#00449E">  Sorting and Ranking </p>

- In Pandas, there are a variety of ranking functions with `.rank()`.

.panelset[

.panel[.panel-name[example]

- Consider the following DataFrame.

```{python}
import numpy as np
df = pd.DataFrame(data={'Animal': ['fox', 'Kangaroo', 'deer',
                                   'spider', 'snake'],
                        'Number_legs': [4, 2, 4, 8, np.nan]})
df
```
]

.panel[.panel-name[method (1)]

- `.rank(method = "min", ascending=False)` does give the largest values the smallest ranks.

- `.rank(method = "dense", ascending=False)` does give the largest values the smallest ranks without any gaps between ranks when breaking ties.

- `.rank(method = "average", ascending=False)` calculates the average rank for each unique value.
]


.panel[.panel-name[method (2)]
```{python}
df['default_rank'] = df['Number_legs'].rank(ascending = False)  # method = 'average'
df['min_rank'] = df['Number_legs'].rank(method='min', ascending = False)
df['dense_rank'] = df['Number_legs'].rank(method='dense', ascending = False)
df
```
]


.panel[.panel-name[na_option]
- `na_option = keep` assigns `NaN` rank to `NaN` values (default).
- `na_option = top` assign smallest rank to `NaN` values if ascending
- `na_option = bottom` assign highest rank to `NaN` values if ascending
```{python}
df['NA_bottom'] = df['Number_legs'].rank(na_option='bottom')
df['NA_top'] = df['Number_legs'].rank(na_option='top')
df
```
]

.panel[.panel-name[pct]

- `pct = True` displays the returned rankings in percentile form.	
```{python}
df['pct_rank'] = df['Number_legs'].rank(pct=True)
df
```
]

]


---
#  Making Changes to Series and DataFrames
### <p style="color:#00449E"> Dropping Values </p>


.panelset[

.panel[.panel-name[Columns]
- To drop a column, we can select columns to drop with the `.drop()` method with `axis = 1` or `axis = "columns"` on our dataframe.

```{python}
# all the current columns in our data
scientists.columns

# drop the shuffled age column
# we provide the axis=1 argument to drop column-wise
scientists_dropped = scientists.drop( ['Age'], axis ="columns")
scientists_dropped.columns
```

]

.panel[.panel-name[Rows]
- To drop rows, we can select rows by index to drop with the `.drop()` method with `axis = 0`, which is default.


```{python}
# all the current columns in our data
scientists.columns

# drop rows by their indices
scientists_rows_dropped = scientists.drop( [2, 4, 6] )
scientists_rows_dropped
```

]

]


---
#  Making Changes to Series and DataFrames
### <p style="color:#00449E">   Modifying Columns with `.assign()` </p>

.panelset[

.panel[.panel-name[(0)]
- Let's create a new set of columns that contain the `datetime` representations of the object (string) dates.
```{python}
# format the 'Born' column as a datetime
born_datetime = pd.to_datetime( scientists['Born'] )
died_datetime = pd.to_datetime( scientists['Died'] )

scientists['born_dt'], scientists['died_dt'] = (
  born_datetime,
  died_datetime
)

scientists['age_days'] =  scientists['died_dt'] - scientists['born_dt']
```


]

.panel[.panel-name[(1)]
- Let’s create the `age_year_assign` column using `.assign()`.

```{python}
scientists = scientists.assign(
  # new columns on the left of the equal sign
  # how to calculate values on the right of the equal sign
  # separate new columns with a comma
  age_days_assign = scientists['died_dt'] - scientists['born_dt'],
  age_year_assign = scientists['age_days'].astype('timedelta64[Y]')
)
```
]

.panel[.panel-name[(2)]
- In the previous panel, we had to use `age_days` to create `age_year_assign`.
  - To be able to use `age_days_assign` when calculating `age_year_assign` in the previous panel, we need to know about `lambda` functions.
  
```{python}
scientists = scientists.drop( ['age_days'], axis = 1)  # to drop age_days
scientists = scientists.assign(
  age_days_assign = scientists['died_dt'] - scientists['born_dt'],
  age_year_assign = lambda some_df: 
    some_df['age_days_assign'].astype('timedelta64[Y]') 
)
```

]

]



---
# Pandas Data Structures Basics
### <p style="color:#00449E"> Lambda functions </p>
.panelset[

.panel[.panel-name[(1)]
- Python has support for so-called anonymous or lambda functions. 
  - Lambda functions are a way of writing functions consisting of a single statement, the result of which is the return value. 
  - A syntax for a lambda function is `lambda ARGUMENTS : EXPRESSION`

```{python}
def short_function(x):
  return x * 2

equiv_anon = lambda x: x * 2
short_function(2)
equiv_anon(2)
```

]


.panel[.panel-name[(2)]
- A `lambda` function can have multiple arguments:

```{python}
fn_two = lambda a, b : a * b
fn_two(1, 2)

fn_three = lambda a, b, c : a + b + c
fn_two(1, 2, 3)
```

]



.panel[.panel-name[(3)]
- The power of lambda is better shown when we use them as an anonymous function inside another function.
  - Say we have a function definition that takes one argument, and that argument will be multiplied with an unknown number:

```{python}
def myfunc(n):
  return lambda a : a * n
```

]


.panel[.panel-name[(4)]
.pull-left[
- Use that function definition to make a function that always doubles the number we send in:

```{python}
def myfunc(n):
  return lambda a : a * n

my_doubler = myfunc(2)
my_doubler(10)
```
]

.pull-right[
- Use the same function definition to make a function that always triples the number we send in:
```{python}
def myfunc(n):
  return lambda a : a * n

my_tripler = myfunc(3)
my_tripler(10)
```

]

]

.panel[.panel-name[(5)]
- Here is the example of applying a lambda function to single variable in DataFrame using `.assign()`

```{python}
values= [['Rohan',182],['Elvish',100],['Deepak',198],
         ['Soni',160],['Radhika',140],['Vansh',180]]
df = pd.DataFrame(values, columns = ['name','tot_marks'])
 
# Applying lambda function to find percentage of 'tot_marks' column
# using df.assign()
df = df.assign( percentage = 
  lambda some_name: (some_name['tot_marks'] /200 * 100) )
```

]

]




---
class: inverse, center, middle

# Apply Functions

---
#  Apply Functions
### <p style="color:#00449E">  </p>

- Learning about `.apply()` is fundamental in the data cleaning process. 

- It also encapsulates key concepts in programming, mainly writing **functions**. 

- The `.apply()` method takes a function and applies it (i.e., runs it) across each row or column of a DataFrame without having us write the code for each element separately.



---
#  Apply Functions
### <p style="color:#00449E">  </p>
- How do we use functions in Pandas?
  - We've already seen lambda functions in Pandas!
- Here’s a toy DataFrame of two columns.
```{python}
df = pd.DataFrame({"a": [10, 20, 30], "b": [20, 30, 40]})
```

- We can `.apply()` our functions over a `Series` (i.e., a **column** or a **row**).
- Let's consider the following example:

.pull-left[
```{python}
def my_sq(x):
  """Squares a given value
  """
  return x ** 2
```
]
.pull-right[
```{python}
df['a'] ** 2
# this would not allow us to use 
# a function we wrote ourselves.
```
]


---
#  Apply Functions
### <p style="color:#00449E">  Apply Over a Series </p>

.panelset[

.panel[.panel-name[(1)]
-  If we want to square each value in column `a`, we can do the following:

```{python}
sq = df['a'].apply(my_sq)
```
]

.panel[.panel-name[(2)]
- Let’s consider a function that takes two parameters.

```{python}
def my_exp(x, e):
  return x ** e

cubed = my_exp(2, 3)
my_exp(2)  # does it work?
```
]

.panel[.panel-name[(3)]
- If we want to apply the function `my_exp(x, e)` on our series, we will need to pass in the second parameter.
  -  To do this, we pass the second argument as a **keyword** argument into `.apply()`.

```{python}
ex2 = df['a'].apply(my_exp, e=2)
ex3 = df['a'].apply(my_exp, e=3)
```
]


]



---
#  Apply Functions
### <p style="color:#00449E">  Apply Over a DataFrame --- Column-Wise Operations </p>

.panelset[

.panel[.panel-name[DataFrames]
- We’ve seen how to apply functions over a one-dimensional `Series`.

- `DataFrames` typically have at least two dimensions. 
  - When we apply a function over a dataframe, we first need to specify which axis to apply the function over–for example, column-by-column or row-by-row.
]

.panel[.panel-name[(1)]

- Use the `axis = 0` parameter (the default value) in `.apply()` when working with functions in a column-wise manner (i.e., for each column).

```{python}
def print_me(x):
  print(x)
df.apply(print_me, axis =0)
```

- Compare this output to the following:

```{python}
print(df['a']); print(df['b'])
```
]



.panel[.panel-name[(2)]

-  When we apply a function across a DataFrame (in this case, column-wise with `axis=0`), the **entire** axis (e.g., column) is passed into the **first** argument of the function.

```{python}
def avg_3(x, y, z):
   return (x + y + z) / 3

df.apply(avg_3)  # does it work?
df.apply(avg_3, y= 1, z = 1)
df.apply(avg_3, y= [1, 1, 1], z = [1, 1, 1])
df.apply(avg_3, y= [1, 1, 1], z = [1, 5, 10])
```


]

.panel[.panel-name[(3)]
-  Does the following work?

```{python}
def avg_3_apply(col):
  """The avg_3 function but apply compatible by taking in all the values 
  as the first argument and parsing out the values within the function
  """
   x = col[0]
   y = col[1]
   z = col[2]
   return (x + y + z) / 3
df.apply(avg_3_apply)  # does it work?
```


]

]
  

---
#  Apply Functions
### <p style="color:#00449E">  Apply Over a DataFrame --- Row-Wise Operations </p>

.panelset[


.panel[.panel-name[(1)]

- Use the `axis = 1` parameter in `.apply()` when working with functions in a row-wise manner (i.e., for each column).
  -  The **entire row** is used as the first argument.


- Let's `.apply( axis = 1)` to each row.
```{python}
df.apply( avg_3_apply, axis = 1 )  
```

- Does it work?

]


.panel[.panel-name[(2)]

-  The main issue here is the `index out of bounds`. 

  - We passed the row of data in as the first argument, but in our function we begin indexing out of range. 
  
  - That is, we have only two values in each row, but we tried to get index 2, which means the third element, and it does not exist).

]

.panel[.panel-name[(3)]

-  If we want to calculate our averages row-wise, we have to write a new function to work with two values.

```{python}
def avg_2_apply(row):
    """Taking the average of row value.
    Assuming that there are only 2 values in a row.
    """
    x = row[0]
    y = row[1]
    return (x + y) / 2
df.apply(avg_2_apply, axis =1)
```

]

]
  

---
#  Apply Functions
### <p style="color:#00449E">  Lambda Functions </p>
- Sometimes the function used in the `.apply()` method is simple enough that there is no need to create a separate function.

.pull-left[

```{python}
def my_sq(x):
  return x ** 2

df['a_sq'] = df['a'].apply(my_sq)
```

]

.pull-right[

```{python}
df['a_sq_lamb'] = ( df['a']
    .apply(lambda x: x ** 2) )
```

]

- We can see that the actual function is a simple one-liner. 
  - Usually when this happens, we would want to use lambda functions.



---
#  Apply Functions
### <p style="color:#00449E">   Vectorized Functions </p>


.panelset[


.panel[.panel-name[(1)]
- When we use `.apply()`, we are able to make a function work on a column-by-column or row-by-row basis.


- However, there might be times when it is not feasible to rewrite a function in this way. 
  - We can then leverage the `.vectorize()` function and decorator to vectorize any function.
  - We expect performance gains by doing so.
  
  
]
 
.panel[.panel-name[(2)] 
- Here’s our average function, which we can apply on a row-by-row basis:

```{python}
def avg_2(x, y):
  return (x + y) / 2

df   # to remind ourselves
avg_2( df['a'], df['b'] )
```

- For a vectorized function, we’d like to be able to pass in a vector of values for `x` and a vector of values for `y`, and the results should be the average of the given `x` and `y` values in the same order. 

]

.panel[.panel-name[(3)]

- `avg_2(df['a'], df['y'])` works because the actual calculations within our function are inherently vectorized.

  - If we add two numeric columns together, `Pandas` (and the `NumPy` library) will automatically perform element-wise addition.
  
  - Likewise, when we divide by a scalar, it will “broadcast” the scalar, and divide each element by the scalar.
]


.panel[.panel-name[(4)]

- Let’s change our function and perform a non-vectorizable calculation.
```{python}
def avg_2_mod(x, y):
   """Calculate the average, unless x is 20."""
   if x == 20:
     return np.NaN
   else:
     return (x + y) / 2
avg_2_mod( df['a'], df['b'] )   # does it work?
avg_2_mod(10, 20)
avg_2_mod(20, 30)
```


]

.panel[.panel-name[w/ np (1)]
- We pass `np.vectorize()` to the function we want to vectorize, to create a new function.

```{python}
# np.vectorize actually creates a new function
avg_2_mod_vec = np.vectorize(avg_2_mod)

# use the newly vectorized function
avg_2_mod_vec( df['a'], df['b'] )

```

]


.panel[.panel-name[w/ np (2)]

- Sometimes, we want to modify an existing function without changing its source code. 
  - We can then consider using a decorator.


- A decorator is a function that takes one function as input and returns another function.


- We can add `@decorator_name` before the function that we want to decorate:
]

.panel[.panel-name[w/ np (3)]
```{python}
# to use the vectorize decorator
# we use the @ symbol before our function definition
@np.vectorize
def v_avg_2_mod(x, y):
   if x == 20:
     return np.NaN
   else:
     return (x + y) / 2
   
v_avg_2_mod( df['a'], df['b']) )
```

]



]







---
class: inverse, center, middle

# Exporting and Importing Data

---
# Exporting and Importing Data
### <p style="color:#00449E"> Pickle </p>


.panelset[

.panel[.panel-name[(1)]
- Python has a way to `pickle` data. 
  - This is Python’s way of serializing and saving data in a binary format.
  - `pickle` files are usually saved with an extension of `.p`, `.pkl`, or `.pickle`.
  - If we try to open it in a text editor, we will see a bunch of garbled characters.

- Create the `output` folder in your working directory.
  - We will use the `output` folder to store the exported `Series` or `DataFrame`.
]

.panel[.panel-name[(2)]
- To export `Series` or `DataFrame` as a `pickle` file, we use the `to_pickle()` method.
```{python}
# pass in a string to the path you want to save
scientists.to_pickle('output/scientists_df.pickle')
```
]

.panel[.panel-name[(3)]
- To read `pickle` data, we can use the `pd.read_pickle()` function.

```{python}
dataframe_pickle = pd.read_pickle(
  'output/scientists_df.pickle'
  )
```

]

]


---
# Exporting and Importing Data
### <p style="color:#00449E">  Comma-Separated Values (CSV) </p>

- Comma-separated values (CSV) are the most flexible data storage type.
  - For each row, the column information is separated with a comma.


- To export `Series` or `DataFrame` as a `csv` file, we use the `to_csv()` method.

```{python}
# index =False  does not write the row names in the CSV output
scientists.to_csv('output/scientists_df_no_index.csv', 
                   index =False)
```



---
# Exporting and Importing Data
### <p style="color:#00449E"> Excel </p>

- The more of your work you can do in Python and/or R, the easier it will be to scale up to larger projects, catch and fix mistakes, and collaborate. 

- However, Excel’s popularity and market share are unrivaled. 

- To export `Series` or `DataFrame` as an `.xlsx` file, we use the `to_excel()` method.

```{python}
# saving a DataFrame into Excel format
scientists.to_excel(
  "output/scientists_df.xlsx",
  sheet_name = "scientists",
  index = False)
```





---
class: inverse, center, middle

# Exploratory Data Analysis with `Seaborn`
<html><div style='float:left'></div><hr color='#EB811B' size=1px width=796px></html>

---
# Exploratory Data Analysis 
### <p style="color:#00449E">  </p>

- Here we discuss how to use summary statistics and visualization to explore your data in a systematic way, a task that statisticians call **exploratory data analysis** (EDA). 


- EDA is an iterative cycle. We:
  - Generate questions about your data.
  - Search for answers by visualizing, transforming, and modelling our data.
  - Use what we learn to refine our questions and/or generate new questions.
  
- Here, we focus on the visualization part.
  


---
# Exploratory Data Analysis 
### <p style="color:#00449E"> Tidy `data.frame` </p>

```{r, echo=FALSE, eval = T, warning=F, message=F, out.width = '90%', fig.align='center'}
knitr::include_graphics("../lec_figs/tidy-1.png")
```

- In a tidy `DataFrame`,
  - A **variable** is in a column.
  - An **observation** is in a row. 
  - A **value** are in a cell.


---
# Exploratory Data Analysis 
### <p style="color:#00449E"> Tidy `data.frame` </p>

- A **variable** is a quantity, quality, or property that we can measure/count.
  
  
- An **observation** is a set of measurements made under similar conditions (e.g, similar unit of entity, time, and/or geography).
  - We usually make all of the measurements in an observation at the same time and on the same object.
  - An observation will contain several values, each associated with a different variable.
  - We sometimes refer to an observation as a data point.


- The **value** of a variable may change from measurement to measurement.


---
# Exploratory Data Analysis 
### <p style="color:#00449E"> Categorical/Discrete vs. Continuous Variables </p>


- A **discrete/categorical variable** is a variable whose value is obtained by *counting* and is whole numbers.
  - Number of red marbles in a jar
  - Number of heads when flipping three coins 
  - Students’ letter grade
  - US state/county


- A **continuous variable** is a variable whose value is obtained by *measuring*  and can have a decimal or fractional value.
  - Height/weight of students
  - Time it takes to get to school
  - Fuel efficiency of a vehicle (e.g., miles per gallon)


---
# Exploratory Data Analysis 
### <p style="color:#00449E"> Making Discoveries from a Data Set </p>

.panelset[

.panel[.panel-name[Distribution]
- What type of **variation** occurs within a variable?


- **Variation** is the tendency of the values of a variable to change from measurement to measurement. 
  - We can see variation easily in real life; if we measure any continuous variable twice, we will be likely to get two different values.
  - Which values are the most common? Why?
  - Which values are rare? Why? Does that match your expectations?
  - Can we see any unusual patterns? What might explain them?

]

.panel[.panel-name[Relationship]
- **Co-variation** is the tendency for the values of two or more variables to vary together in a related way. 


- What type of **co-variation** occurs between variables?

]

.panel[.panel-name[Steps]

- Figure out whether variables of interests are categorical or continuous.

- Think which geometric objects, aesthetic mappings, and faceting are appropriate to visualize distributions and relationships.

- If needed, transform a given `DataFrame` (e.g., subset of observations, new variables, summarized data) and try new visualizations.

]

.panel[.panel-name[Types]

  - A distribution of a categorical variable (e.g., bar charts and more)
  - A distribution of a continuous variable (e.g., histograms and more)
  - A relationship between two categorical variables (e.g., bar charts and more)
  - A relationship between two continuous variables (e.g., scatter plots  and more)
  - A relationship between a categorical variable and a continuous variable (e.g., boxplots and more)
  - A time trend of a categorical variable (e.g., bar plots and more)
  - A time trend of a continuous variable (e.g., line plots and more)
  
]

.panel[.panel-name[Summary Stat.]

- Use `skim(DataFrame)` or `.describe()` to know:

  - Mean (Average, Expected Value);
  
  - Standard Deviation (SD)
  
  - Minimum, First Quartile (Q1), Median (Q2), Third Quartile (Q3), and Maximum.

]

]



---
class: inverse, center, middle

# Data Visualization with `seaborn`


---
# Data Visualization

.pull-left[

```{r, echo=FALSE, eval = T, out.width = '67%', fig.align='center'}
knitr::include_graphics("../lec_figs/lego.png")
```

]
.pull-right[
- Graphs and charts let us explore and learn about the structure of the information we have in DataFrame. 

- Good data visualizations make it easier to communicate our ideas and findings to other people. 


]


---
#  `seaborn`

```{r, echo=FALSE, out.width = '20%', fig.align='center'}
knitr::include_graphics("../lec_figs/seaborn-logo.png")
```

- `seaborn` is a Python data visualization library based on `matplotlib`. 
  - It allows us to easily create beautiful but complex graphics using a simple interface.
  - It also provides a general improvement in the default appearance of `matplotlib`-produced plots, and so I recommend using it by default.

```{python, echo = T, eval = F}
import seaborn as sns
sns.set_theme(rc={'figure.dpi': 600, 
                  'figure.figsize': (5, 3.75)})   # better quality

```


---
# Data Visualization with `seaborn`
### <p style="color:#00449E"> Getting started with `seaborn`

- Let's get the names of `DataFrame`s provided by the `seaborn` library:

```{python, echo = T, eval = F}
import seaborn as sns
print( sns.get_dataset_names() )
```


- Let's use the `titanic` and `tips` DataFrames:

```{python, echo = T, eval = F}
titanic = sns.load_dataset('titanic')
titanic.head()
tips = sns.load_dataset('tips')
tips.head()
```




---
# Data Visualization with `seaborn`
### <p style="color:#00449E"> Bar Chart 

- A bar chart is used to plot the frequency of the different categories.
  - It is useful to visualize how values of a **categorical variable** are distributed.
  - A variable is **categorical** if it can only take one of a small set of values.
  
  
- We use `sns.countplot()` function to plot a bar chart:


.pull-left[
```{python, echo = T, eval = F}
sns.countplot(data = titanic,
              x =  'sex')
```
]

.pull-right[

- Mapping
  - `data`: DataFrame.
  - `x`:  Name of a categorical variable (column) in DataFrame

]








---
# Data Visualization with `seaborn`
### <p style="color:#00449E"> Bar Chart 

- We can further break up the bars in the bar chart based on another categorical variable. 

  - This is useful to visualize the relationship between the two categorical variables.


.pull-left[
```{python, echo = T, eval = F}
sns.countplot(data = titanic,
              x = 'sex'
              hue = 'survived')
```
]

.pull-right[

- Mapping
  - `hue`:  Name of a categorical variable

]





---
# Data Visualization with `seaborn`
### <p style="color:#00449E"> Histogram 

- A histogram is a **continuous** version of a bar chart.
  - It is used to plot the frequency of the different values.
  - It is useful to visualize how values of a **continuous variable** are distributed.

  
- We use `sns.histplot()` function to plot a histogram:
.pull-left[
```{python, echo = T, eval = F}
sns.histplot(data = titanic,
             x =  'age', 
             bins = 5)
```
]

.pull-right[
- Mapping
  - `bins`:  Number of bins

]




---
# Data Visualization with `seaborn`
### <p style="color:#00449E"> Histogram 

- A boxplot computes a summary of the distribution and then display a specially formatted box.
  - It is useful to visualize how values of a **continuous variable** are distributed across different values of another (categorical) variable.
  
  
- We use `sns.histplot()` function to plot a histogram:
.pull-left[
```{python, echo = T, eval = F}
sns.boxplot(data = tips,
             y='total_bill')
```
]

.pull-right[
```{python, echo = T, eval = F}
sns.boxplot(data = tips,
            x='time', y='total_bill')
```
]






---
# Data Visualization with `seaborn`
### <p style="color:#00449E"> Scatter plot 

- A scatter plot is used to display the relationship between two continuous variables.

  -  We can see co-variation as a pattern in the scattered points.

- We use `sns.scatterplot()` function to plot a scatter plot:

.pull-left[
```{python, echo = T, eval = F}
sns.scatterplot(data = tips,
                x = 'total_bill', 
                y = 'tip')
```
]

.pull-right[
- Mapping
  - `x`:  Name of a continuous variable on the horizontal axis
  - `y`:  Name of a continuous variable on the vertical axis
]


---
# Data Visualization with `seaborn`
### <p style="color:#00449E"> Scatter plot 

- To the scatter plot, we can add a `hue`-`VARIABLE` mapping to display how the relationship between two continuous variables varies by `VARIABLE`.

- Suppose we are interested in the following question:
  - **Q**. Does a smoker and a non-smoker have a difference in tipping behavior?

```{python, echo = T, eval = F}
sns.scatterplot(data = tips,
                x = 'total_bill', 
                y = 'tip',
                hue = 'smoker')
```



---
# Data Visualization with `seaborn`
### <p style="color:#00449E"> Fitted line 

- From the scatter plot, it is often difficult to clearly see the relationship between two continuous variables.

  - `sns.lmplot()` adds a line that fits well into the scattered points.
  
  - On average, the fitted line describes the relationship between two continuous variables.
  

```{python, echo = T, eval = F}
sns.lmplot(data = tips,
           x = 'total_bill', 
           y = 'tip')
```





---
# Data Visualization with `seaborn`
### <p style="color:#00449E"> Transparency with `alpha`

- In a scatter plot, adding transparency with `alpha` helps address many data points on the same location.
  - We can map `alpha` to number between 0 and 1.
  
.pull-left[
```{python, echo = T, eval = F}
sns.scatterplot(x = 'total_bill', 
                y = 'tip',
                hue = 'smoker',
                alpha = .25)
```
]

.pull-left[
```{python, echo = T, eval = F}
sns.lmplot(data = tips,
           x = 'total_bill', 
           y = 'tip',
           scatter_kws = {'alpha' : 0.2})
```
]




---
# Data Visualization with `seaborn`
### <p style="color:#00449E"> Scatter plot 

- To the scatter plot, we can add a `hue`-`VARIABLE` mapping to display how the relationship between two continuous variables varies by `VARIABLE`.

- Using the fitted lines, let's answer the following question:
  - **Q**. Does a smoker and a non-smoker have a difference in tipping behavior?

```{python, echo = T, eval = F}
sns.scatterplot(data = tips,
                x = 'total_bill', 
                y = 'tip',
                hue = 'smoker')
```

  


---
# Data Visualization with `seaborn`
### <p style="color:#00449E"> Line cahrt 

- A line chart is used to display the trend in a continuous variable or the change in a continuous variable over other variable.
  - It draws a line by connecting the scattered points in order of the variable on the x-axis, so that it highlights exactly when changes occur.
- We use `sns.lineplot()` function to plot a line plot:
.pull-left[
```{python, echo = T, eval = F}
path_csv = 'https://bcdanl.github.io/data/dji.csv'
dow = pd.read_csv(path_csv, index_col=0, parse_dates=True)
sns.lineplot(data = dow,
             x =  'Date', 
             y =  'Close')
```
]

.pull-right[
- Mapping
  - `x`:  Name of a continuous variable (often time variable) on the horizontal axis 
  - `y`:  Name of a continuous variable on the vertical axis
]


---
# Data Visualization with `seaborn`
### <p style="color:#00449E"> Line cahrt 

- For line charts, we often need to group or connect observations to visualize the number of distinct lines.

```{python, echo = T, eval = F}
healthexp = ( sns.load_dataset("healthexp")
             .sort_values(["Country", "Year"])
             .query("Year <= 2020") )
healthexp.head()

sns.lineplot(data = dow,
             x =  'Year', 
             y =  'Life_Expectancy',
             color = 'Country')
```


---
# Data Visualization with `seaborn`
### <p style="color:#00449E"> Faceting

- Faceting allows us to plot subsets (facets) of our data across subplots. 

.panelset[
.panel[.panel-name[Step 1. FacetGrid()]
- First, we create a `FacetGrid()` object with the data we will be using and define how it will be subset with the `row` and `col` arguments: 
```{python}
g = sns.FacetGrid(
      data = titanic,
      row='class',
      col='sex')
```

]

.panel[.panel-name[Step2. FacetGrid().map()]
- Secodn, we use the `FacetGrid().map()` method to run a plotting function on each of the subsets, passing along any necessary arguments.
```{python}
g.map(sns.histplot, 'age', kde=True)  # kde: kernel density (probability density function)
```

]
]




