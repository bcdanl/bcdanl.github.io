---
title: "Price Elasticities of Orange Juice Demand"
author: "Byeong-Hak Choe<br><br>"
date: "February 4, 2022<br><br>"
output: 
  html_document:
    df_print: paged
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
    highlight: espresso
---

This is an example of the lecture on estimating price elasticity via the model of linear regression with interaction terms using data for orange juice sales. The example is taken from the book, "[Business Data Science: Combining Machine Learning and Economics to Optimize, Automate, and Accelerate Business Decisions](https://www.amazon.com/Business-Data-Science-Combining-Accelerate/dp/1260452778)," and modified by Byeong-Hak Choe.

<br>

- Price elasticity of demand

Price elasticity of demand  measures how sensitive the quantity demanded is to its price.  

<center>
$(\; Price\; elasticity\; of\; demand \; )\, =\,  (\; \%\;  Change\; in\; quantity\;  demanded)\,/\,(\%\;  Change\; in\;  price\;)$
</center>  
  
The concept of the elasticity plays an important role in industries.  

Marketers need to understand how consumers are sensitive to fluctuations in price.  

<br>

- Loading R packages and orange juice data

```{r, echo = TRUE, eval = TRUE, out.height = "100%",  fig.align='center'}
# install.packages("")  # in case you need to install the following R packages

library(tidyverse)  # ggplot and more
theme_set(theme_minimal()) # minimal theme for ggplot
library(skimr) # a better summary of data
library(stargazer)  # regression tables
library(moderndive) # geom_parallel_slopes()
```

We will use weekly sales data for orange juice (OJ) from Dominickâ€™s grocery stores in the 1990s.  

```{r, echo = TRUE, eval = TRUE, out.height = "100%",  fig.align='center'}
oj <- read.table(
  'https://bcdanl.github.io/data/dominick_oj.csv',
  sep = ',',
  header = TRUE,
  stringsAsFactor = TRUE
)
```

<br>


# Descriptive statistics

## OJ data

```{r, echo = TRUE, eval = TRUE, out.height = "100%",  fig.align='center'}
head(oj)
```

`levels()` prints out the categories of the factor variable.

```{r, echo = TRUE, eval = TRUE, out.height = "100%",  fig.align='center'}
levels(oj$brand)
```

`skim()` gives an output of summary statistics with more information including standard deviations, missing values, number of categories for character variables, and histograms. 

```{r, echo = TRUE, eval = TRUE, out.height = "100%",  fig.align='center'}
skim(oj)
```


<br>


# Visualizing OJ data

## Distribution of OJ prices

It is better to use a logarithmic scale when percent change matters.  

```{r, echo = TRUE, eval = TRUE, fig.height = 4, fig.align='center'}

ggplot(data = oj) + 
  geom_boxplot( aes( y = log(price), color = brand )) +
  theme(axis.text.x = element_blank(), axis.ticks = element_blank())

```

<br>


## Distribution of OJ sales

```{r, echo = TRUE, eval = TRUE, fig.height = 4, fig.align='center'}

ggplot(data = oj) + 
  geom_boxplot( aes( y = log(sales), color = brand )) +
  theme(axis.text.x = element_blank(), axis.ticks = element_blank())
```

<br>


## Demand for OJ

```{r, echo = TRUE, eval = TRUE, fig.height = 4, fig.align='center', warning = FALSE, message = FALSE}
ggplot(data = oj, aes( x = log(price), y = log(sales), 
                       color = brand )) + 
  geom_point( alpha = .25 ) 
```

<br>

# Regression models

## Regression model with brand dummies
The regression model for price elasticity of OJ demand can be written as:

<center>
$\log({sales}) = \alpha_{{brand}} + \beta\log({price}) + \epsilon$
</center>  
  

Here $\alpha_{{brand}}$ is shorthand for a separate indicator for each OJ brand:

<center>
$\alpha_{{brand}} = \alpha_{{d}}1_{{[brand=dominicks]}}+\alpha_{{m}}1_{{[brand=minut.emaid]}}+\alpha_{{t}}1_{{[brand=tropicana]}}$
</center>  
  

By the property of natural log, $\beta$ measures the price elasticity of OJ demand:

<center>
$\beta = \Delta\log({sales})/\Delta\log({price})$
</center>  


<br>


## Run the model 

```{r results = "asis", echo = TRUE, eval = TRUE, fig.height = 4, fig.align='center'}

reg_oj1 <- lm(log(sales) ~ log(price) + brand, 
             data=oj)
stargazer(reg_oj1, type = "html", omit = c("Constant"))
```

<br>


## Regression lines

```{r, echo = TRUE, eval = TRUE, fig.height = 4, fig.align='center'}

ggplot(data = oj, aes(x = log(price), y = log(sales), 
                      color = brand )) +
  geom_point(size = .75, alpha = 0.25) +
  geom_parallel_slopes()

```

<br>


## Regerssion model with interaction terms

How does consumer price sensitivity change across brands?

The new regression model can be written as:

<center>
$\log({sales}) = \alpha_{{brand}} + \beta_{{brand}}\log({price}) + \epsilon$
</center>  
  
Here $\beta_{{brand}}$ is shorthand for the brand-specific price elasticity:

<center>
$\beta_{{brand}} = \hspace{.1cm}\beta_{{d}}1_{{[brand=dominicks]}}+\beta_{{m}}1_{{[brand=minutemaid]}}+\beta_{{t}}1_{{[brand=tropicana]}}\hspace{.1cm}$
</center>  


<br>


## Run the model

```{r results = "asis", echo = TRUE, eval = TRUE, out.height = "50%", fig.align='center'}

reg_oj2 <- lm(log(sales) ~ log(price)*brand, 
             data=oj)
stargazer(reg_oj1, reg_oj2, type = "html", omit = c("Constant"))
```

<br>


## Regression lines 

```{r, echo = TRUE, eval = TRUE, fig.height = 4, fig.align='center', warning=FALSE, message=FALSE}

ggplot(data = oj, aes(x = log(price), y = log(sales), 
                      color = brand )) +
  geom_point(size = .75, alpha = 0.25) +
  geom_smooth(method = lm, se=FALSE)

```

<br>


## Advertisement effect

How does consumer price sensitivity change with advertisement?

The new regression model can be written as:

<center>
$\log({sales}) = \alpha_{{brand,feat}} + \beta_{{brand,feat}}\log({price}) + \epsilon$
</center>  
  

Here $\beta_{{brand,feat}}$ measures the brand-feat-specific price elasticity:

<center>
$\beta_{{brand,feat}} = \hspace{.3cm}(\hspace{.1cm} \beta_{{d,noAd}}1_{{[brand=dominicks]}}+\beta_{{m,noAd}}1_{{[brand=minutemaid]}}\\\hspace{5.25cm}+\beta_{{t,noAd}}1_{{[brand=tropicana]}}\hspace{.1cm})\times1_{{[feat=0]}}\\   \hspace{2.5cm} + (\hspace{.1cm}\beta_{{d,Ad}}1_{{[brand=dominicks]}}+\beta_{{m,Ad}}1_{{[brand=minutemaid]}}\\\hspace{5.25cm}+\beta_{{t,Ad}}1_{{[brand=tropicana]}}\hspace{.1cm})\times1_{{[feat=1]}}$
</center>  


<br>


## Run the model

```{r results = "asis", echo = TRUE, eval = TRUE, out.height = "50%", fig.align='center'}

reg_oj3 <- lm(log(sales) ~ log(price)*brand*feat, 
             data=oj)
stargazer(reg_oj1, reg_oj2, reg_oj3, type = "html", omit = c("Constant"))
```

<br>


## Regression lines

```{r, echo = TRUE, eval = TRUE, fig.height = 4, fig.align='center', warning = FALSE, message = FALSE}

ggplot(data = oj, aes(x = log(price), y = log(sales), color = brand )) +
  geom_point(size = .75, alpha = 0.25) +
  geom_smooth(method=lm) +
  facet_grid( . ~ feat)

```

<br>


## Price elasticities of OJ

```{r, echo = FALSE, eval = TRUE, out.height = "75%", fig.align='center'}
coef1 <-  coef(reg_oj1)
coef2 <-  coef(reg_oj2)
coef3 <-  coef(reg_oj3)
elasticity <- data.frame(
  "dominicks" = c(coef1['log(price)'],coef2['log(price)'],coef3['log(price)'],coef3['log(price)']+coef3['log(price):feat']),
  "minute.maid" = c(coef1['log(price)'],
                coef2['log(price)']+coef2['log(price):brandminute.maid'], coef3['log(price)']+coef3['log(price):brandminute.maid'], coef3['log(price)']+coef3['log(price):brandminute.maid']+coef3['log(price):feat']+coef3['log(price):brandminute.maid:feat']),
  "tropicana" = c(coef1['log(price)'],
                coef2['log(price)']+coef2['log(price):brandtropicana'], coef3['log(price)']+coef3['log(price):brandtropicana'], coef3['log(price)']+coef3['log(price):brandtropicana']+coef3['log(price):feat']+coef3['log(price):brandtropicana:feat'])
  )
row.names(elasticity) <- c("Model 1", "Model 2", "Model 3 w/ no ad", "Model 3 w/ ad")

knitr::kable(round(elasticity,1), "simple")   
```

- Which model is better?  

- Which model is more realistic?  
  
- Why does being featured always lead to more price sensitivity?  


<br>


## The relationship between ad and brand

```{r, echo = TRUE, eval = TRUE, fig.height = 4, fig.align='center'}
by_brand <- group_by(oj, brand, feat)
salestable <- mutate(by_brand, 
                        sales_tot = 
                          sum(sales, na.rm = TRUE)
                        ) %>% 
  select(sales_tot, brand, feat) %>% 
  unique()

salestable <- salestable %>% group_by(feat) %>% 
  mutate(sales_prop = sales_tot/sum(sales_tot))

ggplot(data = salestable) +
  geom_bar(mapping = aes(x = factor(feat), y = sales_prop, 
                         fill = brand), stat = "identity") + 
    xlab("feat") + ylab("proportion of sales") + scale_x_discrete(breaks=c(0, 1), labels=c("no ad", "ad"))

```



```{r, echo = TRUE, eval = TRUE, fig.height = 4, fig.align='center'}

ggplot(data = oj) + 
  geom_boxplot( aes( y = log(price), color = brand )) +
  facet_grid( . ~ feat) +
  theme(axis.text.x = element_blank(), axis.ticks = element_blank())

```


```{r, echo = TRUE, eval = TRUE, fig.height = 4, fig.align='center'}

ggplot(data = oj) + 
  geom_boxplot( aes( y = log(sales), color = brand )) +
  facet_grid( . ~ feat) +
  theme(axis.text.x = element_blank(), axis.ticks = element_blank())
```

```{r, echo = TRUE, eval = TRUE, fig.height = 4, fig.align='center', warning = FALSE, message = FALSE}
ggplot(data = oj, aes( x = log(price), y = log(sales), 
                       color = brand )) + 
  geom_point( alpha = .25 ) +
  facet_grid( . ~ feat)
```


<br>



## Residual plot and model fit

- Which model is better?

  - On average, are the predictions correct?

  - Are there systematic errors in prediction?

<br>

Predicted log of sales can be calculated as follows:

```{r, echo = TRUE, eval = TRUE, fig.height = 3.8, fig.align='center', warning=FALSE, message=FALSE}
oj$predLogSales1 <- predict(reg_oj1, newdata = oj)
oj$predLogSales2 <- predict(reg_oj2, newdata = oj)
oj$predLogSales3 <- predict(reg_oj3, newdata = oj)
```

<br>


## Residual plot for model 1

```{r, echo = TRUE, eval = TRUE, fig.height = 3.8, fig.align='center', warning=FALSE, message=FALSE}
# Residual plot 1
ggplot(data = oj, aes(x = predLogSales1, y = log(sales) - predLogSales1 )) +
  geom_point(alpha = 0.2, color = "orange") + geom_smooth(color = "darkblue") +
  geom_line(aes(x = predLogSales1, y = 0), color = "red", linetype = 2) +
  xlab("prediction") + ylab("residual error (actual prediction)")
```

<br>


## Residual plot for model 2

```{r, echo = TRUE, eval = TRUE, fig.height = 3.8, fig.align='center', warning=FALSE, message=FALSE}
# Residual plot 2
ggplot(data = oj, aes(x = predLogSales2, y = log(sales) - predLogSales2 )) +
  geom_point(alpha = 0.2, color = "orange") + geom_smooth(color = "darkblue") +
  geom_line(aes(x = predLogSales2, y = 0), color = "red", linetype = 2) +
  xlab("prediction") + ylab("residual error (actual prediction)")
```

<br>


## Residual plot for model 3

```{r, echo = TRUE, eval = TRUE, fig.height = 3.8, fig.align='center', warning=FALSE, message=FALSE}
# Residual plot 3
ggplot(data = oj, aes(x = predLogSales3, y = log(sales) - predLogSales3 )) +
  geom_point(alpha = 0.2, color = "orange") + geom_smooth(color = "darkblue") +
  geom_line(aes(x = predLogSales3, y = 0), color = "red", linetype = 2) +
  xlab("prediction") + ylab("residual error (actual prediction)")
```