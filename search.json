[
  {
    "objectID": "listing-danl-101-qa.html",
    "href": "listing-danl-101-qa.html",
    "title": "DANL 101 - Q & A",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nSetting the Tool\n\n\nundefined\n\n\nSeptember 5, 2024\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "listing-danl-101-hw.html",
    "href": "listing-danl-101-hw.html",
    "title": "DANL 101 - Homework",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nHomework Assignment 2 - Example Answers\n\n\n\n\n\nOctober 10, 2024\n\n\n\n\nHomework Assignment 2\n\n\n\n\n\nOctober 4, 2024\n\n\n\n\nHomework Assignment 1 - Example Answers\n\n\n\n\n\nOctober 3, 2024\n\n\n\n\nHomework Assignment 1\n\n\n\n\n\nSeptember 19, 2024\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "listing-danl-101-cw.html",
    "href": "listing-danl-101-cw.html",
    "title": "DANL 101 - Classwork",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nfilter(), arrange(), and distinct()\n\n\nClasswork 4\n\n\nOctober 7, 2024\n\n\n\n\nselect() and rename()\n\n\nClasswork 6\n\n\nOctober 7, 2024\n\n\n\n\nQuiz 1 - Addendum\n\n\nClasswork 7\n\n\nOctober 7, 2024\n\n\n\n\nQuiz 1\n\n\nClasswork 5\n\n\nOctober 4, 2024\n\n\n\n\nleft_join()\n\n\nClasswork 3\n\n\nSeptember 26, 2024\n\n\n\n\nR Basics II\n\n\nClasswork 2\n\n\nSeptember 18, 2024\n\n\n\n\nR Basics I\n\n\nClasswork 1\n\n\nSeptember 16, 2024\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "blog-listing.html",
    "href": "blog-listing.html",
    "title": "Big & tiny insights through data",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nNBA\n\n\n3 min\n\n\n\nByeong-Hak Choe\n\n\nFebruary 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython Basics\n\n\n1 min\n\n\n\nByeong-Hak Choe\n\n\nFebruary 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Galaxy: A Data-Driven Journey Through the Star Wars Universe\n\n\n8 min\n\n\n\nByeong-Hak Choe\n\n\nFebruary 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeer Markets\n\n\n5 min\n\n\n\nByeong-Hak Choe\n\n\nNovember 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n1 min\n\n\n\nByeong-Hak Choe\n\n\nOctober 27, 2023\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "danl-qa/danl-101-04-qa.html",
    "href": "danl-qa/danl-101-04-qa.html",
    "title": "Setting the Tool",
    "section": "",
    "text": "Welcome to our Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the course materials.\nWhether you are looking to delve deeper into the slides, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions to Byeong-Hak (@bcdanl) or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!\n\n\n\n Back to top"
  },
  {
    "objectID": "index-home.html",
    "href": "index-home.html",
    "title": "Byeong-Hak Choe",
    "section": "",
    "text": "Hello! üëã\nI am an assistant professor of data analytics and economics at School of Business at SUNY Geneseo.\nMy research interests lie in economics of the environment and climate change."
  },
  {
    "objectID": "index-home.html#research",
    "href": "index-home.html#research",
    "title": "Byeong-Hak Choe",
    "section": "Research",
    "text": "Research\n\nWorking papers\n1Ô∏è‚É£ Social Media Campaign, Lobbying, and Legislation: Evidence from #cliamtechange and Energy Lobbies\n2Ô∏è‚É£ Climate Finance under Conflicts and Renegotiations: A Dynamic Contract Approach\n\n\nWork in progress\nüåü ‚ÄòHiding Behind a Small Cake‚Äô in an Online Dictator Game: The Way You Hide Matters!, (with TabareÃÅ Capitan (1st author) , Jason Shogren, and Benjamin White).\nüåü Estimating the Value of Statistical Life through Big Data, (with Stephen Newbold and Alexander James).\n\n\nBook chapters\nüí° Governance and Climate Finance in the Developing World (with Tilsa Or√©-Monago).\n-¬†In Wu, F., Zhang, D., and Ji, Q. (Eds.), Climate Finance: Supporting a Sustainable Energy Transition, Chapter 7, Springer Nature (July, 2024)."
  },
  {
    "objectID": "danl-cw/danl-101-cw-01.html",
    "href": "danl-cw/danl-101-cw-01.html",
    "title": "R Basics I",
    "section": "",
    "text": "base-R provides the R object state.name. Write an R code to assign state.name to a variable, US_states.\nAnswer:\n\nUS_states &lt;- state.name\n\n\nstate.name is a predefined R object that contains the names of all 50 U.S. states. The code assigns the contents of state.name to a new variable US_states, effectively storing the state names in this new variable.\n\nIn the general R environment, a variable is a name assigned to any object or data stored in memory, whether it‚Äôs a simple value, a vector, or a more complex structure like a data frame. For this reason, I often refer to a variable as ‚Äúthe name of this object‚Äù in the general R environment.\nIn a data.frame, a variable is a column that represents a particular attribute of the data.frame."
  },
  {
    "objectID": "danl-cw/danl-101-cw-01.html#question-1.",
    "href": "danl-cw/danl-101-cw-01.html#question-1.",
    "title": "R Basics I",
    "section": "",
    "text": "base-R provides the R object state.name. Write an R code to assign state.name to a variable, US_states.\nAnswer:\n\nUS_states &lt;- state.name\n\n\nstate.name is a predefined R object that contains the names of all 50 U.S. states. The code assigns the contents of state.name to a new variable US_states, effectively storing the state names in this new variable.\n\nIn the general R environment, a variable is a name assigned to any object or data stored in memory, whether it‚Äôs a simple value, a vector, or a more complex structure like a data frame. For this reason, I often refer to a variable as ‚Äúthe name of this object‚Äù in the general R environment.\nIn a data.frame, a variable is a column that represents a particular attribute of the data.frame."
  },
  {
    "objectID": "danl-cw/danl-101-cw-01.html#question-2.",
    "href": "danl-cw/danl-101-cw-01.html#question-2.",
    "title": "R Basics I",
    "section": "Question 2.",
    "text": "Question 2.\nThe temp_F vector contains the average high temperatures in January for the following cities: Seoul, Lagos, Paris, Rio de Janeiro, San Juan, and Rochester.\n\ntemp_F &lt;- c(35, 88, 42, 84, 81, 30)\n\nCreate a new vector named temp_C that stores the converted Celsius temperatures. Below is the conversion formula:\n\\[\nC = \\frac{5}{9}\\times(F - 32)\n\\]\nAnswer:\n\ntemp_F &lt;- c(35, 88, 42, 84, 81, 30)\ntemp_C &lt;- (5/9) * (temp_F - 32)\ntemp_C\n\n[1]  1.666667 31.111111  5.555556 28.888889 27.222222 -1.111111\n\n\nThe formula to convert Fahrenheit to Celsius is applied element-wise to the temp_F vector, which stores the temperatures in Fahrenheit. The code then assigns the converted Celsius temperatures to the temp_C vector."
  },
  {
    "objectID": "danl-cw/danl-101-cw-01.html#question-3.",
    "href": "danl-cw/danl-101-cw-01.html#question-3.",
    "title": "R Basics I",
    "section": "Question 3.",
    "text": "Question 3.\n\nWrite an R code to calculate the standard deviation (SD) of the integer vector x below manually. That is to calculate the SD without using the sd() or the var() functions.\n\n\nx &lt;- 1:25\n\n\nAlso, write an R code to test whether the standard deviation you calculate manually above is equal to sd(x).\n\nAnswer:\n\n# Manual calculation of standard deviation\nn &lt;- length(x)\nmean_x &lt;- sum(x) / n\nvariance_manual &lt;- sum((x - mean_x)^2) / (n - 1)\nsd_manual &lt;- sqrt(variance_manual)\n\n# Test if it is equal to sd(x)\nsd_manual == sd(x)\n\n[1] TRUE\n\n\n\nThe formula for standard deviation is the square root of the variance. Variance is calculated as the sum of the squared differences from the mean, divided by the number of observations minus 1 (for a sample).\nThe sd_manual is then compared to the result of the built-in sd() function to ensure correctness."
  },
  {
    "objectID": "danl-cw/danl-101-cw-01.html#question-4.",
    "href": "danl-cw/danl-101-cw-01.html#question-4.",
    "title": "R Basics I",
    "section": "Question 4.",
    "text": "Question 4.\n\nConsider the vectors:\n\n\nmy_vec &lt;- c(-10, -20, 30, 10, 50, 40, -100)\nbeers &lt;- c(\"BUD LIGHT\", \"BUSCH LIGHT\", \"COORS LIGHT\", \n           \"GENESEE LIGHT\", \"MILLER LITE\", \"NATURAL LIGHT\")\n\n\nWrite an R code to filter only the positive values in my_vec.\nWrite an R code to access the beers that are in positions 2, 4, and 6 using indexing.\n\nAnswer:\n\n# Filtering positive values\npositive_values &lt;- my_vec[my_vec &gt; 0]\n\n# Accessing beers in positions 2, 4, and 6\nbeers &lt;- c(\"BUD LIGHT\", \"BUSCH LIGHT\", \"COORS LIGHT\", \n           \"GENESEE LIGHT\", \"MILLER LITE\", \"NATURAL LIGHT\")\nselected_beers &lt;- beers[c(2, 4, 6)]\n\npositive_values\n\n[1] 30 10 50 40\n\nselected_beers\n\n[1] \"BUSCH LIGHT\"   \"GENESEE LIGHT\" \"NATURAL LIGHT\"\n\n\n\nThe positive values from my_vec are filtered using logical indexing (my_vec &gt; 0), and the selected beers are accessed using the positions 2, 4, and 6 through direct indexing (beers[c(2, 4, 6)])."
  },
  {
    "objectID": "danl-cw/danl-101-cw-01.html#question-5.",
    "href": "danl-cw/danl-101-cw-01.html#question-5.",
    "title": "R Basics I",
    "section": "Question 5.",
    "text": "Question 5.\n\nWrite an R code to read the CSV file, https://bcdanl.github.io/data/mlb_teams.csv using the tidyverse‚Äôs read_csv() function, and assign it to MLB_teams.\n\nAnswer:\n\nlibrary(tidyverse)  # to use the read_csv() function\nMLB_teams &lt;- read_csv(\"https://bcdanl.github.io/data/mlb_teams.csv\")\n\n\n\n\n\n\n\n\n\n\nThe read_csv() function from the tidyverse package is used to read the CSV file from the given URL and assign it to the name, MLB_teams. This function automatically handles reading in the CSV file and properly parsing the data."
  },
  {
    "objectID": "posts/starwars/starwars_df.html",
    "href": "posts/starwars/starwars_df.html",
    "title": "Exploring the Galaxy: A Data-Driven Journey Through the Star Wars Universe",
    "section": "",
    "text": "The Star Wars saga, spanning decades of films, series, and an expansive lore, has introduced us to an incredibly diverse array of characters, each contributing to the rich tapestry of its universe. But what can data tell us about these characters and their world? Leveraging the starwars.csv dataset, this blog post embarks on a data-driven exploration, uncovering insights and patterns through the lens of the R tidyverse."
  },
  {
    "objectID": "posts/starwars/starwars_df.html#the-cast-of-the-galaxy-loading-and-inspecting-the-data",
    "href": "posts/starwars/starwars_df.html#the-cast-of-the-galaxy-loading-and-inspecting-the-data",
    "title": "Exploring the Galaxy: A Data-Driven Journey Through the Star Wars Universe",
    "section": "The Cast of the Galaxy: Loading and Inspecting the Data",
    "text": "The Cast of the Galaxy: Loading and Inspecting the Data\nOur journey begins with the basics‚Äîloading the dataset and getting a sense of its structure:\n\n\nCode\nlibrary(tidyverse)\n\n# Load the dataset\nstarwars_data &lt;- read_csv(\"https://bcdanl.github.io/data/starwars.csv\")\n\n\nWith the data loaded, we find that it encompasses various attributes of Star Wars characters, including but not limited to their names, species, heights, weights, and allegiances. The diversity in species and homeworld paves the way for intriguing analyses.\n\n‚Üê ‚Üí\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Description for starwars data.frame\nThe following describes the variables in the starwars data.frame.\n\nfilms List of films the character appeared in\nname Name of the character\nspecies Name of species\nheight Height (cm)\nmass Weight (kg)\nhair_color, skin_color, eye_color Hair, skin, and eye colors\nbirth_year Year born (BBY = Before Battle of Yavin)\nsex The biological sex of the character, namely male, female, hermaphroditic, or none (as in the case for Droids).\ngender The gender role or gender identity of the character as determined by their personality or the way they were programmed (as in the case for Droids).\nhomeworld Name of homeworld\n\n\n\nCode\nskim(starwars_data) |&gt; \n  select(-n_missing)\n\n\n\nData summary\n\n\nName\nstarwars_data\n\n\nNumber of rows\n173\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n9\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\nskim_variable\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nfilms\n1.00\n10\n23\n0\n7\n0\n\n\nname\n1.00\n3\n21\n0\n87\n0\n\n\nspecies\n0.97\n3\n14\n0\n37\n0\n\n\nhair_color\n0.90\n4\n13\n0\n12\n0\n\n\nskin_color\n1.00\n3\n19\n0\n31\n0\n\n\neye_color\n1.00\n3\n13\n0\n15\n0\n\n\nsex\n0.97\n4\n14\n0\n4\n0\n\n\ngender\n0.97\n8\n9\n0\n2\n0\n\n\nhomeworld\n0.91\n4\n14\n0\n48\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nheight\n0.97\n171.31\n35.58\n66\n167\n178\n188\n264\n‚ñÇ‚ñÅ‚ñá‚ñÖ‚ñÅ\n\n\nmass\n0.79\n101.97\n190.62\n15\n55\n77\n84\n1358\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nbirth_year\n0.66\n108.86\n193.59\n8\n33\n52\n82\n896\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#unveiling-galactic-demographics-species-and-gender",
    "href": "posts/starwars/starwars_df.html#unveiling-galactic-demographics-species-and-gender",
    "title": "Exploring the Galaxy: A Data-Driven Journey Through the Star Wars Universe",
    "section": "Unveiling Galactic Demographics: Species and Gender",
    "text": "Unveiling Galactic Demographics: Species and Gender\nOur first foray into the galaxy‚Äôs demographics involves understanding the distribution of species and gender among the characters.\n\nSpecies in the Spotlight\n\n\nCode\n# Species distribution\nstarwars_data |&gt;\n  filter(!is.na(species)) |&gt; \n  group_by(species) |&gt;\n  summarise(count = n()) |&gt;\n  ggplot(aes(x = reorder(species, count), y = count, fill = species)) +\n  geom_col(show.legend = F) +\n  coord_flip() +\n  labs(title = \"Species Distribution in Star Wars\",\n       x = \"Species\",\n       y = \"Count\") +\n  theme_minimal() +\n  scale_fill_viridis_d()\n\n\n\n\n\nThis visualization reveals the prevalence of humans in the Star Wars universe, followed by a fascinating variety of alien species. Each species brings its unique culture and story to the narrative, enriching the saga‚Äôs diversity.\n\n\nGender Dynamics Across the Galaxy\n\n\nCode\n# Gender distribution by species\nstarwars_data |&gt;\n  filter(!is.na(gender)) |&gt; \n  group_by(species, gender) |&gt;\n  summarise(count = n()) |&gt;\n  ggplot(aes(y = reorder(species, count), x = count, fill = gender)) +\n  geom_bar(stat = \"identity\", position = position_dodge2(preserve = \"single\")) +\n  guides(fill = guide_legend(label.position = \"bottom\",\n                             keywidth = 2,\n                             nrow = 1)) +\n  theme_minimal() +\n  labs(title = \"Gender Distribution by Species\",\n       x = \"Species\",\n       y = \"Count\",\n       fill = \"Gender\") +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\nThe Height of Heroism: Analyzing Character Heights\nMoving from demographics, we explore physical characteristics, starting with character heights. This analysis could reveal whether heroes and villains differ significantly in stature.\n\n\nCode\n# Height distribution\nstarwars_data |&gt;\n  filter(!is.na(height)) |&gt;\n  ggplot(aes(x = height)) +\n  geom_histogram(aes(fill = ..count..), binwidth = 5, show.legend = F) +\n  scale_fill_viridis_c() +\n  labs(title = \"Height Distribution of Star Wars Characters\",\n       x = \"Height (cm)\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\nThe histogram of character heights may show a broad range, reflecting the diversity of the Star Wars universe, from towering Wookiees to diminutive droids.\n\n\nAllegiances and Homeworlds: The Galactic Divide\nAnother compelling aspect of the Star Wars saga is the clear delineation between factions, such as the Rebellion and the Empire. Analyzing characters‚Äô homeworld provides a window into the narrative‚Äôs structure.\n\n\nCode\n# homeworld distribution\nstarwars_data |&gt;\n  filter(!is.na(homeworld)) |&gt; \n  group_by(homeworld) |&gt;\n  summarise(count = n()) |&gt;\n  filter(count &gt; 3) |&gt; \n  ggplot(aes(x = fct_reorder(homeworld, count), y = count, fill = homeworld)) +\n  geom_col(show.legend = F) +\n  coord_flip() +\n  labs(title = \"Homeworlds in Star Wars\",\n       x = \"Homeworld\",\n       y = \"Count\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set3\")\n\n\n\n\n\nThis bar chart reveals not just the quantity of characters associated with major factions like the Rebel Alliance, the Galactic Empire, the Jedi Order, or the Sith, but also the lesser-known groups that play crucial roles in the galaxy‚Äôs balance of power. The visualization demonstrates the narrative‚Äôs rich backdrop, where allegiances define character motivations, actions, and, ultimately, their fates.\nSuch a distribution also prompts us to consider the narratives from a broader perspective‚Äîhow do these allegiances influence the storyline? Do characters within the same faction share similar traits or destinies? This opens up a deeper analysis of themes like loyalty, betrayal, and redemption that run through the Star Wars saga."
  },
  {
    "objectID": "posts/starwars/starwars_df.html#galactic-insights-conclusions-drawn-from-the-data",
    "href": "posts/starwars/starwars_df.html#galactic-insights-conclusions-drawn-from-the-data",
    "title": "Exploring the Galaxy: A Data-Driven Journey Through the Star Wars Universe",
    "section": "Galactic Insights: Conclusions Drawn from the Data",
    "text": "Galactic Insights: Conclusions Drawn from the Data\nOur journey through the Star Wars universe, guided by data, reveals not just the diversity and complexity of its characters but also the intricate web of relationships, conflicts, and themes that make the saga enduringly compelling. From the demographics of species and gender to the allegiances that define the galaxy‚Äôs political landscape, and the mystical underpinnings of the Force, our analysis has uncovered patterns and raised questions that deepen our appreciation of the Star Wars narrative.\nThis exploration also highlights the power of data visualization in uncovering insights and telling stories. Each chart and graph has provided a different lens through which to view the data, offering a new understanding of the Star Wars universe.\n\nThe Future of Galactic Analysis\nWhile we‚Äôve only scratched the surface of what‚Äôs possible with the starwars.csv dataset, the potential for further analysis is vast. Future explorations could delve into relationships between characters, the impact of different directors and writers on the portrayal of characters, or how the Star Wars universe has evolved over time.\nAs we conclude this data-driven journey, we‚Äôre reminded of the depth and breadth of the Star Wars saga‚Äîa testament to its creators and the community that keeps it alive. Whether through data analysis, storytelling, or simply enjoying the saga, the exploration of this galaxy far, far away continues to offer endless possibilities for discovery and insight."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#instructor-1",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#instructor-1",
    "title": "Lecture 1",
    "section": "Instructor",
    "text": "Instructor\nCurrent Appointment & Education\n\nName: Byeong-Hak Choe.\nAssistant Professor of Data Analytics and Economics, School of Business at SUNY Geneseo.\nPh.D.¬†in Economics from University of Wyoming.\nM.S. in Economics from Arizona State University.\nM.A.¬†in Economics from SUNY Stony Brook.\nB.A. in Economics & B.S. in Applied Mathematics from Hanyang University at Ansan, South Korea.\n\nMinor in Business Administration.\nConcentration in Finance."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#instructor-2",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#instructor-2",
    "title": "Lecture 1",
    "section": "Instructor",
    "text": "Instructor\nEconomics and Data Science\n\nChoe, B.H., 2021. ‚ÄúSocial Media Campaigns, Lobbying and Legislation: Evidence from #climatechange and Energy Lobbies.‚Äù\nQuestion: To what extent do social media campaigns compete with fossil fuel lobbying on climate change legislation?\nData include:\n\n5.0 million tweets with #climatechange/#globalwarming around the globe;\n12.0 million retweets/likes to those tweets;\n0.8 million Twitter users who wrote those tweets;\n1.4 million Twitter users who retweeted or liked those tweets;\n0.3 million US Twitter users with their location at a city level;\nFirm-level lobbying data (expenses, targeted bills, etc.)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#instructor-3",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#instructor-3",
    "title": "Lecture 1",
    "section": "Instructor",
    "text": "Instructor\nEconomics and Data Science\n\nChoe, B.H. and Ore-Monago, T., 2024. ‚ÄúGovernance and Climate Finance in the Developing World‚Äù\nClimate finance refers to the financial resources allocated for mitigating and adapting to climate change, including support for initiatives that reduce greenhouse gas emissions and enhance resilience to climate impacts.\n\nWe focus on transnational financing that rich countries provide poor countries with financial resources, in order to help them adapt to climate change and mitigate greenhouse gas (GHG) emissions.\nSince the GHG emissions in developing countries are rapidly growing, it is crucial to assess the effectiveness of climate finance.\nPoor governance can be significant barriers to emissions reductions within these countries."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#instructor-4",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#instructor-4",
    "title": "Lecture 1",
    "section": "Instructor",
    "text": "Instructor\nEconomics and Data Science\n\nChoe, B.H. and Ore-Monago, T., 2024. ‚ÄúGovernance and Climate Finance in the Developing World‚Äù\nData include:\n\nGlobal climate finance data (e.g., donors, recipients, characteristics of climate change projects)\nWorld Bank Governance Indicators over the years (e.g., government effectiveness, voice and accountability, political stability and absence of violence/terrorism, regulatory quality, rule of law, control of corruption)\nVarious economic indicators (e.g., trade pattern of low carbon technology products, macroeconomic risks, energy)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#instructor-5",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#instructor-5",
    "title": "Lecture 1",
    "section": "Instructor",
    "text": "Instructor\nEconomics and Data Science\n\nChoe, B.H., James, Alex and Newbold, Steve, 2025. ‚ÄúEstimating the Value of Statistical Life (VSL) through Big Data‚Äù\nVSL is the monetary value associated with reducing the risk of death.\n\nHow much value would that be? How can we measure it?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-1",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-1",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nEmail, Class & Office Hours\n\nEmail: bchoe@geneseo.edu\nClass Homepage:\n\nhttps://mylearning.suny.edu/d2l/home/1513935\nhttp://bcdanl.github.io\n\nOffice: South Hall 301\nOffice Hours:\n\nIn-person: Mondays and Wednesdays 1:30 P.M.‚Äì3:00 P.M.\nOnline: by appointment via email."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-2",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-2",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Description\n\nThis course offers a practical introduction to the data analytics process and methods.\nThe goal is to help you unlock the potential of data analysis and enhance your ability to transform data into a powerful decision-making tool.\nYou will develop foundational data analytics skills that will prepare you for a career or further studies in more advanced data analytics topics.\nThe course covers: (1) an introduction to data analytics thinking, (2) exploratory data analysis through data wrangling and visualization, and (3) an introduction to data science, social media analytics, and artificial intelligence (AI).\nThroughout the course, you will gain hands-on experience with the Python and R programming languages, along with its associated data analysis libraries and AI tools."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-3",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-3",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Learning Outcomes\n\nGrasp the basic principles of data analytics, including data types and data processing.\nGain introductory experience with programming languages commonly used in data analytics, such as Python or R.\nDevelop the ability to create and interpret various types of data visualizations.\nEnhance critical thinking skills by learning to ask relevant questions and draw insights from data.\nApply data analytics techniques to solve real-world problems in various domains."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-4",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-4",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nReference Materials\n\nR for Data Science (2nd Edition) by Hadley Wickham & Garrett Grolemund.\nPython for Data Science by Arthur Turrell et. al.\nCoding for Economists by Arthur Turrell.\nStatistical Inference via Data Science: A ModernDive into R and the Tidyverse by Chester Ismay and Albert Y. Kim."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-5",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-5",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Requirements\n\nHomework: There will be six homework assignments.\nQuiz: There will be in-class quizzes.\nClass Participation: You are encouraged to ask questions and discuss topics during the class time.\nExam: There will be two short midterm exams and one comprehensive final exam.\nTeam presentation: There will be a team presentation."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-6",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-6",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nTeam Presentations\n\nEach team will present on data storytelling with visualization.\nData storytelling with visualization is the art of communicating complex data insights in a clear, engaging, and impactful way by blending data analysis, visual design, and narrative techniques.\nIt goes beyond simply showing charts and graphs; it involves crafting a compelling story that guides the audience through the data, highlights key findings, and effectively conveys the intended message."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-7",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-7",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nTeam Presentations\n\nKey aspects of data storytelling include:\n\nClarity: Make sure the visuals are easy to understand and focus on the most important information.\nStructure: Just like a story, start with an introduction, present the main points, and finish with a conclusion.\nEngagement: Tailor the story to your audience so it is relevant and interesting to them."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-8",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-8",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nClass Schedule\n\nThere will be tentatively 42 class sessions.\n\nThe midterm exam 1 is scheduled on October 9, 2024, Wednesday, during the class time.\nThe midterm exam 2 is scheduled on November 8, 2024, Friday, during the class time.\nThe team presentation is scheduled during the first week of December, 2024.\nThe final exam is scheduled on December 16, 2024, Monday, noon‚Äì2:00 P.M."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-9",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-9",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Contents"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-10",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-10",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Contents"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-11",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-11",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Contents"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-12",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-12",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nGrading\n\\[\n\\begin{align}\n(\\text{Total Percentage Grade}) =&\\;\\, 0.05\\times(\\text{Attendance}) \\notag\\\\\n&\\,+\\, 0.15\\times(\\text{Quiz & Class Participation})\\notag\\\\\n& \\,+\\, 0.15\\times(\\text{Homework})\\notag\\\\  \n&\\,+\\, 0.15\\times(\\text{Presentation})\\notag\\\\\n& \\,+\\, 0.50\\times(\\text{Exam}).\\notag\n\\end{align}\n\\]"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-13",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-13",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nGrading\n\nYou are allowed up to 6 absences without penalty.\n\nSend me an email if you have standard excused reasons (illness, family emergency, transportation problems, etc.).\n\nFor each absence beyond the initial six, there will be a deduction of 1% from the Total Percentage Grade.\nThe single lowest homework score will be dropped when calculating the total homework score.\n\nEach homework except for the homework with the lowest score accounts for 20% of the total homework score."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-14",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-14",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nGrading\n\\[\n\\begin{align}\n&(\\text{Total Exam Score}) \\\\\n=\\, &\\text{max}\\,\\left\\{0.50\\times(\\text{Midterm Exam Score}) \\,+\\, 0.50\\times(\\text{Final Exam Score})\\right.,\\notag\\\\\n&\\qquad\\;\\,\\left.0.25\\times(\\text{Midterm Exam Score}) \\,+\\, 0.75\\times(\\text{Final Exam Score})\\right\\}.\\notag\n\\end{align}\n\\]\n\nThe total exam score is the maximum between\n\nthe simple average of the midterm exam score and the final exam score and\nthe weighted average of them with one-fourth weight on the midterm exam score and three-third weight on the final exam score:"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-15",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-15",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nMake-up Policy\n\nMake-up exams will not be given unless you have either a medically verified excuse or an absence excused by the University.\nIf you cannot take exams because of religious obligations, notify me by email at least two weeks in advance so that an alternative exam time may be set.\nA missed exam without an excused absence earns a grade of zero.\nLate submissions for homework assignment will be accepted with a penalty.\nA zero will be recorded for a missed assignment."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-16",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-16",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nAcademic Integrity and Plagiarism\n\nAll homework assignments and exams must be the original work by you.\nExamples of academic dishonesty include:\n\nrepresenting the work, thoughts, and ideas of another person as your own\nallowing others to represent your work, thoughts, or ideas as theirs, and\nbeing complicit in academic dishonesty by suspecting or knowing of it and not taking action.\n\nGeneseo‚Äôs Library offers frequent workshops to help you understand how to paraphrase, quote, and cite outside sources properly.\n\nSee https://www.geneseo.edu/library/library-workshops."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-17",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-17",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nArtificial Intelligence (AI) Policy\n\nUnless AI tools are explicitly permitted for homework or in-class quizzes, you must complete your work independently.\nThis means you should not use tools like ChatGPT for any aspect of our coursework.\nSuch use is a form of academic dishonesty. Use of such tools is not only cheating, it will also cheat you of the opportunity to learn and develop your own skills.\nWhile AI will undoubtedly play important roles in our future society, you will be better able to utilize AI if you have developed your own critical thinking, writing, and analytical skills by doing your own work.\nIf you have any questions about this, please ask."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-18",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-18",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nAccessibility\n\nThe Office of Accessibility will coordinate reasonable accommodations for persons with physical, emotional, or cognitive disabilities to ensure equal access to academic programs, activities, and services at Geneseo.\nPlease contact me and the Office of Accessibility Services for questions related to access and accommodations."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-19",
    "href": "danl-lec/danl-101-lec-01-2024-0826.html#syllabus-19",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCareer Design\n\nTo get information about career development, you can visit the Career Development Events Calendar (https://www.geneseo.edu/career_development/events/calendar).\nYou can stop by South 112 to get assistance in completing your Handshake Profile https://app.joinhandshake.com/login.\n\nHandshake is ranked #1 by students as the best place to find full-time jobs.\n50% of the 2018-2020 graduates received a job or internship offer on Handshake.\nHandshake is trusted by all 500 of the Fortune 500."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-1",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-1",
    "title": "Lecture 6",
    "section": "R Basics",
    "text": "R Basics\nData Types\n\n\n\n\n\n\n\nLogical: TRUE or FALSE.\nNumeric: Numbers with decimals\nInteger: Integers\nCharacter: Text strings\nFactor: Categorical values.\n\nEach possible value of a factor is known as a level."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-2",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-2",
    "title": "Lecture 6",
    "section": "R Basics",
    "text": "R Basics\nData Containers\n\n\n\n\n\n\n\n\n\nvector: 1D collection of variables of the same type\ndata.frame: 2D collection of variables of multiple types\n\nA data.frame is a collection of vectors."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-3",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-3",
    "title": "Lecture 6",
    "section": "R Basics",
    "text": "R Basics\nData Types\n\n\norig_number &lt;- 4.39898498\nclass(orig_number)\nmod_number &lt;- as.integer(orig_number)\nclass(mod_number)\n\n# TRUE converts to 1; FALSE does to 0.\nas.numeric(TRUE)\nas.numeric(FALSE)\n\n\n\nSometimes we need to explicitly cast a value from one type to another.\n\nWe can do this using built-in functions like as.character(), as.integer(), as.numeric(), and as.factor()."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-4",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-4",
    "title": "Lecture 6",
    "section": "R Basics",
    "text": "R Basics\nData Types\n\n\nCharacterNumbersLogical (TRUE/FALSE)VectorsFactors\n\n\nmyname &lt;- \"my_name\"\nclass(myname) # returns the data **type** of an object.\n\nStrings are known as character in R.\nUse the double quotes (\") or single quotes (') to wrap around the string\n\nMost IDE, including RStudio, automatically provides a pair of quotes when typing just one quote.\n\n\n\n\nfavorite.integer &lt;- as.integer(2)\nclass(favorite.integer)\n\nfavorite.numeric &lt;- as.numeric(8.8)\nclass(favorite.numeric)\n\nNumbers have different classes.\n\nThe most common two are integer and numeric. Integers are whole numbers.\n\n\n\n\nclass(TRUE)\nclass(FALSE)\nfavorite.numeric == 8.8\nfavorite.numeric == 9.9\nclass(favorite.numeric == 8.8)\n\nWe use the == to test for equality in R\n\n\n\na &lt;- 1:10  # colon operator\nb &lt;- c(\"3\", 4, 5)\nbeers &lt;- c(\"BUD LIGHT\", \"BUSCH LIGHT\", \"COORS LIGHT\", \n           \"MILLER LITE\", \"NATURAL LIGHT\")\nclass(a)\nclass(b)\nclass(beers)\n\nWe can create one-dimensional data structures called ‚Äúvectors‚Äù.\nc(...): Returns a vector that is constructed from one or more arguments, with the order of the vector elements corresponding to the order of the arguments.\n\n\n\nbeers &lt;- as.factor(beers)\nclass(beers)\n\nlevels(beers)\nnlevels(beers)\n\nFactors store categorical data.\nUnder the hood, factors are actually integers that have a string label attached to each unique integer.\n\nFor example, if we have a long list of Male/Female labels for each of our patients, this will be stored a ‚Äúcolumn‚Äù of zeros and ones by R."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-5",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-5",
    "title": "Lecture 6",
    "section": "R Basics",
    "text": "R Basics\nWorkflow: Quotation marks, parentheses, and +\nx &lt;- \"hello\n\nQuotation marks and parentheses must always come in a pair.\n\nIf not, Console Pane will show you the continuation character +:\n\nThe + tells you that R is waiting for more input; it doesn‚Äôt think you‚Äôre done yet."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-6",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-6",
    "title": "Lecture 6",
    "section": "R Basics",
    "text": "R Basics\nFunctions\n\nA function can take any number and type of input parameters and return any number and type of output results.\nR ships a vast number of built-in functions.\nR also allows a user to define a new function.\nWe will mostly use built-in functions."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-7",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-7",
    "title": "Lecture 6",
    "section": "R Basics",
    "text": "R Basics\nFunctions, Arguments, and Parameters\nlibrary(tidyverse)\n\n# The function `str_c()`, provided by `tidyverse`, concatenates characters.\nstr_c(\"Data\", \"Analytics\")\nstr_c(\"Data\", \"Analytics\", sep = \"!\")\n\nWe invoke a function by entering its name and a pair of opening and closing parentheses.\nMuch as a cooking recipe can accept ingredients, a function invocation can accept inputs called arguments.\nWe pass arguments sequentially inside the parentheses (, separated by commas).\nA parameter is a name given to an expected function argument.\nA default argument is a fallback value that R passes to a parameter if the function invocation does not explicitly provide one."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-8",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-8",
    "title": "Lecture 6",
    "section": "R Basics",
    "text": "R Basics\nArithmetic Operations and Mathematical Functions\n\n\nAlgebraMath functions\n\n\n\n\n5 + 3\n5 - 3\n5 * 3\n5 / 3\n5^3\n\n( 3 + 4 )^2\n3 + 4^2\n3 + 2 * 4^2\n3 + 2 * 4 + 2\n(3 + 2) * (4 + 2)\n\n\n\nAll of the basic operators with parentheses we see in mathematics are available to use.\nR can be used for a wide range of mathematical calculations.\n\n\n\n\n\n5 * abs(-3)\nsqrt(17) / 2\nexp(3)\nlog(3)\nlog(exp(3))\nexp(log(3))\n\nR has many built-in mathematical functions that facilitate calculations and data analysis.\n\n\n\nabs(x): the absolute value \\(|x|\\)\nsqrt(x): the square root \\(\\sqrt{x}\\)\nexp(x): the exponential value \\(e^x\\), where \\(e = 2.718...\\)\nlog(x): the natural logarithm \\(\\log_{e}(x)\\), or simply \\(\\log(x)\\)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-9",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-9",
    "title": "Lecture 6",
    "section": "R Basics",
    "text": "R Basics\nVectorized Operations\na &lt;- c(1, 2, 3, 4, 5)\nb &lt;- c(5, 4, 3, 2, 1)\n\na + b\na - b\na * b\na / b\nsqrt(a)\n\nVectorized operations mean applying a function to every element of a vector without explicitly writing a loop.\n\nThis is possible because most functions in R are vectorized, meaning they are designed to operate on vectors element-wise.\nVectorized operations are a powerful feature of R, enabling efficient and concise code for data analysis and manipulation."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-central-tendency",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-central-tendency",
    "title": "Lecture 6",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\n\nMeasures of centrality are used to describe the central or typical value in a given vector.\n\nThey represent the ‚Äúcenter‚Äù or most representative value of a data set.\n\nTo describe this centrality, several statistical measures are commonly used:\n\nMean: The arithmetic average of all values in the data set.\nMedian: The middle value when the data set is ordered from least to greatest.\nMode: The most frequently occurring value in the data set."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-central-tendency-1",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-central-tendency-1",
    "title": "Lecture 6",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\nMean\n\\[\n\\overline{x} = \\frac{x_{1} + x_{2} + \\cdots + x_{N}}{N}\n\\]\nx &lt;- c(1, 2, 3, 4, 5)\nsum(x)\nmean(x)\n\nThe arithmetic mean (or simply mean or average) is the sum of all the values divided by the number of observations in the data set.\n\nmean() calculates the mean of the values in a vector.\nFor a given vector \\(x\\), if we happen to have \\(N\\) observations \\((x_{1}, x_{2}, \\cdots , x_{N})\\), we can write the arithmetic mean of the data sample as above."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-central-tendency-2",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-central-tendency-2",
    "title": "Lecture 6",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\nMedian\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx &lt;- c(1, 2, 3, 4, 5)\nmedian(x)\n\nThe median is the measure of center value in a given vector.\n\nmedian() calculates the median of the values in a vector."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-central-tendency-3",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-central-tendency-3",
    "title": "Lecture 6",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\nMode\n\nThe mode is the value(s) that occurs most frequently in a given vector.\nMode is useful, although it is often not a very good representation of centrality.\nThe R package, modest, provides the mfw(x) function that calculate the mode of values in vector x."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-dispersion",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-dispersion",
    "title": "Lecture 6",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\n\nMeasures of dispersion are used to describe the degree of variation in a given vector.\n\nThey are a representation of the numerical spread of a given data set.\n\nTo describe this dispersion, a number of statistical measures are developed\n\nRange\nVariance\nStandard deviation\nQuartile"
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-dispersion-1",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-dispersion-1",
    "title": "Lecture 6",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\nRange\n\\[\n(\\text{range of x}) \\,=\\, (\\text{maximum value in x}) \\,-\\, (\\text{minimum value in x})\n\\]\nx &lt;- c(1, 2, 3, 4, 5)\nmax(x)\nmin(x)\nrange &lt;- max(x) - min(x)\n\nThe range is the difference between the largest and the smallest values in a given vector.\n\nmax(x) returns the maximum value of the values in a given vector \\(x\\).\nmin(x) returns the minimum value of the values in a given vector \\(x\\)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-dispersion-2",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-dispersion-2",
    "title": "Lecture 6",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\nVariance\n\\[\n\\overline{s}^{2} = \\frac{(x_{1}-\\overline{x})^{2} + (x_{2}-\\overline{x})^{2} + \\cdots + (x_{N}-\\overline{x})^{2}}{N-1}\\;\\,\n\\]\nx &lt;- c(1, 2, 3, 4, 5)\nvar(x)\n\nThe variance is used to calculate the deviation of all data points in a given vector from the mean.\n\nThe larger the variance, the more the data are spread out from the mean and the more variability one can observe in the data sample.\nTo prevent the offsetting of negative and positive differences, the variance takes into account the square of the distances from the mean.\n\nvar(x) calculates the variance of the values in a vector \\(x\\)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-dispersion-3",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-dispersion-3",
    "title": "Lecture 6",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\nStandard Deviation\n\\[\n\\overline{s} = \\sqrt{ \\left( \\frac{(x_{1}-\\overline{x})^{2} + (x_{2}-\\overline{x})^{2} + \\cdots + (x_{N}-\\overline{x})^{2}}{N-1}\\;\\, \\right) }\n\\]\nx &lt;- c(1, 2, 3, 4, 5)\nsd(x)\n\nThe standard deviation (SD)‚Äîthe square root of the variance‚Äîis also a measure of the spread of values within a given vector.\n\nsd(x) calculates the standard deviation of the values in a vector \\(x\\)\nSD helps us understand how representative the mean is of the data.\n\nA low SD suggests that the mean is a good summary, while a high SD suggests greater variability around the mean."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-dispersion-4",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-dispersion-4",
    "title": "Lecture 6",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\nQuartiles\nquantile(x)\nquantile(x, 0) # the minimum\nquantile(x, 0.25) # the 1st quartile\nquantile(x, 0.5) # the 2nd quartile\nquantile(x, 0.75) # the 3rd quartile\nquantile(x, 1) # the maximum\n\nA quartile is a quarter of the number of data points in a given vector.\n\nQuartiles are determined by first sorting the values and then splitting the sorted values into four disjoint smaller data sets.\nQuartiles are a useful measure of dispersion because they are much less affected by outliers or a skewness in the data set than the equivalent measures in the whole data set."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-dispersion-5",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#measures-of-dispersion-5",
    "title": "Lecture 6",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\nInterquartile Range\n\n\n\n\n\n\n\n\n\nAn interquartile range describes the difference between the third quartile (Q3) and the first quartile (Q1), telling us about the range of the middle half of the scores in the distribution.\n\nThe quartile-driven descriptive measures (both centrality and dispersion) are best explained with a popular plot called a box plot."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-10",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-10",
    "title": "Lecture 6",
    "section": "R Basics",
    "text": "R Basics\nAbsolute vs.¬†Relative Pathnames\n\n\nAbsolute PathRelative Path\n\n\n\nComplete path from the root directory to the target file or directory.\nIndependent of the current working directory.\nExample\n\nMac:\n\n/Users/user/documents/data/car_data.csv\n\nWindows:\n\nC:\\\\Users\\\\user\\\\Documents\\\\data\\\\car_data.csv\n\n\n\n\n\n\nPath relative to the working directory.\n\nRelative path changes based on the working directory. \n\nExample:\n\nAbsolute pathname for car_data.csv is /Users/user/documents/data/car_data.csv.\nSuppose the current directory is /Users/user/documents/.\nThen, the relative pathname for car_data.csv is dada/car_data.csv.\n\nFor the Posit Cloud project, we can use a relative path.\n\nThe current working directory in is /cloud/project/"
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-11",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-11",
    "title": "Lecture 6",
    "section": "R Basics",
    "text": "R Basics\nWorking with Data from Files\n\n\nWe use the read_csv() function to read a comma-separated values (CSV) file.\n\n\nDownload the CSV file, car_data.csv from the Class Files module in our Brightspace.\nCreate a sub-directory, data, by clicking ‚ÄúNew Folder‚Äù in the Files Pane in Posit Cloud.\nUpload the car_data.csv file to the sub-directory data.\nProvide the relative pathname for the file, car_data.csv, to the read_csv() function.\n\nuciCar &lt;- read_csv('HERE WE PROVIDE A RELATIVE PATHNAME FOR car_data.csv')\nView(uciCar)\n\nView()/view() displays the data in a simple spreadsheet-like grid."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-12",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-12",
    "title": "Lecture 6",
    "section": "R Basics",
    "text": "R Basics\nExamining data.frames\n\n\nclass(uciCar)\ndim(uciCar)\nnrow(uciCar)\nncol(uciCar)\n\nlibrary(skimr)\nskim(uciCar)\n\n\n\ndim() shows how many rows and columns are in the data for data.frame.\nnrow() and ncol() shows the number of rows and columns for data.frame respectively.\nskimr::skim() provides a more detailed summary.\n\nskimr is the R package that provides the function skim()."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-13",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-13",
    "title": "Lecture 6",
    "section": "R Basics",
    "text": "R Basics\nReading data.frames from an URL\ntvshows &lt;- read_csv(\n        'https://bcdanl.github.io/data/tvshows.csv')\n\nWe can import the CSV file from the web."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-14",
    "href": "danl-lec/danl-101-lec-06-2024-0909.html#r-basics-14",
    "title": "Lecture 6",
    "section": "R Basics",
    "text": "R Basics\nTidy data.frame: Variables, Observations, and Values\n\n\n\n\nThere are three rules which make a data.frame tidy:\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n\n\n\n‚Äì&gt;  ‚Äì&gt;  ‚Äì&gt;  ‚Äì&gt;"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools",
    "title": "Lecture 5",
    "section": "Setting the Tools",
    "text": "Setting the Tools\nPosit Cloud\n\nPosit Cloud (formerly RStudio Cloud) is a web service that delivers a browser-based experience similar to RStudio, the standard IDE for the R language.\nFor our course, we use Posit Cloud for the R programming component.\n\nIf you want to install R and RStudio on your laptop, you use my office hours."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-1",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-1",
    "title": "Lecture 5",
    "section": "Setting the Tools",
    "text": "Setting the Tools\nRStudio Environment\n\n\n\n\n\n\n\nScript Pane is where you write R commands in a script file that you can save.\n\nAn R script is simply a text file containing R commands.\nRStudio will color-code different elements of your code to make it easier to read."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-2",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-2",
    "title": "Lecture 5",
    "section": "Setting the Tools",
    "text": "Setting the Tools\nRStudio Environment\n\n\n\n\n\n\n\nConsole Pane allows you to interact directly with the R interpreter and type commands where R will immediately execute them."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-3",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-3",
    "title": "Lecture 5",
    "section": "Setting the Tools",
    "text": "Setting the Tools\nRStudio Environment\n\n\n\n\n\n\n\nEnvironment Pane is where you can see the values of variables, data frames, and other objects that are currently stored in memory.\nType a &lt;- 1 in Console, and then hit Enter."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-4",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-4",
    "title": "Lecture 5",
    "section": "Setting the Tools",
    "text": "Setting the Tools\nRStudio Environment\n\n\n\n\n\n\n\nPlots Pane contains any graphics that you generate from your R code."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-5",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-5",
    "title": "Lecture 5",
    "section": "Setting the Tools",
    "text": "Setting the Tools\nR Packages and tidyverse\n\nR packages are collections of R functions, compiled code, and data that are combined in a structured format.\nSeveral R packages come with numerous pre-built functions that can perform a wide range of data analysis tasks."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-6",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-6",
    "title": "Lecture 5",
    "section": "Setting the Tools",
    "text": "Setting the Tools\ntidyverse\n\n\n\nThe tidyverse is a collection of R packages designed for data science that share an underlying design philosophy, grammar, and data structures.\n\n\n\ntidyverse includes a lot of R packages, including ggplot2, dplyr, and tidyr.\nThe tidyverse packages work harmoniously together to make data manipulation, exploration, and visualization more."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-7",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-7",
    "title": "Lecture 5",
    "section": "Setting the Tools",
    "text": "Setting the Tools\nInstalling R packages with install.packages(\"packageName\")\ninstall.packages(\"tidyverse\")\n\nR packages can be easily installed from within R using a base-R function install.packages(\"packageName\").\n\nTo install the R package tidyverse, type and run the following command from R console:\n\nWhile running the above codes, you may encounter the pop-up question, and you can answer ‚ÄúNo‚Äù"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-8",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-8",
    "title": "Lecture 5",
    "section": "Setting the Tools",
    "text": "Setting the Tools\nLoading R packages with library(packageName)\nlibrary(tidyverse)\nmpg\n\nOnce installed, a package is loaded into an R session using a base-R function library(packageName) so that R package‚Äôs functions and data can be used.\n\nTo load the R package tidyverse, type and run the following commands from a R script:\n\nmpg is the data.frame provided by the R package ggplot2, one of the R pakcages in tidyverse.\n\nSince tidyverse is installed, ggplot2 package is already installed."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-9",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-9",
    "title": "Lecture 5",
    "section": "Setting the Tools",
    "text": "Setting the Tools\nRStudio Options Setting\n\n\n\n\n\nThis option menu is found by menus as follows:\n\nTools \\(&gt;\\) Global Options\n\nCheck the boxes as in the left.\nChoose the option Never for  Save workspace to .RData on exit:"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-10",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-10",
    "title": "Lecture 5",
    "section": "Setting the Tools",
    "text": "Setting the Tools\nWorkflow: Naming and File Management\n\nSave your class R script for each class.\nI use the following style of file name for class R script:\n\ne.g., danl-101-lec-04-2024-0905.R\n\nDo not have any space when you name a file.\n\nIt is recommended to use all lower cases."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-11",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-11",
    "title": "Lecture 5",
    "section": "Setting the Tools",
    "text": "Setting the Tools\nWorkflow: Code and comment style\n\nThe two main principles for coding and managing data are:\n\nMake things easier for your future self.\nDon‚Äôt trust your future self.\n\nThe # mark is R‚Äôs comment character.\n\nIn R scripts (*.R files), # indicates that the rest of the line is to be ignored.\nWrite comments before the line that you want the comment to apply to."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-danl-tools-1",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-danl-tools-1",
    "title": "Lecture 5",
    "section": "Setting the DANL Tools",
    "text": "Setting the DANL Tools\nWorkflow: Shortcuts in Posit Cloud (RStudio)\n\n\n\n\nWindows\n\nAlt + - adds an assignment operator\nCtrl + Enter runs a current line of code\nCtrl + Shift + C makes a comment (#)\nCtrl + Shift + R makes a section (# Section - - - -)\n\n\n\n\nMac\n\noption + - adds an assignment operator\ncommand + return runs a current line of code\ncommand + shift + C makes a comment (#)\ncommand + shift + R makes a section (# Section - - - -)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-12",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-12",
    "title": "Lecture 5",
    "section": "Setting the Tools",
    "text": "Setting the Tools\nWorkflow: Shortcuts in Posit Cloud (RStudio)\n\nCtrl (command for Mac Users) + Z undoes the previous action.\nCtrl (command for Mac Users) + Shift + Z redoes when undo is executed."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-13",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-13",
    "title": "Lecture 5",
    "section": "Setting the Tools",
    "text": "Setting the Tools\nWorkflow: Shortcuts in Posit Cloud (RStudio)\n\nCtrl (command for Mac Users) + F is useful when finding a phrase (and replace the phrase) in the RScript."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-14",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-14",
    "title": "Lecture 5",
    "section": "Setting the Tools",
    "text": "Setting the Tools\nWorkflow: Auto-completion\n\n\nlibr\n\n\n\n\n\n\n\nAuto-completion of command is useful.\n\nType libr in the RScript in RStudio and wait for a second."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-15",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#setting-the-tools-15",
    "title": "Lecture 5",
    "section": "Setting the Tools",
    "text": "Setting the Tools\nWorkflow: STOP icon\n\n\n\n\nWhen the code is running, RStudio shows the STOP icon ( üõë ) at the top right corner in the Console Pane.\n\nDo not click it unless if you want to stop running the code."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#r-basics-1",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#r-basics-1",
    "title": "Lecture 5",
    "section": "R Basics",
    "text": "R Basics\nValues, Variables, and Types\n\n\n\n\nA value is datum (literal) such as a number or text.\nThere are different types of values:\n\n352.3 is known as a float or double;\n22 is an integer;\n‚ÄúHello World!‚Äù is a string."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#r-basics-2",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#r-basics-2",
    "title": "Lecture 5",
    "section": "R Basics",
    "text": "R Basics\nValues, Variables, and Types\na &lt;- 10    # The most popular assignment operator in R is `&lt;-`.\na\n\n\n\n\n\n\n\nA variable is a name that refers to a value.\n\nWe can think of a variable as a box that has a value, or multiple values, packed inside it.\n\nA variable is just a name!"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#r-basics-3",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#r-basics-3",
    "title": "Lecture 5",
    "section": "R Basics",
    "text": "R Basics\nObjects\n\nSometimes you will hear variables referred to as objects.\nEverything that is not a literal value, such as 10, is an object."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#r-basics-4",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#r-basics-4",
    "title": "Lecture 5",
    "section": "R Basics",
    "text": "R Basics\nAssignment\nx &lt;- 2\nx &lt; - 3\n\nWhat is going on here?\nThe shortcut for the assignment &lt;- is:\n\nWindows: Alt + -\nMac: option + -"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2024-0906.html#r-basics-5",
    "href": "danl-lec/danl-101-lec-05-2024-0906.html#r-basics-5",
    "title": "Lecture 5",
    "section": "R Basics",
    "text": "R Basics\nAssignment\nx &lt;- 2\ny &lt;- x + 12\n\nIn programming code, everything on the right side needs to have a value.\n\nThe right side can be a literal value, or a variable that has already been assigned a value, or a combination.\n\nWhen R reads y &lt;- x + 12, it does the following:\n\nSees the &lt;- in the middle.\nKnows that this is an assignment.\nCalculates the right side (gets the value of the object referred to by x and adds it to 12).\nAssigns the result to the left-side variable, y."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#descriptive-statistics",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#descriptive-statistics",
    "title": "Lecture 8",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\n\n\n\n\n\n\nDescriptive statistics condense data into manageable summaries, making it easier to understand key characteristics of the data.\n\nThey help reveal patterns, trends, and relationships within the data that might not be immediately apparent from raw numbers."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#descriptive-statistics-1",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#descriptive-statistics-1",
    "title": "Lecture 8",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\n\nData quality assessment:\n\nDescriptive statistics can highlight potential issues in data quality, such as outliers or unexpected distributions, prompting further investigation.\n\nFoundation for further analysis:\n\nDescriptive statistics often serve as a starting point for more advanced statistical analyses and predictive modeling.\n\nData visualization enhancement:\n\nDescriptive statistics often form the basis for effective data visualizations, making complex data more accessible and understandable."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#descriptive-statistics-2",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#descriptive-statistics-2",
    "title": "Lecture 8",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nMeasures of Central Tendency\n\nMeasures of centrality are used to describe the central or typical value in a given vector.\n\nThey represent the ‚Äúcenter‚Äù or most representative value of a data set.\n\nTo describe this centrality, several statistical measures are commonly used:\n\nMean: The arithmetic average of all values in the data set.\nMedian: The middle value when the data set is ordered from least to greatest.\nMode: The most frequently occurring value in the data set."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#measures-of-central-tendency-1",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#measures-of-central-tendency-1",
    "title": "Lecture 8",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\nMean\n\\[\n\\overline{x} = \\frac{x_{1} + x_{2} + \\cdots + x_{N}}{N}\n\\]\nx &lt;- c(1, 2, 3, 4, 5)\nsum(x)\nmean(x)\n\nThe arithmetic mean (or simply mean or average) is the sum of all the values divided by the number of observations in the data set.\n\nmean() calculates the mean of the values in a vector.\nFor a given vector \\(x\\), if we happen to have \\(N\\) observations \\((x_{1}, x_{2}, \\cdots , x_{N})\\), we can write the arithmetic mean of the data sample as above."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#measures-of-central-tendency-2",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#measures-of-central-tendency-2",
    "title": "Lecture 8",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\nMedian\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx &lt;- c(1, 2, 3, 4, 5)\nmedian(x)\n\nThe median is the measure of center value in a given vector.\n\nmedian() calculates the median of the values in a vector."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#measures-of-central-tendency-3",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#measures-of-central-tendency-3",
    "title": "Lecture 8",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\nMode\n\nThe mode is the value(s) that occurs most frequently in a given vector.\nMode is useful, although it is often not a very good representation of centrality.\nThe R package, modest, provides the mfw(x) function that calculate the mode of values in vector x."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#descriptive-statistics-3",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#descriptive-statistics-3",
    "title": "Lecture 8",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nMeasures of Dispersion\n\nMeasures of dispersion are used to describe the degree of variation in a given vector.\n\nThey are a representation of the numerical spread of a given data set.\n\nTo describe this dispersion, a number of statistical measures are developed\n\nRange\nVariance\nStandard deviation\nQuartile"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#measures-of-dispersion-1",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#measures-of-dispersion-1",
    "title": "Lecture 8",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\nRange\n\\[\n(\\text{range of x}) \\,=\\, (\\text{maximum value in x}) \\,-\\, (\\text{minimum value in x})\n\\]\nx &lt;- c(1, 2, 3, 4, 5)\nmax(x)\nmin(x)\nrange &lt;- max(x) - min(x)\n\nThe range is the difference between the largest and the smallest values in a given vector.\n\nmax(x) returns the maximum value of the values in a given vector \\(x\\).\nmin(x) returns the minimum value of the values in a given vector \\(x\\)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#measures-of-dispersion-2",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#measures-of-dispersion-2",
    "title": "Lecture 8",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\nVariance\n\\[\n\\overline{s}^{2} = \\frac{(x_{1}-\\overline{x})^{2} + (x_{2}-\\overline{x})^{2} + \\cdots + (x_{N}-\\overline{x})^{2}}{N-1}\\;\\,\n\\]\nx &lt;- c(1, 2, 3, 4, 5)\nvar(x)\n\nThe variance is used to calculate the deviation of all data points in a given vector from the mean.\n\nThe larger the variance, the more the data are spread out from the mean and the more variability one can observe in the data sample.\nTo prevent the offsetting of negative and positive differences, the variance takes into account the square of the distances from the mean.\n\nvar(x) calculates the variance of the values in a vector \\(x\\)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#measures-of-dispersion-3",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#measures-of-dispersion-3",
    "title": "Lecture 8",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\nStandard Deviation\n\\[\n\\overline{s} = \\sqrt{ \\left( \\frac{(x_{1}-\\overline{x})^{2} + (x_{2}-\\overline{x})^{2} + \\cdots + (x_{N}-\\overline{x})^{2}}{N-1}\\;\\, \\right) }\n\\]\nx &lt;- c(1, 2, 3, 4, 5)\nsd(x)\n\nThe standard deviation (SD)‚Äîthe square root of the variance‚Äîis also a measure of the spread of values within a given vector.\n\nsd(x) calculates the standard deviation of the values in a vector \\(x\\)\nSD helps us understand how representative the mean is of the data.\n\nA low SD suggests that the mean is a good summary, while a high SD suggests greater variability around the mean."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#measures-of-dispersion-4",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#measures-of-dispersion-4",
    "title": "Lecture 8",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\nQuartiles\nquantile(x)\nquantile(x, 0) # the minimum\nquantile(x, 0.25) # the 1st quartile\nquantile(x, 0.5) # the 2nd quartile\nquantile(x, 0.75) # the 3rd quartile\nquantile(x, 1) # the maximum\n\nA quartile is a quarter of the number of data points in a given vector.\n\nQuartiles are determined by first sorting the values and then splitting the sorted values into four disjoint smaller data sets.\nQuartiles are a useful measure of dispersion because they are much less affected by outliers or a skewness in the data set than the equivalent measures in the whole data set."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#measures-of-dispersion-5",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#measures-of-dispersion-5",
    "title": "Lecture 8",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\nInterquartile Range\n\n\n\n\n\n\n\n\n\nAn interquartile range describes the difference between the third quartile (Q3) and the first quartile (Q1), telling us about the range of the middle half of the scores in the distribution.\n\nThe quartile-driven descriptive measures (both centrality and dispersion) are best explained with a popular plot called a box plot."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#r-basics-1",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#r-basics-1",
    "title": "Lecture 8",
    "section": "R Basics",
    "text": "R Basics\nCSV file\n\nA CSV (comma-separated values) file is a text file in which values are separated by commas.\nCSV files are most commonly encountered in spreadsheets and databases.\nExample\n\nhttps://bcdanl.github.io/data/tvshows.csv"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#r-basics-2",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#r-basics-2",
    "title": "Lecture 8",
    "section": "R Basics",
    "text": "R Basics\nAbsolute Pathnames\n\nComplete path from the root directory to the target file or directory.\nIndependent of the working directory.\n\ngetwd() returns the pathname of the working directory.\nThe working directory for a Posit Cloud project is /cloud/project/\n\nExample of absolute pathnames for custdata_rev.csv\n\nMac:\n\n/Users/user/documents/data/custdata_rev.csv\n\nWindows:\n\nC:\\\\Users\\\\user\\\\Documents\\\\data\\\\custdata_rev.csv"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#r-basics-3",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#r-basics-3",
    "title": "Lecture 8",
    "section": "R Basics",
    "text": "R Basics\nRelative Pathnames\n\nPath relative to the working directory.\nExample:\n\nAbsolute pathname for custdata_rev.csv is /Users/user/documents/data/custdata_rev.csv.\nSuppose the working directory is /Users/user/documents/.\nThen, the relative pathname for custdata_rev.csv is dada/custdata_rev.csv.\n\nWhen using the Posit Cloud project, we can use a relative path to read a file."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#r-basics-4",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#r-basics-4",
    "title": "Lecture 8",
    "section": "R Basics",
    "text": "R Basics\nWorking with Data from Files\n\n\nWe use the read_csv() function to read a comma-separated values (CSV) file.\n\n\nDownload the CSV file, custdata_rev.csv from the Class Files module in our Brightspace.\nCreate a sub-directory, data, by clicking ‚ÄúNew Folder‚Äù in the Files Pane in Posit Cloud.\nUpload the custdata_rev.csv file to the sub-directory data.\nProvide the relative pathname for the file, custdata_rev.csv, to the read_csv() function.\n\ncustdata &lt;- read_csv('HERE WE PROVIDE A RELATIVE PATHNAME FOR custdata_rev.csv')\nView(custdata)\n\nView() displays the data in a simple spreadsheet-like grid."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#r-basics-5",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#r-basics-5",
    "title": "Lecture 8",
    "section": "R Basics",
    "text": "R Basics\nExamining data.frames\n\n\nclass(custdata)\ndim(custdata)\nnrow(custdata)\nncol(custdata)\n\nsummary(custdata_rev)\nlibrary(skimr)\nskim(custdata_rev)\n\n\n\ndim() shows how many rows and columns are in the data for data.frame.\nnrow() and ncol() shows the number of rows and columns for data.frame respectively.\nskimr::skim() refers to the skim() function from the skimr package.\n\nThis provides a more comprehensive summary.\nIt‚Äôs a more user-friendly alternative to functions like base-R‚Äôs summary(), offering both numerical and categorical summaries."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#r-basics-6",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#r-basics-6",
    "title": "Lecture 8",
    "section": "R Basics",
    "text": "R Basics\nReading data.frames from an URL\ntvshows &lt;- read_csv(\n        'https://bcdanl.github.io/data/tvshows.csv')\n\nWe can import the CSV file from the web."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2024-0913.html#r-basics-7",
    "href": "danl-lec/danl-101-lec-08-2024-0913.html#r-basics-7",
    "title": "Lecture 8",
    "section": "R Basics",
    "text": "R Basics\nTidy data.frame: Variables, Observations, and Values\n\n\n\n\nThere are three rules which make a data.frame tidy:\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n\n\n\n‚Äì&gt;  ‚Äì&gt;  ‚Äì&gt;  ‚Äì&gt;"
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2024-0830.html#sports-analytics",
    "href": "danl-lec/danl-101-lec-03-2024-0830.html#sports-analytics",
    "title": "Lecture 3",
    "section": "Sports Analytics",
    "text": "Sports Analytics\nMoneyball‚Äôs Impact\n\n\n\n\n\n\n\n\n\nThe use of data analytics for sports was popularized by the Moneyball book by Michael Lewis in 2003 and the movie starring Brad Pitt and Jonah Hill in 2011."
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2024-0830.html#what-is-sports-analytics",
    "href": "danl-lec/danl-101-lec-03-2024-0830.html#what-is-sports-analytics",
    "title": "Lecture 3",
    "section": "What is Sports Analytics?",
    "text": "What is Sports Analytics?\n\nSports analytics is the use of data analysis and statistical techniques, such as, machine learning, to evaluate and improve the performance of athletes, teams, and organizations in sports.\nIt involves collecting and analyzing data related to various aspects of sports:\n\nPlayer Performance Analysis\nTeam Tactics Analysis\nInjury Prevention and Recovery\nRecruitment and Scouting\nFan Engagement and Business Operations"
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2024-0830.html#what-is-machine-learning",
    "href": "danl-lec/danl-101-lec-03-2024-0830.html#what-is-machine-learning",
    "title": "Lecture 3",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning (ML) algorithm allows computers to learn from data and improve their performance on tasks without being explicitly programmed.\nHow Does It Work?\n\nComputers are given large amounts of data.\nThey use statistical algorithms (step-by-step instructions with statistics) to find patterns in that data.\nBased on these patterns, the computer makes predictions or decisions."
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2024-0830.html#fan-analytics",
    "href": "danl-lec/danl-101-lec-03-2024-0830.html#fan-analytics",
    "title": "Lecture 3",
    "section": "1. Fan Analytics",
    "text": "1. Fan Analytics\n\n\n\nSeason Ticket Renewals‚ÄîLikelihood to Purchase Again\n\n\n\ne.g., 69% of fans in Tier 1 seats who said on the survey that they would ‚Äúprobably not‚Äù renew actually did.\nThe types of questions for fan analytics would be:\n\nWhy do season ticket holders renew their tickets?\nWhat factors drive last-minute individual seat ticket purchases?\nHow to price the tickets?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2024-0830.html#fan-analytics-1",
    "href": "danl-lec/danl-101-lec-03-2024-0830.html#fan-analytics-1",
    "title": "Lecture 3",
    "section": "1. Fan Analytics",
    "text": "1. Fan Analytics\n\n\n\n\nBusiness offices at sports team do dynamic pricing:\n\nIt adjusts ticket prices based on various factors such as the team‚Äôs performance, opponent, game time, and real-time data like weather and traffic."
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2024-0830.html#team-tactics",
    "href": "danl-lec/danl-101-lec-03-2024-0830.html#team-tactics",
    "title": "Lecture 3",
    "section": "2. Team Tactics",
    "text": "2. Team Tactics\nDecision Tree for Run or Pass Plays in Football\n\n\n\nRun or Pass in the Next Play\n\n\n\nA decision tree is a machine learning model that makes decisions by splitting data into branches based on input variables.\n\nOff_Pers: Offensive Personnel (e.g., Value ‚Äú11‚Äù meaning 1 running back, 1 tight end, and 3 wide receivers)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2024-0830.html#team-tactics-1",
    "href": "danl-lec/danl-101-lec-03-2024-0830.html#team-tactics-1",
    "title": "Lecture 3",
    "section": "2. Team Tactics",
    "text": "2. Team Tactics\nDecision Tree for Run or Pass Plays in Football\n\n\n\nRun or Pass in the Next Play\n\n\n\nIf a football team sees an opponent team‚Äôs personnel formation that looks like a pass, and it is third or fourth down with more than 5 yards to go, how likely would the opponent team pass in the next play?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2024-0830.html#hockey-player-performance",
    "href": "danl-lec/danl-101-lec-03-2024-0830.html#hockey-player-performance",
    "title": "Lecture 3",
    "section": "3. Hockey Player Performance",
    "text": "3. Hockey Player Performance\n\n\\[\nPM \\,=\\, (\\text{Number of his team's goal}) \\,-\\, (\\text{Number of opponent team's goal})\n\\]\n\nThe player ‚Äúplus-minus‚Äù (PM) is a common hockey performance metric.\nThe limits of this approach are obvious:\n\nThere is no accounting for teammates or opponents.\nIn hockey, where players tend to be grouped together on ‚Äúlines‚Äù and coaches will ‚Äúline match‚Äù against opponents, a player‚Äôs PM can be artificially inflated or deflated by the play of his opponents and peers.\n\nHere, we instead use machine learning methods to analyze how likely making a goal is associated with whether or not a player is on the ice."
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2024-0830.html#hockey-player-performance-1",
    "href": "danl-lec/danl-101-lec-03-2024-0830.html#hockey-player-performance-1",
    "title": "Lecture 3",
    "section": "3. Hockey Player Performance",
    "text": "3. Hockey Player Performance\nData\n\nThe data comprise of play-by-play NHL game data for regular and playoff games during 11 seasons of 2002-2003 through 2013-2014.\nThere were 2,439 players involved in 69,449 goals.\nThe data contains information that indicates:\n\nSeasons\nHome & away teams\nTeam configuration such as 5 on 4 powerplay\nWhich players are on & off the ice when a goal is made."
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2024-0830.html#hockey-player-performance-2",
    "href": "danl-lec/danl-101-lec-03-2024-0830.html#hockey-player-performance-2",
    "title": "Lecture 3",
    "section": "3. Hockey Player Performance",
    "text": "3. Hockey Player Performance\n\n\n\n\n\nPeter Forsberg\n\n\n\n\n\n\nSidney Crosby\n\n\n\n\n\nHow is the presence of a legend player, e.g., Peter Forsberg or Sidney Crosby, associated with the likelihood of making a goal?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2024-0828.html#why-data-analytics",
    "href": "danl-lec/danl-101-lec-02-2024-0828.html#why-data-analytics",
    "title": "Lecture 2",
    "section": "Why Data Analytics?",
    "text": "Why Data Analytics?\n\nFill in the gaps left by traditional business and economics classes.\n\nPractical skills that will benefit your future career.\nNeglected skills like how to actually find datasets in the wild and clean them.\n\nData analytics skills are largely distinct from (and complementary to) the core quantitative works familiar to business undergrads.\n\nData visualization, cleaning and wrangling; databases; machine learning; etc.\n\nIn short, we will cover things that I wish someone had taught me when I was undergraduate."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2024-0828.html#you-at-the-end-of-this-course",
    "href": "danl-lec/danl-101-lec-02-2024-0828.html#you-at-the-end-of-this-course",
    "title": "Lecture 2",
    "section": "You, at the end of this course",
    "text": "You, at the end of this course"
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2024-0828.html#why-data-analytics-1",
    "href": "danl-lec/danl-101-lec-02-2024-0828.html#why-data-analytics-1",
    "title": "Lecture 2",
    "section": "Why Data Analytics?",
    "text": "Why Data Analytics?\n\nData analysts use analytical tools and techniques to extract meaningful insights from data.\n\nSkills in data analytics are also useful for business analysts or market analysts.\n\nBreau of Labor Statistics forecasts that the projected growth rate of the employment in the industry related to data analytics from 2021 to 2031 is 36%.\n\nThe average growth rate for all occupations is 5%."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2024-0828.html#why-r-python-and-databases",
    "href": "danl-lec/danl-101-lec-02-2024-0828.html#why-r-python-and-databases",
    "title": "Lecture 2",
    "section": "Why R, Python, and Databases?",
    "text": "Why R, Python, and Databases?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2024-0828.html#why-r-python-and-databases-1",
    "href": "danl-lec/danl-101-lec-02-2024-0828.html#why-r-python-and-databases-1",
    "title": "Lecture 2",
    "section": "Why R, Python, and Databases?",
    "text": "Why R, Python, and Databases?\n\nStack Overflow is the most popular Q & A website specifically for programmers and software developers in the world.\nSee how programming languages have trended over time based on use of their tags in Stack Overflow from 2008 to 2022.\n\n\n\nMost Popular Languagues\n\n\nData Science and Big Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2024-0828.html#the-state-of-the-art",
    "href": "danl-lec/danl-101-lec-02-2024-0828.html#the-state-of-the-art",
    "title": "Lecture 2",
    "section": "The State of the Art",
    "text": "The State of the Art\nGenerative AI and ChatGPT\n\n\nData Science and Big Data Trend\nFrom 2008 to 2023\n\n\nProgrammers in 2024"
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2024-0828.html#the-state-of-the-art-1",
    "href": "danl-lec/danl-101-lec-02-2024-0828.html#the-state-of-the-art-1",
    "title": "Lecture 2",
    "section": "The State of the Art",
    "text": "The State of the Art\nGenerative AI and ChatGPT\n\nGenerative AI refers to a category of artificial intelligence (AI) that is capable of generating new content, ranging from text, images, and videos to music and code.\n\n\n\nIn the early 2020s, advances in transformer-based deep neural networks enabled a number of generative AI systems notable for accepting natural language prompts as input.\n\nThese include large language model (LLM) chatbots (e.g., ChatGPT, Claude, Copilot, Gemini, LLaMA, Grok).\n\nChatGPT (Chat Generative Pre-trained Transformer) is a chatbot developed by OpenAI and launched on November 30, 2022.\n\nBy January 2023, it had become what was then the fastest-growing consumer software application in history."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2024-0828.html#the-state-of-the-art-2",
    "href": "danl-lec/danl-101-lec-02-2024-0828.html#the-state-of-the-art-2",
    "title": "Lecture 2",
    "section": "The State of the Art",
    "text": "The State of the Art\nGenerative AI and ChatGPT\n\nUsers around the world have explored how to best utilize GPT for writing essays and programming codes.\n\n\n\n\nIs AI a threat to data analytics?\n\nFundamental understanding of the subject matter is still crucial for effectively utilizing AI‚Äôs capabilities.\n\n\n\n\n\nIf you use Generative AI such as ChatGPT, please try to understand what ChatGPT gives you.\n\nCopying and pasting it without any understanding harms your learning opportunity."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2024-0828.html#what-is-git",
    "href": "danl-lec/danl-101-lec-02-2024-0828.html#what-is-git",
    "title": "Lecture 2",
    "section": "What is Git?",
    "text": "What is Git?\n\n\n\n\n\\(\\quad\\)\n\nGit is the most popular version control tool for any software development.\n\nIt tracks changes in a series of snapshots of the project, allowing developers to revert to previous versions, compare changes, and merge different versions.\nIt is the industry standard and ubiquitous for coding collaboration."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2024-0828.html#what-is-github",
    "href": "danl-lec/danl-101-lec-02-2024-0828.html#what-is-github",
    "title": "Lecture 2",
    "section": "What is GitHub?",
    "text": "What is GitHub?\n\nGitHub is a web-based hosting platform for Git repositories to store, manage, and share code.\nOut class website is hosted on a GitHub repository.\nCourse contents will be posted not only in Brightspace but also in our GitHub repositories (‚Äúrepos‚Äù) and websites.\nGithub is useful for many reasons, but the main reason is how user friendly it makes uploading and sharing code."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2024-0828.html#what-is-github-1",
    "href": "danl-lec/danl-101-lec-02-2024-0828.html#what-is-github-1",
    "title": "Lecture 2",
    "section": "What is GitHub?",
    "text": "What is GitHub?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2024-0828.html#what-is-r",
    "href": "danl-lec/danl-101-lec-02-2024-0828.html#what-is-r",
    "title": "Lecture 2",
    "section": "What is R?",
    "text": "What is R?\n\nR is a programming language and software environment designed for statistical computing and graphics.\nR has become a major tool in data analysis, statistical modeling, and visualization.\n\nIt is widely used among statisticians and data scientists for developing statistical software and performing data analysis.\nR is open source and freely available."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2024-0828.html#what-is-rstudio",
    "href": "danl-lec/danl-101-lec-02-2024-0828.html#what-is-rstudio",
    "title": "Lecture 2",
    "section": "What is RStudio?",
    "text": "What is RStudio?\n\nRStudio is an integrated development environment (IDE) for R.\n\nAn IDE is a software application that provides comprehensive facilities (e.g., text code editor, graphical user interface (GUI)) to computer programmers for software development.\n\nRStudio is a user-friendly interface that makes using R easier and more interactive.\n\nIt provides a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging, and workspace management.\n\nWe will use a free cloud version of RStudio, which is Posit Cloud."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2024-0828.html#what-is-python",
    "href": "danl-lec/danl-101-lec-02-2024-0828.html#what-is-python",
    "title": "Lecture 2",
    "section": "What is Python?",
    "text": "What is Python?\n\nPython is a versatile programming language known for its simplicity and readability.\nPython has become a dominant tool in various fields including data analysis, machine learning, and web development.\n\nIt is widely used among developers, data scientists, and researchers for building applications and performing data-driven tasks.\nPython is open source and has a vast ecosystem of libraries and frameworks."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2024-0828.html#what-is-jupyter",
    "href": "danl-lec/danl-101-lec-02-2024-0828.html#what-is-jupyter",
    "title": "Lecture 2",
    "section": "What is Jupyter?",
    "text": "What is Jupyter?\n\nJupyter is an open-source integrated development environment (IDE) primarily for Python, though it supports many other languages.\n\nJupyter provides a notebook interface that allows users to write and execute code in a more interactive and visual format.\n\nJupyter Notebook is a user-friendly environment that enhances coding, data analysis, and visualization.\n\nIt offers a web-based interface that combines live code, equations, visualizations, and narrative text.\nJupyter is widely used for data science, machine learning, and research, enabling easy sharing and collaboration.\n\nWe will use a free cloud version of Jupyter, which is Google Colab."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2024-0828.html#python-vs.-r",
    "href": "danl-lec/danl-101-lec-02-2024-0828.html#python-vs.-r",
    "title": "Lecture 2",
    "section": "Python vs.¬†R",
    "text": "Python vs.¬†R"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#what-is-bi",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#what-is-bi",
    "title": "Lecture 4",
    "section": "What is BI?",
    "text": "What is BI?\n\n\n\n\n\n\n\n\n\n\n\n\nBusiness Intelligence (BI) is a process that involves the collection, integration, analysis, and presentation of business data to support better decision-making.\nHow Does It Work?\n\nData Collection: Gathering data from various sources, like databases.\nData Integration: Combining data into a unified view.\nData Analysis: Identifying trends and insights from data.\nReporting and Visualization: Displaying data via dashboards, reports, and visualizations."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#popular-bi-tools",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#popular-bi-tools",
    "title": "Lecture 4",
    "section": "Popular BI tools",
    "text": "Popular BI tools\n  \n\nPython and R can also be BI tools."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#what-is-a-dashboard",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#what-is-a-dashboard",
    "title": "Lecture 4",
    "section": "What is a Dashboard?",
    "text": "What is a Dashboard?\n\nA dashboard is a visual display of key information, data, and metrics, presented in a way that is easy to read and interpret at a glance.\nDashboard Examples:\n\nMicrosoft Power BI\nTableau\nLooker\nPython and R"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#purpose-of-ml-and-bi-in-business",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#purpose-of-ml-and-bi-in-business",
    "title": "Lecture 4",
    "section": "Purpose of ML and BI in Business",
    "text": "Purpose of ML and BI in Business\n\nInformed Decision-Making: ML and BI provides insights from data to support strategic and operational decisions.\nPerformance Monitoring: Tracks key performance indicators and metrics to ensure goals are met.\nData Visualization: Transforms complex data into easy-to-understand visual formats like dashboards and reports.\nOperational Efficiency: Identifies inefficiencies and areas for improvement within business processes."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-in-the-retail-sector-1",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-in-the-retail-sector-1",
    "title": "Lecture 4",
    "section": "Data Analytics in the Retail Sector",
    "text": "Data Analytics in the Retail Sector\n\nThe retail sector is heavily invested in analytics due to large volumes, thin margins, and rapidly changing customer preferences.\nRetailers like Amazon, Walmart, and Target have made significant investments in analytics to optimize their value chains.\nAnalytics are crucial for understanding suppliers, customers, employees, and stakeholders to make better data-driven decisions.\nThe extensive use of retail analytics by companies like Amazon highlights the potential for numerous applications, many of which are discussed throughout the source material."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-applications-in-the-retail-sector",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-applications-in-the-retail-sector",
    "title": "Lecture 4",
    "section": "Data Analytics Applications in the Retail Sector",
    "text": "Data Analytics Applications in the Retail Sector\n1. Inventory Optimization\n\nKey Questions:\n\nWhich products are in high demand?\nWhich products are slow to sell or becoming outdated?\n\nBusiness Benefits:\n\nPredict demand for fast-moving products and ensure adequate stock to prevent shortages.\nAccelerate the turnover of slow-moving products by pairing them with high-demand items."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-applications-in-the-retail-sector-1",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-applications-in-the-retail-sector-1",
    "title": "Lecture 4",
    "section": "Data Analytics Applications in the Retail Sector",
    "text": "Data Analytics Applications in the Retail Sector\n2. Price Elasticity\n\nKey Questions:\n\nWhat is the net margin for this product?\nWhat discount can be offered on this product?\n\nBusiness Benefits:\n\nOptimize markdowns for each product to minimize margin losses.\nDetermine the best price for product bundles to protect margins.\n\n\nWhile online retailers can tailor user experiences upon login, physical stores struggle with this at the entrance."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-applications-in-the-retail-sector-2",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-applications-in-the-retail-sector-2",
    "title": "Lecture 4",
    "section": "Data Analytics Applications in the Retail Sector",
    "text": "Data Analytics Applications in the Retail Sector\n3. Market Basket Analysis\n\n\nKey Questions:\n\nWhich products should be combined to create a bundle offer?\nShould bundles mix slow-moving and fast-moving items?\nShould bundles consist of products from the same or different categories?\n\nBusiness Benefits:\n\nMachine learning uncovers hidden product correlations, enabling:\n\n\nStrategic product bundling focused on inventory management or margin optimization.\nEnhanced cross-selling or upselling through bundling products from different or the same categories, respectively."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-applications-in-the-retail-sector-3",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-applications-in-the-retail-sector-3",
    "title": "Lecture 4",
    "section": "Data Analytics Applications in the Retail Sector",
    "text": "Data Analytics Applications in the Retail Sector\n4. Shopper Insight\n\n\nKey Questions:\n\nWhich customers are buying which products at which locations?\n\nBusiness Benefits:\n\nBy segmenting customers, businesses can create personalized offers, leading to improved customer experience and retention."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-applications-in-the-retail-sector-4",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-applications-in-the-retail-sector-4",
    "title": "Lecture 4",
    "section": "Data Analytics Applications in the Retail Sector",
    "text": "Data Analytics Applications in the Retail Sector\n5. Customer Churn Analysis\n\nKey Questions:\n\nWhich customers are likely not to return?\nHow much revenue could be lost?\nHow can these customers be retained?\nWhat demographic is most loyal?\n\nBusiness Benefits:\n\nIdentify customer and product relationships with high churn to focus on improving product quality and addressing churn reasons.\nUse customer lifetime value (LTV) to target marketing efforts, enhancing customer retention."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-applications-in-the-retail-sector-5",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-applications-in-the-retail-sector-5",
    "title": "Lecture 4",
    "section": "Data Analytics Applications in the Retail Sector",
    "text": "Data Analytics Applications in the Retail Sector\n6. New Store Analysis\n\nKey Questions:\n\nWhere should a new store be located?\nWhat and how much initial inventory should be stocked?\n\nBusiness Benefits:\n\nLeverage best practices from other locations and channels to ensure a strong start.\nCompare competitor data to develop a unique selling proposition (USP) that attracts new customers."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-applications-in-the-retail-sector-6",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-applications-in-the-retail-sector-6",
    "title": "Lecture 4",
    "section": "Data Analytics Applications in the Retail Sector",
    "text": "Data Analytics Applications in the Retail Sector\n7. Store Layout\n\n\n\nKey Questions:\n\nHow should the store be laid out to maximize sales?\nHow can in-store customer experience be enhanced?\n\nBusiness Benefits:\n\nAnalyze product associations to optimize store layout for customer satisfaction.\nPlan workforce deployment to enhance customer interactions and improve overall experience."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-applications-in-the-retail-sector-7",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-applications-in-the-retail-sector-7",
    "title": "Lecture 4",
    "section": "Data Analytics Applications in the Retail Sector",
    "text": "Data Analytics Applications in the Retail Sector\n8. Video Analytics\n\n\nKey Questions:\n\nWhat demographic is entering the store during peak sales periods?\nHow can a high LTV customer be identified at the store entrance for a personalized experience?\n\nBusiness Benefits:\n\nPlan in-store promotions and events based on the demographics of incoming traffic.\nEnhance customer experience through targeted engagement and instant discounts, leading to higher retention rates."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-vs.-data-science-1",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-vs.-data-science-1",
    "title": "Lecture 4",
    "section": "Data Analytics vs.¬†Data Science",
    "text": "Data Analytics vs.¬†Data Science\nFocus and Key Activities\n\nData Analytics:\n\nPrimarily focuses on examining existing datasets to generate insights.\nIt involves exploratory data analysis, which help in understanding historical data and identifying patterns or trends.\n\nData Science:\n\nEncompasses a broader scope, including data analytics, but extends to predictive analysis.\nData science aims to uncover insights from data through advanced statistical methods and machine learning (ML) methods."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-vs.-data-science-2",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-vs.-data-science-2",
    "title": "Lecture 4",
    "section": "Data Analytics vs.¬†Data Science",
    "text": "Data Analytics vs.¬†Data Science\nKey Activities\n\nData Analytics:\n\nInvolves tidying, transforming, and visualizing data.\nThe goal is to provide actionable insights based on existing data, often through dashboards, reports, or visualizations.\n\nData Science:\n\nInvolves data collection, exploration, and the use of advanced techniques like ML.\nData scientists often work on building ML models that predict future trends or optimize decisions."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-vs.-data-science-3",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-vs.-data-science-3",
    "title": "Lecture 4",
    "section": "Data Analytics vs.¬†Data Science",
    "text": "Data Analytics vs.¬†Data Science\nSkill Sets\n\nData Analytics:\n\nRequires skills in tools like Excel, SQL, and BI software.\nIt may also involve basic statistical knowledge and proficiency in creating data visualizations.\n\nData Science:\n\nRequires a deeper understanding of programming languages like Python or R, advanced statistical methods and machine learning algorithms.\nData scientists often need to have strong mathematical and computational skills."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-vs.-data-science-4",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-vs.-data-science-4",
    "title": "Lecture 4",
    "section": "Data Analytics vs.¬†Data Science",
    "text": "Data Analytics vs.¬†Data Science\nTools & Techniques\n\nData Analytics:\n\nCommonly uses tools like SQL, Tableau, Power BI, and Excel.\nThe focus is on querying data and creating reports or visualizations.\n\nData Science:\n\nUtilizes more advanced tools and techniques such as Python and R with ML-related tools.\nTechniques include data analytics, machine learning, and algorithm development."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-vs.-data-science-5",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-vs.-data-science-5",
    "title": "Lecture 4",
    "section": "Data Analytics vs.¬†Data Science",
    "text": "Data Analytics vs.¬†Data Science\nApplications\n\nData Analytics:\n\nOften used in business intelligence, reporting, trend analysis, and operational decision-making.\n\nData Science:\n\nApplied in areas requiring predictive insights, such as recommendation systems, fraud detection, and customer segmentation."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-vs.-data-science-6",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-vs.-data-science-6",
    "title": "Lecture 4",
    "section": "Data Analytics vs.¬†Data Science",
    "text": "Data Analytics vs.¬†Data Science\nJob Titles\n\nData Analytics:\n\nRoles often include Data Analyst, Business Analyst, BI Analyst, or Reporting Analyst.\n\nData Science:\n\nRoles include Data Scientist, Machine Learning Engineer, Data Engineer, and AI Specialist."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-vs.-data-science-7",
    "href": "danl-lec/danl-101-lec-04-2024-0904.html#data-analytics-vs.-data-science-7",
    "title": "Lecture 4",
    "section": "Data Analytics vs.¬†Data Science",
    "text": "Data Analytics vs.¬†Data Science\nFuzzy Distinctions\n\nThe difference between professionals focusing on descriptive analytics and those engaged in all types of analytics is not clear-cut.\nGraduates of data-related programs often perform tasks aligned with data science."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-1",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-1",
    "title": "Lecture 7",
    "section": "R Basics",
    "text": "R Basics\nFunctions\n\nA function can take any number and type of input parameters and return any number and type of output results.\nR ships a vast number of built-in functions.\nR also allows a user to define a new function.\nWe will mostly use built-in functions."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-2",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-2",
    "title": "Lecture 7",
    "section": "R Basics",
    "text": "R Basics\nFunctions, Arguments, and Parameters\nlibrary(tidyverse)\n\n# The function `str_c()`, provided by `tidyverse`, concatenates characters.\nstr_c(\"Data\", \"Analytics\")\nstr_c(\"Data\", \"Analytics\", sep = \"!\")\n\nWe invoke a function by entering its name and a pair of opening and closing parentheses.\nMuch as a cooking recipe can accept ingredients, a function invocation can accept inputs called arguments.\nWe pass arguments sequentially inside the parentheses (, separated by commas).\nA parameter is a name given to an expected function argument.\nA default argument is a fallback value that R passes to a parameter if the function invocation does not explicitly provide one."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-3",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-3",
    "title": "Lecture 7",
    "section": "R Basics",
    "text": "R Basics\nArithmetic Operations and Mathematical Functions\n\n\nAlgebraMath functions\n\n\n\n\n5 + 3\n5 - 3\n5 * 3\n5 / 3\n5^3\n\n( 3 + 4 )^2\n3 + 4^2\n3 + 2 * 4^2\n3 + 2 * 4 + 2\n(3 + 2) * (4 + 2)\n\n\n\nAll of the basic operators with parentheses we see in mathematics are available to use.\nR can be used for a wide range of mathematical calculations.\n\n\n\n\n\n5 * abs(-3)\nsqrt(17) / 2\nexp(3)\nlog(3)\nlog(exp(3))\nexp(log(3))\n\nR has many built-in mathematical functions that facilitate calculations and data analysis.\n\n\n\nabs(x): the absolute value \\(|x|\\)\nsqrt(x): the square root \\(\\sqrt{x}\\)\nexp(x): the exponential value \\(e^x\\), where \\(e = 2.718...\\)\nlog(x): the natural logarithm \\(\\log_{e}(x)\\), or simply \\(\\log(x)\\)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-4",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-4",
    "title": "Lecture 7",
    "section": "R Basics",
    "text": "R Basics\nVectorized Operations\na &lt;- c(1, 2, 3, 4, 5)\nb &lt;- c(5, 4, 3, 2, 1)\n\na + b\na - b\na * b\na / b\nsqrt(a)\n\nVectorized operations mean applying a function to every element of a vector without explicitly writing a loop.\n\nThis is possible because most functions in R are vectorized, meaning they are designed to operate on vectors element-wise.\nVectorized operations are a powerful feature of R, enabling efficient and concise code for data analysis and manipulation."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#descriptive-statistics",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#descriptive-statistics",
    "title": "Lecture 7",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\n\n\n\n\n\n\nDescriptive statistics condense data into manageable summaries, making it easier to understand key characteristics of the data.\n\nThey help reveal patterns, trends, and relationships within the data that might not be immediately apparent from raw numbers."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#descriptive-statistics-1",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#descriptive-statistics-1",
    "title": "Lecture 7",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\n\nData quality assessment:\n\nDescriptive statistics can highlight potential issues in data quality, such as outliers or unexpected distributions, prompting further investigation.\n\nFoundation for further analysis:\n\nDescriptive statistics often serve as a starting point for more advanced statistical analyses and predictive modeling.\n\nData visualization enhancement:\n\nDescriptive statistics often form the basis for effective data visualizations, making complex data more accessible and understandable."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#descriptive-statistics-2",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#descriptive-statistics-2",
    "title": "Lecture 7",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nMeasures of Central Tendency\n\nMeasures of centrality are used to describe the central or typical value in a given vector.\n\nThey represent the ‚Äúcenter‚Äù or most representative value of a data set.\n\nTo describe this centrality, several statistical measures are commonly used:\n\nMean: The arithmetic average of all values in the data set.\nMedian: The middle value when the data set is ordered from least to greatest.\nMode: The most frequently occurring value in the data set."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#measures-of-central-tendency-1",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#measures-of-central-tendency-1",
    "title": "Lecture 7",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\nMean\n\\[\n\\overline{x} = \\frac{x_{1} + x_{2} + \\cdots + x_{N}}{N}\n\\]\nx &lt;- c(1, 2, 3, 4, 5)\nsum(x)\nmean(x)\n\nThe arithmetic mean (or simply mean or average) is the sum of all the values divided by the number of observations in the data set.\n\nmean() calculates the mean of the values in a vector.\nFor a given vector \\(x\\), if we happen to have \\(N\\) observations \\((x_{1}, x_{2}, \\cdots , x_{N})\\), we can write the arithmetic mean of the data sample as above."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#measures-of-central-tendency-2",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#measures-of-central-tendency-2",
    "title": "Lecture 7",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\nMedian\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx &lt;- c(1, 2, 3, 4, 5)\nmedian(x)\n\nThe median is the measure of center value in a given vector.\n\nmedian() calculates the median of the values in a vector."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#measures-of-central-tendency-3",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#measures-of-central-tendency-3",
    "title": "Lecture 7",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\nMode\n\nThe mode is the value(s) that occurs most frequently in a given vector.\nMode is useful, although it is often not a very good representation of centrality.\nThe R package, modest, provides the mfw(x) function that calculate the mode of values in vector x."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#descriptive-statistics-3",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#descriptive-statistics-3",
    "title": "Lecture 7",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nMeasures of Dispersion\n\nMeasures of dispersion are used to describe the degree of variation in a given vector.\n\nThey are a representation of the numerical spread of a given data set.\n\nTo describe this dispersion, a number of statistical measures are developed\n\nRange\nVariance\nStandard deviation\nQuartile"
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#measures-of-dispersion-1",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#measures-of-dispersion-1",
    "title": "Lecture 7",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\nRange\n\\[\n(\\text{range of x}) \\,=\\, (\\text{maximum value in x}) \\,-\\, (\\text{minimum value in x})\n\\]\nx &lt;- c(1, 2, 3, 4, 5)\nmax(x)\nmin(x)\nrange &lt;- max(x) - min(x)\n\nThe range is the difference between the largest and the smallest values in a given vector.\n\nmax(x) returns the maximum value of the values in a given vector \\(x\\).\nmin(x) returns the minimum value of the values in a given vector \\(x\\)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#measures-of-dispersion-2",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#measures-of-dispersion-2",
    "title": "Lecture 7",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\nVariance\n\\[\n\\overline{s}^{2} = \\frac{(x_{1}-\\overline{x})^{2} + (x_{2}-\\overline{x})^{2} + \\cdots + (x_{N}-\\overline{x})^{2}}{N-1}\\;\\,\n\\]\nx &lt;- c(1, 2, 3, 4, 5)\nvar(x)\n\nThe variance is used to calculate the deviation of all data points in a given vector from the mean.\n\nThe larger the variance, the more the data are spread out from the mean and the more variability one can observe in the data sample.\nTo prevent the offsetting of negative and positive differences, the variance takes into account the square of the distances from the mean.\n\nvar(x) calculates the variance of the values in a vector \\(x\\)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#measures-of-dispersion-3",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#measures-of-dispersion-3",
    "title": "Lecture 7",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\nStandard Deviation\n\\[\n\\overline{s} = \\sqrt{ \\left( \\frac{(x_{1}-\\overline{x})^{2} + (x_{2}-\\overline{x})^{2} + \\cdots + (x_{N}-\\overline{x})^{2}}{N-1}\\;\\, \\right) }\n\\]\nx &lt;- c(1, 2, 3, 4, 5)\nsd(x)\n\nThe standard deviation (SD)‚Äîthe square root of the variance‚Äîis also a measure of the spread of values within a given vector.\n\nsd(x) calculates the standard deviation of the values in a vector \\(x\\)\nSD helps us understand how representative the mean is of the data.\n\nA low SD suggests that the mean is a good summary, while a high SD suggests greater variability around the mean."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#measures-of-dispersion-4",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#measures-of-dispersion-4",
    "title": "Lecture 7",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\nQuartiles\nquantile(x)\nquantile(x, 0) # the minimum\nquantile(x, 0.25) # the 1st quartile\nquantile(x, 0.5) # the 2nd quartile\nquantile(x, 0.75) # the 3rd quartile\nquantile(x, 1) # the maximum\n\nA quartile is a quarter of the number of data points in a given vector.\n\nQuartiles are determined by first sorting the values and then splitting the sorted values into four disjoint smaller data sets.\nQuartiles are a useful measure of dispersion because they are much less affected by outliers or a skewness in the data set than the equivalent measures in the whole data set."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#measures-of-dispersion-5",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#measures-of-dispersion-5",
    "title": "Lecture 7",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\nInterquartile Range\n\n\n\n\n\n\n\n\n\nAn interquartile range describes the difference between the third quartile (Q3) and the first quartile (Q1), telling us about the range of the middle half of the scores in the distribution.\n\nThe quartile-driven descriptive measures (both centrality and dispersion) are best explained with a popular plot called a box plot."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-5",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-5",
    "title": "Lecture 7",
    "section": "R Basics",
    "text": "R Basics\nAbsolute vs.¬†Relative Pathnames\n\n\nAbsolute PathRelative Path\n\n\n\nComplete path from the root directory to the target file or directory.\nIndependent of the current working directory.\nExample\n\nMac:\n\n/Users/user/documents/data/car_data.csv\n\nWindows:\n\nC:\\\\Users\\\\user\\\\Documents\\\\data\\\\car_data.csv\n\n\n\n\n\n\nPath relative to the working directory.\n\nRelative path changes based on the working directory. \n\nExample:\n\nAbsolute pathname for car_data.csv is /Users/user/documents/data/car_data.csv.\nSuppose the current directory is /Users/user/documents/.\nThen, the relative pathname for car_data.csv is dada/car_data.csv.\n\nFor the Posit Cloud project, we can use a relative path.\n\nThe current working directory in is /cloud/project/"
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-6",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-6",
    "title": "Lecture 7",
    "section": "R Basics",
    "text": "R Basics\nWorking with Data from Files\n\n\nWe use the read_csv() function to read a comma-separated values (CSV) file.\n\n\nDownload the CSV file, car_data.csv from the Class Files module in our Brightspace.\nCreate a sub-directory, data, by clicking ‚ÄúNew Folder‚Äù in the Files Pane in Posit Cloud.\nUpload the car_data.csv file to the sub-directory data.\nProvide the relative pathname for the file, car_data.csv, to the read_csv() function.\n\nuciCar &lt;- read_csv('HERE WE PROVIDE A RELATIVE PATHNAME FOR car_data.csv')\nView(uciCar)\n\nView()/view() displays the data in a simple spreadsheet-like grid."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-7",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-7",
    "title": "Lecture 7",
    "section": "R Basics",
    "text": "R Basics\nExamining data.frames\n\n\nclass(uciCar)\ndim(uciCar)\nnrow(uciCar)\nncol(uciCar)\n\nlibrary(skimr)\nskim(uciCar)\n\n\n\ndim() shows how many rows and columns are in the data for data.frame.\nnrow() and ncol() shows the number of rows and columns for data.frame respectively.\nskimr::skim() provides a more detailed summary.\n\nskimr is the R package that provides the function skim()."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-8",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-8",
    "title": "Lecture 7",
    "section": "R Basics",
    "text": "R Basics\nReading data.frames from an URL\ntvshows &lt;- read_csv(\n        'https://bcdanl.github.io/data/tvshows.csv')\n\nWe can import the CSV file from the web."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-9",
    "href": "danl-lec/danl-101-lec-07-2024-0911.html#r-basics-9",
    "title": "Lecture 7",
    "section": "R Basics",
    "text": "R Basics\nTidy data.frame: Variables, Observations, and Values\n\n\n\n\nThere are three rules which make a data.frame tidy:\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n\n\n\n‚Äì&gt;  ‚Äì&gt;  ‚Äì&gt;  ‚Äì&gt;"
  },
  {
    "objectID": "posts/nba/nba.html#salary-distribution-among-teams",
    "href": "posts/nba/nba.html#salary-distribution-among-teams",
    "title": "NBA",
    "section": "Salary Distribution Among Teams",
    "text": "Salary Distribution Among Teams\nLet‚Äôs start with the salary distribution among teams using seaborn for visualization. ‚Äã‚Äã\n\n\nCode\n\n# Handle missing values in 'Salary' by replacing them with the median salary\nmedian_salary = nba['Salary'].median()\nnba['Salary'].fillna(median_salary, inplace=True)\n\n\n\n\nCode\n# Set the aesthetic style of the plots\nsns.set_style(\"whitegrid\")\n\n# Calculate total salary by team\nteam_salary = (\n    nba\n    .groupby('Team')['Salary']\n    .sum()\n    .reset_index()\n    .sort_values(by='Salary', ascending=False)\n)\n\n# Plot total salary by team\nplt.figure(figsize=(10, 8))\nsns.barplot(data = team_salary,\n            x = 'Salary', y = 'Team',\n            palette = 'coolwarm')\nplt.title('Total Salary Distribution Among NBA Teams')\nplt.xlabel('Total Salary')\nplt.ylabel('Team')\nplt.xticks(rotation=45)\nplt.show()\n\n\n\n\n\nThe visualization above displays the total salary distribution among NBA teams, with teams sorted by their total salary expenditure. This bar plot reveals which teams are the biggest spenders on player salaries and which are more conservative. The color gradient provides a visual cue to easily distinguish between the higher and lower spending teams. Portland Trail Blazers spent most in their players‚Äô salary, followed by Golden State Warriors and Philadelphia 76ers."
  },
  {
    "objectID": "posts/nba/nba.html#player-age-distribution",
    "href": "posts/nba/nba.html#player-age-distribution",
    "title": "NBA",
    "section": "Player Age Distribution",
    "text": "Player Age Distribution\nNext, let‚Äôs explore the Player Age Distribution across the NBA. We‚Äôll create a histogram to visualize how player ages are distributed, which will help us understand if the league trends younger, older, or has a balanced age mix. ‚Äã‚Äã\n\n\nCode\n# Convert 'Birthday' column to datetime format\nfrom dateutil import parser\nnba['Birthday'] = nba['Birthday'].apply(lambda x: parser.parse(x))\n\n# Now, let's calculate the age of each player\nnba['Age'] = (datetime.now() - nba['Birthday']).dt.days // 365\n\n# Plot the age distribution of NBA players\nplt.figure(figsize=(10, 6))\nsns.histplot(nba['Age'],\n             bins = 15,\n             kde = True,\n             color = 'skyblue')\nplt.title('Age Distribution of NBA Players')\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.show()\n\n\n\n\n\n\nThe histogram above shows the age distribution of NBA players, with a kernel density estimate (KDE) overlay to indicate the distribution shape. The majority of players fall within a certain age range from 25 to 35, illustrating the league‚Äôs age dynamics. The plot helps identify the common ages for NBA players and whether there are significant numbers of very young or older players."
  },
  {
    "objectID": "posts/nba/nba.html#position-wise-salary-insights",
    "href": "posts/nba/nba.html#position-wise-salary-insights",
    "title": "NBA",
    "section": "Position-wise Salary Insights",
    "text": "Position-wise Salary Insights\nMoving on to Position-wise Salary Insights, we‚Äôll examine how average salaries differ across player positions. This analysis could reveal which positions are typically higher-paid, potentially reflecting their value on the basketball court. Let‚Äôs create a box plot to visualize the salary distribution for each position. ‚Äã‚Äã\n\n\nCode\n# Plot salary distribution by player position\nplt.figure(figsize=(10, 6))\nsns.boxplot(data = nba,\n            x = 'Position', y = 'Salary',\n            palette = 'Set2')\nplt.title('Salary Distribution by Position')\nplt.xlabel('Position')\nplt.ylabel('Salary')\nplt.show()\n\n\n\n\n\nThe box plot above illustrates the salary distribution by player position, showcasing the variation in salaries among different positions within the NBA. This visualization helps us understand which positions tend to have higher median salaries and the spread of salaries within each position, including outliers that represent exceptionally high or low salaries. While the positions of C and PG have the widest interquantiles of salaries, the positions of FC, F, G, and GF have the narrowest interquantiles of them."
  },
  {
    "objectID": "posts/nba/nba.html#top-10-highest-paid-players",
    "href": "posts/nba/nba.html#top-10-highest-paid-players",
    "title": "NBA",
    "section": "Top 10 Highest Paid Players",
    "text": "Top 10 Highest Paid Players\nLastly, we‚Äôll identify the Top 10 Highest Paid Players in the NBA. This analysis highlights the star earners of the league, providing insights into which players command the highest salaries and potentially why. Let‚Äôs extract and visualize this information. ‚Äã‚Äã\n\n\nCode\n# Identify the top 10 highest paid players\ntop_10_salaries = nba.sort_values(by='Salary', ascending=False).head(10)\n\n# Plot the top 10 highest paid players\nplt.figure(figsize=(12, 8))\nsns.barplot(data = top_10_salaries,\n            x = 'Salary', y = 'Name',\n            palette = 'viridis')\nplt.title('Top 10 Highest Paid NBA Players')\nplt.xlabel('Salary')\nplt.ylabel('Player')\nplt.show()\n\n\n\n\n\nThe bar chart above reveals the top 10 highest-paid NBA players, showcasing those who stand at the pinnacle of the league in terms of salary. Stephen Curry is the highest-paid NBA player, followed by Russel Westbrook and Chris Paul. This visualization not only highlights the star players who command the highest salaries but also may reflect their marketability, performance, and contribution to their respective teams."
  },
  {
    "objectID": "posts/py-basic/blog-python-basics.html",
    "href": "posts/py-basic/blog-python-basics.html",
    "title": "Python Basics",
    "section": "",
    "text": "Python is a high-level, interpreted programming language. This is a simple Python code:\n\n\nCode\nprint('Hello, World!')\n\n\n\n\n\nIn Python, variables can store data of different types without explicitly declaring the type.\nFor example:\n\n\nCode\ninteger_variable = 10\nstring_variable = 'Hello'\nfloat_variable = 10.5\n\nfloat_variable\n\n\n10.5\n\n\n\n\n\nPython supports the usual logical conditions from mathematics:\n\n\nCode\n# Equals: a == b\n# Not Equals: a != b\n# Less than: a &lt; b\n# Less than or equal to: a &lt;= b\n# Greater than: a &gt; b\n# Greater than or equal to: a &gt;= b\n\n\nThese conditions can be used in several ways, most commonly in ‚Äòif statements‚Äô and loops.\n\n\nCode\n# if statement:\nif 5 &gt; 2:\n    print('Five is greater than two!')\n\n\n\n\n\nA function is a block of code which only runs when it is called.\nYou can pass data, known as parameters, into a function.\nA function can return data as a result.\n\n\nCode\n# Defining a function:\ndef my_function():\n    print('Hello from a function')\n\n# Calling a function:\nmy_function()\n\n\n\n\n\nA list is a collection which is ordered and changeable.\nA dictionary is a collection which is unordered, changeable and indexed.\n\n\nCode\n# List example:\nmy_list = ['apple', 'banana', 'cherry']\n\n# Dictionary example:\nmy_dict = {'name': 'John', 'age': 36}"
  },
  {
    "objectID": "posts/py-basic/blog-python-basics.html#what-is-python",
    "href": "posts/py-basic/blog-python-basics.html#what-is-python",
    "title": "Python Basics",
    "section": "",
    "text": "Python is a high-level, interpreted programming language. This is a simple Python code:\n\n\nCode\nprint('Hello, World!')"
  },
  {
    "objectID": "posts/py-basic/blog-python-basics.html#variables-and-data-types",
    "href": "posts/py-basic/blog-python-basics.html#variables-and-data-types",
    "title": "Python Basics",
    "section": "",
    "text": "In Python, variables can store data of different types without explicitly declaring the type.\nFor example:\n\n\nCode\ninteger_variable = 10\nstring_variable = 'Hello'\nfloat_variable = 10.5\n\nfloat_variable\n\n\n10.5"
  },
  {
    "objectID": "posts/py-basic/blog-python-basics.html#control-structures",
    "href": "posts/py-basic/blog-python-basics.html#control-structures",
    "title": "Python Basics",
    "section": "",
    "text": "Python supports the usual logical conditions from mathematics:\n\n\nCode\n# Equals: a == b\n# Not Equals: a != b\n# Less than: a &lt; b\n# Less than or equal to: a &lt;= b\n# Greater than: a &gt; b\n# Greater than or equal to: a &gt;= b\n\n\nThese conditions can be used in several ways, most commonly in ‚Äòif statements‚Äô and loops.\n\n\nCode\n# if statement:\nif 5 &gt; 2:\n    print('Five is greater than two!')"
  },
  {
    "objectID": "posts/py-basic/blog-python-basics.html#functions",
    "href": "posts/py-basic/blog-python-basics.html#functions",
    "title": "Python Basics",
    "section": "",
    "text": "A function is a block of code which only runs when it is called.\nYou can pass data, known as parameters, into a function.\nA function can return data as a result.\n\n\nCode\n# Defining a function:\ndef my_function():\n    print('Hello from a function')\n\n# Calling a function:\nmy_function()"
  },
  {
    "objectID": "posts/py-basic/blog-python-basics.html#lists-and-dictionaries",
    "href": "posts/py-basic/blog-python-basics.html#lists-and-dictionaries",
    "title": "Python Basics",
    "section": "",
    "text": "A list is a collection which is ordered and changeable.\nA dictionary is a collection which is unordered, changeable and indexed.\n\n\nCode\n# List example:\nmy_list = ['apple', 'banana', 'cherry']\n\n# Dictionary example:\nmy_dict = {'name': 'John', 'age': 36}"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html",
    "href": "posts/beer-markets/beer-markets.html",
    "title": "Beer Markets",
    "section": "",
    "text": "Diving into the complex world of what people like in their beer, the beer_markets.csv dataset comes across as a goldmine of data, showing us the detailed interactions between buyers and their favorite beers. This dataset covers everything from how much and at what price people are buying beer to how deals and brand loyalty influence their decisions, across different types of people and places. As we start digging into this dataset, we aim to uncover the patterns that show what really influences the modern beer drinker‚Äôs choices, offering up valuable insights for marketers, industry watchers, and beer lovers. By breaking down the data, our exploration will shine a light on the factors that drive consumer behavior in the beer market, giving us a full picture of the trends that shape this lively industry.\nCode\n# Creating an interactive table\n!pip install itables\nfrom itables import init_notebook_mode\nfrom itables import show\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Reading the CSV file\nbeer_data = pd.read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")\nshow(beer_data)\n\n\n\n\n\n\n\n    \n      \n      hh\n      _purchase_desc\n      quantity\n      brand\n      dollar_spent\n      beer_floz\n      price_per_floz\n      container\n      promo\n      market\n      buyertype\n      income\n      childrenUnder6\n      children6to17\n      age\n      employment\n      degree\n      cow\n      race\n      microwave\n      dishwasher\n      tvcable\n      singlefamilyhome\n      npeople\n    \n  Loading... (need help?)\nCode\n# Setting up the visualization settings\nsns.set(style=\"whitegrid\")\n\n# Calculate total quantity and spending for each brand\nbrand_summary = beer_data.groupby('brand').agg({'quantity':'sum', 'dollar_spent':'sum'}).reset_index()\n\n# Sort by total quantity and spending\nbrand_summary_sorted_quantity = brand_summary.sort_values('quantity', ascending=False)\nbrand_summary_sorted_spent = brand_summary.sort_values('dollar_spent', ascending=False)\nCode\n# Plotting total quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=brand_summary_sorted_quantity, palette='viridis')\nplt.title('Total Quantity of Beer Purchased by Brand')\nplt.xlabel('Total Quantity')\nplt.ylabel('Brand')\nplt.show()\nThe bar charts above display the total quantity of beer purchased and the total spending by brand. From the looks of it, certain brands dominate in terms of quantity sold and total spending, indicating their popularity.\nNow, let‚Äôs calculate the average quantity purchased and average spending per purchase. For this, we‚Äôll consider each row in the dataset as a separate purchase and compute the averages accordingly.\nCode\n# Calculate average quantity purchased and average spending per purchase\naverage_purchase = beer_data.groupby('brand').agg({\n    'quantity': 'mean',\n    'dollar_spent': 'mean'\n}).reset_index()\n\n# Sort by average quantity and average spending\naverage_purchase_sorted_quantity = average_purchase.sort_values('quantity', ascending=False)\naverage_purchase_sorted_spent = average_purchase.sort_values('dollar_spent', ascending=False)\n\n# Plotting average quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=average_purchase_sorted_quantity, palette='viridis')\nplt.title('Average Quantity of Beer Purchased by Brand')\nplt.xlabel('Average Quantity')\nplt.ylabel('Brand')\nplt.show()\nThe visualizations above depict the average quantity of beer purchased per brand and the average spending per brand. This shows which brands tend to be bought in larger quantities on average and which brands tend to have higher spending per purchase, which could be indicative of their price point or the purchase of premium products.\nNext, we‚Äôll look at the total spending across different markets to see if there are any notable differences in spending habits geographically. To do this, we‚Äôll sum up the spending in each market and visualize it.\nCode\n# Calculate total spending in each market\nmarket_spending_summary = beer_data.groupby('market').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nmarket_spending_summary_sorted = market_spending_summary.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending in each market\nplt.figure(figsize=(12, 18))\nsns.barplot(x='dollar_spent', y='market', data=market_spending_summary_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Market')\nplt.xlabel('Total Spending')\nplt.ylabel('Market')\nplt.show()\nThe bar chart illustrates the total spending on beer by market, showcasing the differences in spending habits across various regions. Some markets have significantly higher spending, which could be due to a variety of factors including market size, consumer preferences, or economic factors.\nNow, let‚Äôs move on to the second analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "href": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "title": "Beer Markets",
    "section": "Demographic Analysis",
    "text": "Demographic Analysis\nWe will examine which demographics are buying what kind of beer and whether spending habits vary by demographics such as age, employment, and race. For this, we could look at:\n\nSpending by age group\nSpending by employment status\nSpending by race\n\nI‚Äôll start by analyzing spending by age group.\n\n\nCode\n# Calculate total spending by age group\nage_group_spending = beer_data.groupby('age').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nage_group_spending_sorted = age_group_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by age group\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='age', data=age_group_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Age Group')\nplt.xlabel('Total Spending')\nplt.ylabel('Age Group')\nplt.show()\n\n\n\n\n\nThe bar chart demonstrates the total spending on beer segmented by age group, highlighting which age groups spend the most on beer. It appears that certain age groups are more dominant in beer spending, which may align with the purchasing power or preferences of those groups.\nNext, we will examine spending by employment status.\n\n\nCode\n# Calculate total spending by employment status\nemployment_spending = beer_data.groupby('employment').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nemployment_spending_sorted = employment_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by employment status\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='employment', data=employment_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Employment Status')\nplt.xlabel('Total Spending')\nplt.ylabel('Employment Status')\nplt.show()\n\n\n\n\n\nThe visualization shows the total spending on beer by employment status. We can see that certain employment groups, such as full-time workers, are spending more on beer, which might be related to their disposable income.\nFinally, let‚Äôs look at spending by race to complete the demographic analysis.\n\n\nCode\n# Calculate total spending by race\nrace_spending = beer_data.groupby('race').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nrace_spending_sorted = race_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by race\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='race', data=race_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Race')\nplt.xlabel('Total Spending')\nplt.ylabel('Race')\nplt.show()\n\n\n\n\n\nThe bar chart above indicates the total spending on beer broken down by race, highlighting which racial groups account for the most beer spending within the dataset. This could reflect both the demographics of the regions where the data was collected and cultural preferences regarding beer.\nNow, let‚Äôs proceed to the third analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "href": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "title": "Beer Markets",
    "section": "Price Sensitivity",
    "text": "Price Sensitivity\nWe‚Äôll look at the price per fluid ounce and see if there are any trends or correlations with the quantity purchased or the brand popularity. To do this, we‚Äôll visualize how the price is sensitive to the quantity purchased by brand.\n\n\nCode\n# Ensure there's no entries with 0 for 'price_per_floz' or 'quantity' to avoid log(0) issues\nfiltered_data = beer_data[(beer_data['price_per_floz'] &gt; 0) & (beer_data['quantity'] &gt; 0)]\n\n# Calculate log values for both 'price_per_floz' and 'quantity'\nfiltered_data['log_price_per_floz'] = np.log(filtered_data['price_per_floz'])\nfiltered_data['log_quantity'] = np.log(filtered_data['quantity'])\n\n# Use seaborn to create a scatterplot with fitted lines, facetted by 'brand'\ng = sns.lmplot(data=filtered_data, x='log_quantity', y='log_price_per_floz', col='brand', col_wrap=4, height=3, line_kws={'color': 'red'}, scatter_kws={'alpha':0.5}, aspect = .75)\n\n# Adjusting plot aesthetics\ng.set_titles(\"{col_name}\")\ng.set_axis_labels(\"Log of Quantity\", \"Log of Price per Floz\")\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle('Log of Price per Floz vs. Log of Quantity')\n\nplt.show()\n\n\n\n\n\nHere‚Äôs the scatterplot with fitted straight lines for the log of price_per_floz versus the log of quantity, facetted by brands. Each subplot represents a different brand, showing the relationship between these two logarithmic variables along with a fitted line to illustrate the trend within each brand‚Äôs data.\n\n\nCode\n# Adjust the facetting to split rows by 'brand' and columns by 'promo' for a more detailed comparative analysis\ng = sns.lmplot(data=filtered_data, x='log_quantity', y='log_price_per_floz', row='brand', col='promo', height=3, aspect=.75, line_kws={'color': 'red'}, scatter_kws={'alpha':0.5})\n\n# Adjusting plot aesthetics\ng.set_titles(\"Brand: {row_name}\\n Promo: {col_name}\")\ng.set_axis_labels(\"Log of Quantity\", \"Log of Price per Floz\")\nplt.subplots_adjust(top=0.9, wspace = .4, hspace = .4)\ng.fig.suptitle('Log of Price per Floz vs. Log of Quantity')\n\nplt.show()\n\n\n\n\n\nThe scatterplot has been reorganized to split rows by brand and columns by promo status, offering a comprehensive view across different brands and their promotional status. Each subplot now provides a clear comparison of the log of price_per_floz versus the log of quantity for purchases made on promotion versus those that were not, across various beer brands.\nThis layout facilitates an easier comparison across brands and how promotion impacts the relationship between quantity and price per fluid ounce within each brand.\nLastly, let‚Äôs move to the fourth analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#promotional-impact-on-quantity-purchased",
    "href": "posts/beer-markets/beer-markets.html#promotional-impact-on-quantity-purchased",
    "title": "Beer Markets",
    "section": "Promotional Impact on Quantity Purchased",
    "text": "Promotional Impact on Quantity Purchased\nWe‚Äôll assess the impact of promotions on the quantity of beer purchased. For this analysis, we can calculate the average quantity purchased with and without promotions and visualize the difference. We‚Äôll do this for each brand to see which brands are most affected by promotions.\nLet‚Äôs begin this analysis by looking at the average quantity purchased with and without promotions for each brand.\n\n\nCode\n# Calculate average quantity purchased with and without promotions for each brand\npromo_impact = beer_data.groupby(['brand', 'promo']).agg({'quantity':'mean'}).reset_index()\n\n# Pivot the data to have promo and non-promo side by side for each brand\npromo_impact_pivot = promo_impact.pivot(index='brand', columns='promo', values='quantity').reset_index()\npromo_impact_pivot.columns = ['brand', 'non_promo', 'promo']\n\n# Calculate the difference in average quantity purchased between promo and non-promo\npromo_impact_pivot['promo_impact'] = promo_impact_pivot['promo'] - promo_impact_pivot['non_promo']\n\n# Sort by the impact of promo\npromo_impact_pivot_sorted = promo_impact_pivot.sort_values('promo_impact', ascending=False)\n\n# Plotting the difference in average quantity purchased between promo and non-promo for each brand\nplt.figure(figsize=(12, 10))\nsns.barplot(x='promo_impact', y='brand', data=promo_impact_pivot_sorted, palette='viridis')\nplt.title('Impact of Promotions on Average Quantity Purchased by Brand')\nplt.xlabel('Difference in Average Quantity Purchased (Promo - Non-Promo)')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\n\nThe bar chart illustrates the impact of promotions on the average quantity of beer purchased by brand. A positive value indicates that, on average, more beer is purchased when there is a promotion compared to when there isn‚Äôt. Some brands appear to be significantly more influenced by promotions, with customers buying more when the products are on sale or promotion.\nThis comprehensive analysis has provided insights into purchase patterns, demographic preferences, price sensitivity, and the impact of promotions on beer purchases."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DANL 101-05: Introduction to Data Analytics, Fall 2024",
    "section": "",
    "text": "Welcome! üëã\n\\(-\\) Explore, Learn, and Grow with Data Analytics! üåü"
  },
  {
    "objectID": "index.html#bullet-lecture-slides",
    "href": "index.html#bullet-lecture-slides",
    "title": "DANL 101-05: Introduction to Data Analytics, Fall 2024",
    "section": "\\(\\bullet\\,\\) Lecture Slides üöÄ",
    "text": "\\(\\bullet\\,\\) Lecture Slides üöÄ\n\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nLecture 17\n\n\nOctober 11, 2024\n\n\n\n\nLecture 16\n\n\nOctober 7, 2024\n\n\n\n\nLecture 15\n\n\nOctober 4, 2024\n\n\n\n\nLecture 14\n\n\nSeptember 30, 2024\n\n\n\n\nLecture 13\n\n\nSeptember 27, 2024\n\n\n\n\nLecture 12\n\n\nSeptember 25, 2024\n\n\n\n\nLecture 11\n\n\nSeptember 23, 2024\n\n\n\n\nLecture 10\n\n\nSeptember 20, 2024\n\n\n\n\nLecture 9\n\n\nSeptember 16, 2024\n\n\n\n\nLecture 8\n\n\nSeptember 13, 2024\n\n\n\n\nLecture 7\n\n\nSeptember 11, 2024\n\n\n\n\nLecture 6\n\n\nSeptember 9, 2024\n\n\n\n\nLecture 5\n\n\nSeptember 6, 2024\n\n\n\n\nLecture 4\n\n\nSeptember 4, 2024\n\n\n\n\nLecture 3\n\n\nAugust 30, 2024\n\n\n\n\nLecture 2\n\n\nAugust 28, 2024\n\n\n\n\nLecture 1\n\n\nAugust 26, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#bullet-course-q-a",
    "href": "index.html#bullet-course-q-a",
    "title": "DANL 101-05: Introduction to Data Analytics, Fall 2024",
    "section": "\\(\\bullet\\,\\) Course Q & A ‚ùì",
    "text": "\\(\\bullet\\,\\) Course Q & A ‚ùì\n\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nSetting the Tool\n\n\nSeptember 5, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#bullet-classwork",
    "href": "index.html#bullet-classwork",
    "title": "DANL 101-05: Introduction to Data Analytics, Fall 2024",
    "section": "\\(\\bullet\\,\\) Classwork ‚å®Ô∏è",
    "text": "\\(\\bullet\\,\\) Classwork ‚å®Ô∏è\n\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nfilter(), arrange(), and distinct()\n\n\nOctober 7, 2024\n\n\n\n\nselect() and rename()\n\n\nOctober 7, 2024\n\n\n\n\nQuiz 1 - Addendum\n\n\nOctober 7, 2024\n\n\n\n\nQuiz 1\n\n\nOctober 4, 2024\n\n\n\n\nleft_join()\n\n\nSeptember 26, 2024\n\n\n\n\nR Basics II\n\n\nSeptember 18, 2024\n\n\n\n\nR Basics I\n\n\nSeptember 16, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#bullet-homework",
    "href": "index.html#bullet-homework",
    "title": "DANL 101-05: Introduction to Data Analytics, Fall 2024",
    "section": "\\(\\bullet\\,\\) Homework üíª",
    "text": "\\(\\bullet\\,\\) Homework üíª\n\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nHomework Assignment 2 - Example Answers\n\n\nOctober 10, 2024\n\n\n\n\nHomework Assignment 2\n\n\nOctober 4, 2024\n\n\n\n\nHomework Assignment 1 - Example Answers\n\n\nOctober 3, 2024\n\n\n\n\nHomework Assignment 1\n\n\nSeptember 19, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "listing-danl-101-lec.html",
    "href": "listing-danl-101-lec.html",
    "title": "DANL 101 - Lecture",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nLecture 17\n\n\nNobel Prize for Machine Learning; Midterm I Review\n\n\nOctober 11, 2024\n\n\n\n\nLecture 16\n\n\nData Preparation and Management with R\n\n\nOctober 7, 2024\n\n\n\n\nLecture 15\n\n\nData Preparation and Management with R\n\n\nOctober 4, 2024\n\n\n\n\nLecture 14\n\n\nData Preparation and Management with R\n\n\nSeptember 30, 2024\n\n\n\n\nLecture 13\n\n\nData Preparation and Management\n\n\nSeptember 27, 2024\n\n\n\n\nLecture 12\n\n\nData Preparation and Management\n\n\nSeptember 25, 2024\n\n\n\n\nLecture 11\n\n\nData Preparation and Management\n\n\nSeptember 23, 2024\n\n\n\n\nLecture 10\n\n\nData Preparation and Management\n\n\nSeptember 20, 2024\n\n\n\n\nLecture 9\n\n\nR Basics\n\n\nSeptember 16, 2024\n\n\n\n\nLecture 8\n\n\nR Basics\n\n\nSeptember 13, 2024\n\n\n\n\nLecture 7\n\n\nR Basics\n\n\nSeptember 11, 2024\n\n\n\n\nLecture 6\n\n\nR Basics\n\n\nSeptember 9, 2024\n\n\n\n\nLecture 5\n\n\nRStudio; R Basics\n\n\nSeptember 6, 2024\n\n\n\n\nLecture 4\n\n\nBusiness Intelligence; Data Analytics in the Retail Sector; Data Analytics vs.¬†Data Science; RStudio\n\n\nSeptember 4, 2024\n\n\n\n\nLecture 3\n\n\nIntroduction with Sports Analytics\n\n\nAugust 30, 2024\n\n\n\n\nLecture 2\n\n\nPrologue\n\n\nAugust 28, 2024\n\n\n\n\nLecture 1\n\n\nSyllabus, Course Outline, and Introduction\n\n\nAugust 26, 2024\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "econml.html",
    "href": "econml.html",
    "title": "Causal Machine Learning Bookmarks",
    "section": "",
    "text": "Dive into Causal Machine Learning, The World Bank and Pontificia Universidad Cat√≥lica del Per√∫, Alexander Quispe et. al. \nMIT 14.388: Inference on Causal and Structural Parameters Using ML and AI, Department of Economics, MIT, Victor Chernozukhov\n\nPython Website\nJulia Website \n\nMGTECON 634: ML-based Causal Inference, Stanford, Susan Athey \nMachine Learning & Causal Inference: A Short Course, Stanford, Susan Athey, Jan Spiess, and Stefan Wager\n\nTutorial\nYouTube \n\n2018 American Economic Association Continuing Education: Machine Learning and Econometrics, Susan Athey and Guido Imbens \nCausal Inference and Machine Learning in Practice with EconML and CausalML: Industrial Use Cases at Microsoft, TripAdvisor, Uber \nDoubleML: Python and R Packages for the Double/Debiased Machine Learning Framework, P. Bach, V. Chernozhukov, M. S. Kurz, and M. Spindler \nEconML: A Python Package for ML-based Heterogeneous Treatment Effects Estimation, Microsoft \nCausalML: A Python Package for ML-based Causal Inference, Uber"
  },
  {
    "objectID": "econml.html#causal-machine-learning",
    "href": "econml.html#causal-machine-learning",
    "title": "Causal Machine Learning Bookmarks",
    "section": "",
    "text": "Dive into Causal Machine Learning, The World Bank and Pontificia Universidad Cat√≥lica del Per√∫, Alexander Quispe et. al. \nMIT 14.388: Inference on Causal and Structural Parameters Using ML and AI, Department of Economics, MIT, Victor Chernozukhov\n\nPython Website\nJulia Website \n\nMGTECON 634: ML-based Causal Inference, Stanford, Susan Athey \nMachine Learning & Causal Inference: A Short Course, Stanford, Susan Athey, Jan Spiess, and Stefan Wager\n\nTutorial\nYouTube \n\n2018 American Economic Association Continuing Education: Machine Learning and Econometrics, Susan Athey and Guido Imbens \nCausal Inference and Machine Learning in Practice with EconML and CausalML: Industrial Use Cases at Microsoft, TripAdvisor, Uber \nDoubleML: Python and R Packages for the Double/Debiased Machine Learning Framework, P. Bach, V. Chernozhukov, M. S. Kurz, and M. Spindler \nEconML: A Python Package for ML-based Heterogeneous Treatment Effects Estimation, Microsoft \nCausalML: A Python Package for ML-based Causal Inference, Uber"
  },
  {
    "objectID": "econml.html#machine-learning-and-big-data",
    "href": "econml.html#machine-learning-and-big-data",
    "title": "Causal Machine Learning Bookmarks",
    "section": "Machine Learning and Big Data",
    "text": "Machine Learning and Big Data\n\n2023 American Economic Association Continuing Education: Machine Learning and Big Data, Melissa Dell and Matthew Harding \nMachine Learning for Economists (ml4econ), Bank of Israel, Itamar Caspi and Ariel Mansura"
  },
  {
    "objectID": "econml.html#causal-inference",
    "href": "econml.html#causal-inference",
    "title": "Causal Machine Learning Bookmarks",
    "section": "Causal Inference",
    "text": "Causal Inference\n\nCausal Inference: The Mixtape, Scott Cunningham \nCausal Inference for the Brave and True, Matheus Facure \nCausal Inference and Its Applications in Online Industry, Alex Deng \nApplied Empirical Methods, Yale SOM, Paul Goldsmith-Pinkham\n\nYouTube \n\nCausal Inference with Panel Data, Department of Political Science, Stanford, Yiqing Xu\n\nYouTube \n\nCausal Inference: What If, Miguel A. Hern√°n and James M. Robins \nRecent Developments in Difference-in-Differences, Vienna University of Economics and Business, Asjad Naqvi \nDifference-in-Differences Blog \nGov 2003: Causal Inference, Department of Government, Harvard, Matthew Blackwell"
  },
  {
    "objectID": "econml.html#researchers-in-causal-machine-learning",
    "href": "econml.html#researchers-in-causal-machine-learning",
    "title": "Causal Machine Learning Bookmarks",
    "section": "Researchers in Causal Machine Learning",
    "text": "Researchers in Causal Machine Learning\n\nSusan Athey \nAlexandre Belloni \nVictor Chernozhukov \nCarlos Cinelli \nChristian Hansen \nGuido Imbens\nJann Spiess \nStefan Wager"
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html",
    "href": "danl-hw/danl-101-hw-01.html",
    "title": "Homework Assignment 1",
    "section": "",
    "text": "Please answer all of the following questions thoroughly, ensuring that none are left unanswered.\nFor Homework Assignment 1, the use of any generative artificial intelligence (AI) tools is strictly prohibited.\nOnce you have completed the assignment, click the ‚ÄúSubmit‚Äù button at the bottom of this page to have it evaluated.\n\nAfter clicking ‚ÄúSubmit‚Äù button, wait for the message, ‚ÄúData submitted successfully!‚Äù.\nA confirmation email will be sent to the email address that you provide on this homework page once your submission is received.\n\nYou may submit multiple times, but only your most recent submission will be evaluated.\nThe due is September 23, 9:30 A.M., 2024, Monday, Eastern Time.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "cv/cv.html",
    "href": "cv/cv.html",
    "title": "Bio",
    "section": "",
    "text": "I view myself as an applied economist with interest in environmental economics and a particular focus on climate change. Methodologically, I make use of causal inference/econometrics/machine learning methods, and other data science tools to conduct empirical analysis. I also use computational methods to solve integrated assessment models of climate change and theoretical economic models, such as dynamic contracts.\nMy research focuses on how to improve effectiveness of climate policy at both micro and macro levels. In particular, I am interested in building relevant climate-economy models that analyze the interaction between economies and the climate under risks arising from (1) climate change and (2) a transition to carbon-neutral economies.\nAs an economics and data science teacher, my goal is to equip students with the essential tools of machine learning, econometrics, and data science to think critically about business and real-world socioeconomic issues. In this regard, I teach students to use those tools to address important business strategies, socioeconomic issues, and individual decision-making."
  },
  {
    "objectID": "cv/cv.html#working-papers",
    "href": "cv/cv.html#working-papers",
    "title": "Bio",
    "section": "Working papers",
    "text": "Working papers\n\n\n\n\n\n\n\n\nGovernance and Climate Finance in the Developing World (with Tilsa Ore-Monago) (Forthcoming in Springer Nature)\n Abstract : We investigate the relationship between governance and climate finance, particularly in the context of the energy transition in developing countries. Our aim is to examine how governance qualities in developing countries impact financial contributions from contributor countries that intend to fund mitigation projects in the energy sector. We have compiled a dataset of yearly climate finance contributions at the project level spanning from 2011 to 2019. Our analysis, which utilizes random forests and LASSO estimations, reveals that climate finance contributions, particularly those for energy-related projects, are significantly linked to good governance, including a robust legal system, rule of law, and accountability. Ultimately, this study provides valuable insights into the dynamics between governance and climate finance in developing countries and informs policy decisions to support effective climate action in the energy sector. (One of the chapters in the book, \"Climate Finance: Supporting a Sustainable Energy Transition,\" Springer Nature. 2024).\n\n\nSocial Media Campaigns, Lobbying and Legislation: Evidence from #climatechange/#globalwarming and Energy Lobbies\n Abstract : To what extent do social media campaigns compete with fossil fuel lobbying on climate change legislation? In this article, I estimate the effect of social media campaigns on a congressperson's legislative activities against climate change actions during the U.S. Congresses (January 2013-January 2019). I find that (1) a 1% increase in the per-capita level of activities of climate change campaigns using Twitter decreases Democrats' tendency to support climate-unfriendly legislation by 0.9%, while it increases Republicans' one by 0.2%; and (2) a 1% increase in the fossil fuel industry's lobbying expenditure relative to the rest of industries' lobbying expenditure increases Republicans' tendency to support climate-unfriendly legislation by 1.1%. I also find that negative sentiment in social media campaigns contributes to affecting congresspersons' support for climate-unfriendly legislation.\n\n\nClimate Finance under Conflicts and Renegotiations: A Dynamic Contract Approach (AEA 2019 poster) \n Abstract : Considering climate funds (e.g. the Green Climate Fund) as the financial mechanism to provide funding to developing countries, this paper examines a long-term climate funding relationship between two agents---the rich country and the poor country. Conflicts between the rich and poor countries arise when determining 1) the size of climate funding that the rich country contributes to the poor country, and 2) the funding allocation between climate adaptation and mitigation projects in the poor country. In addition, the rich country cannot be forced to commit contractual contributions to the poor country, and the climate funding relationship can be repeatedly renegotiated. This paper derives the following results: (1) climate funds converge to the first-best in the long-run, in terms of the size of climate funding and its balance between adaptation and mitigation projects, if and only if climate damage becomes sufficiently severe. (2) funding allocation between adaptation and mitigation projects becomes more favorable to the poor country if marginal climate costs in the poor country grow faster than in the rich country. (3) fewer conflicts and fewer renegotiations between the rich and poor countries make climate funding contracts more efficient, remedying inequality between the poor and rich countries."
  },
  {
    "objectID": "cv/cv.html#work-in-progress",
    "href": "cv/cv.html#work-in-progress",
    "title": "Bio",
    "section": "Work in progress",
    "text": "Work in progress\n\n\n\n\n\n\n\n\nHiding Behind a Small Cake' in an Online Dictator Game: The Way You Hide Matters!, (with Tabare Capitan (1st author) , Jason Shogren, and Benjamin White)¬†\n Abstract : Using an online dictator game in which receivers have incomplete information of the size of the endowment (big or small), the article, ''Hiding behind a small cake' in a newspaper dictator game (Ockenfels and Werner (2012))'' shows that a few givers who received the big endowment use their giving to signal they received the small endowment (i.e., to lie). In other words, even though a giver will never meet the corresponding receiver, he cares enough about how he could be perceived by others to lie (i.e., second-order beliefs enters his utility function). In our experiment we provide givers with the opportunity to lie about the size of the endowment without using their giving. Similar to Ockenfels and Werner (2012) we find that (i) few take the opportunity to lie---but those who do give less when their giving is not constrained by its role as a signal---and (ii) givers are more likely to lie when the lie is private. However, using a second stage in the experimental design, we show that liars are the most responsive group of givers to a simple message stating the expectation of the receiver."
  },
  {
    "objectID": "cv/cv.html#presentations",
    "href": "cv/cv.html#presentations",
    "title": "Bio",
    "section": "Presentations",
    "text": "Presentations\n\n\n\n\n\n2023\nSouthern Economic Association Annual Meeting, New Orleans, Louisiana\n\n\n2022\nInterdisciplinary Data Science Workshop, Brigham Young University, Provo, Utah\n\n\n2021\nOnline Seminar, Department of Environmental and Business Economics, University of Southern Denmark\n\n\n2019\nUniversity of Wyoming & Colorado State University Economics Graduate Student Symposium, Laramie, Wyoming\n\n\n2019\nAmerican Economic Association Annual Meeting (poster session), Atlanta, Georgia\n\n\n2018\nThe 29th International Conference on Game Theory, Stony Brook, New York"
  },
  {
    "objectID": "cv/cv.html#memberships",
    "href": "cv/cv.html#memberships",
    "title": "Bio",
    "section": "Memberships",
    "text": "Memberships\n\n\n\n\n\n2022‚Äîpresent\nSouthern Economic Association\n\n\n2018‚Äîpresent\nAssociation of Environmental and Resource Economists\n\n\n2017‚Äîpresent\nAmerican Economic Association\n\n\n2017‚Äî2019\nEconometric Society"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#r-basics-1",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#r-basics-1",
    "title": "Lecture 9",
    "section": "R Basics",
    "text": "R Basics\nAccessing Subsets of Vectors in R\n\n\nAn important aspect of working with R objects is knowing how to ‚Äúindex‚Äù them.\n\nIndexing enables the filtering of data subsets for further analysis.\n\nWe focus on two primary types of vector indexing: positional and logical.\nTo access elements in a vector vec, use vec[] with one of these methods:\n\nSingle index: vec[n] where n is a positive integer\nVector of indices: vec[c(i, j, k)] where i, j, k are positive integers\nLogical condition: vec[condition] where condition is a logical expression"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#r-basics-2",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#r-basics-2",
    "title": "Lecture 9",
    "section": "R Basics",
    "text": "R Basics\nAccessing Subsets of Vectors in R\nPositional Indexing\n\nAn index is a positional reference (e.g., 1, 2, 3) used to access individual elements within data structures like a vector.\n\nIn R, the index is positive integer, starting at 1.\n\nmy_vector &lt;- c(10, 20, 30, 40, 50, 60)\nmy_vector[2]\nmy_vector[4]\nmy_vector[6]"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#r-basics-3",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#r-basics-3",
    "title": "Lecture 9",
    "section": "R Basics",
    "text": "R Basics\nAccessing Subsets of Vectors in R\nA Vector of Indices\n\nSelecting multiple elements by providing a vector of indices\n\nmy_vector[ c(3,4,5) ]\nmy_vector[ 3:5 ]"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#r-basics-4",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#r-basics-4",
    "title": "Lecture 9",
    "section": "R Basics",
    "text": "R Basics\nAccessing Subsets of Vectors in R\nLogical Indexing\n\nUsing conditions to filter elements of a vector.\n\n# Filter elements greater than 10\nis_greater_than_10 &lt;- my_vector &gt; 10  # Creates logical vector\nmy_vector[ is_greater_than_10 ]"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#r-basics-5",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#r-basics-5",
    "title": "Lecture 9",
    "section": "R Basics",
    "text": "R Basics\nTidy data.frame: Variables, Observations, and Values\n\n\n\n\nThere are three rules which make a data.frame tidy:\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n\n\n\n‚Äì&gt;  ‚Äì&gt;  ‚Äì&gt;  ‚Äì&gt;"
  },
  {
    "objectID": "danl-cw/danl-101-cw-01.html#question-6.",
    "href": "danl-cw/danl-101-cw-01.html#question-6.",
    "title": "R Basics I",
    "section": "Question 6.",
    "text": "Question 6.\nWrite an R code to provide descriptive statistics‚Äîmean, standard deviation, minimum, first quartile, median, third quartile, and maximum‚Äîfor variables in the MLB_teams data.frame.\nAnswer:\n\nlibrary(skimr)\nskim(MLB_teams)\n\n\nData summary\n\n\nName\nMLB_teams\n\n\nNumber of rows\n300\n\n\nNumber of columns\n56\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n13\n\n\nnumeric\n43\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nlgID\n0\n1\n2\n2\n0\n2\n0\n\n\nteamID\n0\n1\n3\n3\n0\n31\n0\n\n\nfranchID\n0\n1\n3\n3\n0\n30\n0\n\n\ndivID\n0\n1\n1\n1\n0\n3\n0\n\n\nDivWin\n0\n1\n1\n1\n0\n2\n0\n\n\nWCWin\n0\n1\n1\n1\n0\n2\n0\n\n\nLgWin\n0\n1\n1\n1\n0\n2\n0\n\n\nWSWin\n0\n1\n1\n1\n0\n2\n0\n\n\nname\n0\n1\n12\n29\n0\n31\n0\n\n\npark\n0\n1\n8\n31\n0\n37\n0\n\n\nteamIDBR\n0\n1\n3\n3\n0\n31\n0\n\n\nteamIDlahman45\n0\n1\n3\n3\n0\n30\n0\n\n\nteamIDretro\n0\n1\n3\n3\n0\n31\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyearID\n0\n1\n2013.50\n2.88\n2009.00\n2011.00\n2013.50\n2016.00\n2018.00\n‚ñá‚ñá‚ñá‚ñá‚ñá\n\n\nRank\n0\n1\n3.01\n1.44\n1.00\n2.00\n3.00\n4.00\n6.00\n‚ñá‚ñÉ‚ñÖ‚ñÉ‚ñÅ\n\n\nG\n0\n1\n161.99\n0.26\n161.00\n162.00\n162.00\n162.00\n163.00\n‚ñÅ‚ñÅ‚ñá‚ñÅ‚ñÅ\n\n\nGhome\n0\n1\n80.99\n0.53\n78.00\n81.00\n81.00\n81.00\n84.00\n‚ñÅ‚ñÅ‚ñá‚ñÅ‚ñÅ\n\n\nW\n0\n1\n80.99\n11.40\n47.00\n73.00\n81.00\n90.00\n108.00\n‚ñÅ‚ñÖ‚ñá‚ñá‚ñÇ\n\n\nL\n0\n1\n80.99\n11.37\n54.00\n72.00\n81.00\n89.00\n115.00\n‚ñÇ‚ñá‚ñá‚ñÖ‚ñÅ\n\n\nR\n0\n1\n707.24\n73.22\n513.00\n650.75\n707.00\n755.00\n915.00\n‚ñÅ‚ñÜ‚ñá‚ñÖ‚ñÅ\n\n\nAB\n0\n1\n5519.63\n70.84\n5294.00\n5465.00\n5519.50\n5565.00\n5735.00\n‚ñÅ‚ñÖ‚ñá‚ñÖ‚ñÅ\n\n\nH\n0\n1\n1405.71\n73.91\n1199.00\n1353.50\n1403.00\n1452.00\n1625.00\n‚ñÅ‚ñÜ‚ñá‚ñÉ‚ñÅ\n\n\nX2B\n0\n1\n278.00\n25.55\n219.00\n260.00\n276.50\n294.00\n363.00\n‚ñÇ‚ñá‚ñá‚ñÇ‚ñÅ\n\n\nX3B\n0\n1\n29.05\n9.12\n5.00\n22.00\n29.00\n35.00\n57.00\n‚ñÅ‚ñÜ‚ñá‚ñÉ‚ñÅ\n\n\nHR\n0\n1\n167.32\n35.86\n91.00\n141.75\n164.00\n191.25\n267.00\n‚ñÉ‚ñá‚ñá‚ñÖ‚ñÅ\n\n\nBB\n0\n1\n504.87\n64.18\n375.00\n457.00\n503.00\n547.00\n672.00\n‚ñÉ‚ñá‚ñá‚ñÖ‚ñÇ\n\n\nSO\n0\n1\n1235.67\n135.21\n905.00\n1142.75\n1232.00\n1324.25\n1594.00\n‚ñÇ‚ñÖ‚ñá‚ñÖ‚ñÅ\n\n\nSB\n0\n1\n93.12\n29.71\n19.00\n71.00\n91.00\n112.25\n194.00\n‚ñÇ‚ñá‚ñá‚ñÇ‚ñÅ\n\n\nCS\n0\n1\n35.53\n9.59\n13.00\n29.00\n34.00\n42.00\n74.00\n‚ñÇ‚ñá‚ñÖ‚ñÇ‚ñÅ\n\n\nHBP\n0\n1\n54.38\n13.74\n26.00\n44.00\n53.00\n63.00\n101.00\n‚ñÉ‚ñá‚ñÖ‚ñÇ‚ñÅ\n\n\nSF\n0\n1\n41.70\n7.94\n24.00\n36.00\n41.00\n47.00\n64.00\n‚ñÉ‚ñá‚ñá‚ñÉ‚ñÅ\n\n\nRA\n0\n1\n707.24\n79.76\n525.00\n646.75\n704.50\n760.00\n894.00\n‚ñÇ‚ñÜ‚ñá‚ñÖ‚ñÇ\n\n\nER\n0\n1\n652.10\n74.82\n478.00\n598.00\n649.50\n700.50\n846.00\n‚ñÇ‚ñá‚ñá‚ñÖ‚ñÇ\n\n\nERA\n0\n1\n4.06\n0.49\n2.94\n3.71\n4.04\n4.37\n5.36\n‚ñÇ‚ñÜ‚ñá‚ñÉ‚ñÇ\n\n\nCG\n0\n1\n3.83\n2.91\n0.00\n2.00\n3.00\n6.00\n18.00\n‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n\n\nSHO\n0\n1\n10.36\n4.07\n2.00\n7.00\n10.00\n13.00\n23.00\n‚ñÉ‚ñá‚ñá‚ñÇ‚ñÅ\n\n\nSV\n0\n1\n41.44\n7.09\n24.00\n37.00\n41.00\n46.00\n62.00\n‚ñÇ‚ñá‚ñá‚ñÉ‚ñÅ\n\n\nIPouts\n0\n1\n4341.87\n40.37\n4235.00\n4314.75\n4340.00\n4369.00\n4485.00\n‚ñÇ‚ñá‚ñá‚ñÇ‚ñÅ\n\n\nHA\n0\n1\n1405.71\n84.18\n1125.00\n1350.50\n1405.00\n1462.25\n1637.00\n‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñÅ\n\n\nHRA\n0\n1\n167.32\n28.32\n96.00\n147.00\n167.00\n184.00\n258.00\n‚ñÇ‚ñÜ‚ñá‚ñÇ‚ñÅ\n\n\nBBA\n0\n1\n504.87\n55.82\n352.00\n466.00\n504.00\n540.00\n653.00\n‚ñÅ‚ñÖ‚ñá‚ñÖ‚ñÇ\n\n\nSOA\n0\n1\n1235.67\n132.99\n911.00\n1153.00\n1231.00\n1312.50\n1687.00\n‚ñÇ‚ñá‚ñá‚ñÇ‚ñÅ\n\n\nE\n0\n1\n96.28\n15.14\n54.00\n86.00\n97.00\n106.25\n143.00\n‚ñÅ‚ñÜ‚ñá‚ñÉ‚ñÅ\n\n\nDP\n0\n1\n144.00\n17.18\n95.00\n133.00\n144.00\n155.00\n190.00\n‚ñÅ‚ñÖ‚ñá‚ñÖ‚ñÅ\n\n\nFP\n0\n1\n0.98\n0.00\n0.98\n0.98\n0.98\n0.99\n0.99\n‚ñÅ‚ñÉ‚ñá‚ñÖ‚ñÅ\n\n\nattendance\n0\n1\n2439186.37\n647151.08\n811104.00\n1924926.50\n2373285.50\n2988512.50\n3857500.00\n‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÉ\n\n\nBPF\n0\n1\n100.09\n5.58\n88.00\n96.00\n99.50\n103.00\n120.00\n‚ñÉ‚ñá‚ñá‚ñÅ‚ñÅ\n\n\nPPF\n0\n1\n100.09\n5.45\n88.00\n97.00\n100.00\n103.00\n121.00\n‚ñÇ‚ñá‚ñÖ‚ñÅ‚ñÅ\n\n\nTB\n0\n1\n2243.78\n154.63\n1810.00\n2136.75\n2235.00\n2346.25\n2703.00\n‚ñÅ‚ñÖ‚ñá‚ñÖ‚ñÅ\n\n\nWinPct\n0\n1\n0.50\n0.07\n0.29\n0.45\n0.50\n0.56\n0.67\n‚ñÅ‚ñÖ‚ñá‚ñá‚ñÇ\n\n\nrpg\n0\n1\n4.37\n0.45\n3.17\n4.02\n4.37\n4.66\n5.65\n‚ñÅ‚ñÜ‚ñá‚ñÖ‚ñÅ\n\n\nhrpg\n0\n1\n1.03\n0.22\n0.56\n0.88\n1.01\n1.18\n1.65\n‚ñÉ‚ñá‚ñá‚ñÖ‚ñÅ\n\n\ntbpg\n0\n1\n13.85\n0.95\n11.17\n13.19\n13.81\n14.47\n16.69\n‚ñÅ‚ñÖ‚ñá‚ñÖ‚ñÅ\n\n\nkpg\n0\n1\n7.63\n0.83\n5.59\n7.06\n7.61\n8.18\n9.84\n‚ñÇ‚ñÖ‚ñá‚ñÖ‚ñÅ\n\n\nk2bb\n0\n1\n2.48\n0.40\n1.53\n2.20\n2.49\n2.74\n3.75\n‚ñÇ‚ñá‚ñá‚ñÉ‚ñÅ\n\n\nwhip\n0\n1\n1.32\n0.07\n1.16\n1.27\n1.31\n1.37\n1.56\n‚ñÇ‚ñá‚ñÜ‚ñÇ‚ñÅ\n\n\n\n\n\n\nskimr::skim() is a function from the skimr package in R, which provides an enhanced and comprehensive summary of data compared to the traditional summary() function.\n\nIt generates descriptive statistics for a vector or for each column (variable) in a data.frame, offering an easy-to-read output with more details than basic summaries."
  },
  {
    "objectID": "danl-cw/danl-101-cw-02.html",
    "href": "danl-cw/danl-101-cw-02.html",
    "title": "R Basics II",
    "section": "",
    "text": "Write an R code to create a numeric vector named numbers containing the integers from 10 to 50.\n\nAnswer:\n\nnumbers &lt;- 10:50\nnumbers\n\n [1] 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34\n[26] 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n\n\n\nThe colon operator : in R is used to generate a sequence of integers. In this case, 10:50 generates the integers from 10 to 50 and assigns them to the variable name numbers."
  },
  {
    "objectID": "danl-cw/danl-101-cw-02.html#question-1.",
    "href": "danl-cw/danl-101-cw-02.html#question-1.",
    "title": "R Basics II",
    "section": "",
    "text": "Write an R code to create a numeric vector named numbers containing the integers from 10 to 50.\n\nAnswer:\n\nnumbers &lt;- 10:50\nnumbers\n\n [1] 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34\n[26] 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n\n\n\nThe colon operator : in R is used to generate a sequence of integers. In this case, 10:50 generates the integers from 10 to 50 and assigns them to the variable name numbers."
  },
  {
    "objectID": "danl-cw/danl-101-cw-02.html#question-2.",
    "href": "danl-cw/danl-101-cw-02.html#question-2.",
    "title": "R Basics II",
    "section": "Question 2.",
    "text": "Question 2.\n\nCreate a logical vector logical_vec that checks whether the elements of the vector ages &lt;- c(15, 22, 18, 24, 30) are greater than or equal to 20.\n\n\nages &lt;- c(15, 22, 18, 24, 30)\n\nAnswer:\n\nlogical_vec &lt;- ages &gt;= 20\nlogical_vec\n\n[1] FALSE  TRUE FALSE  TRUE  TRUE\n\n\n\nThe comparison operator &gt;= checks each element of the ages vector to see if it‚Äôs greater than or equal to 20. The result is a logical vector of TRUE or FALSE values for each corresponding element."
  },
  {
    "objectID": "danl-cw/danl-101-cw-02.html#question-3.",
    "href": "danl-cw/danl-101-cw-02.html#question-3.",
    "title": "R Basics II",
    "section": "Question 3.",
    "text": "Question 3.\n\nWrite an R code to assign the string ‚ÄúHello, World!‚Äù to a variable named greeting and display its value on the Console.\n\nAnswer:\n\ngreeting &lt;- \"Hello, World!\"\ngreeting\n\n[1] \"Hello, World!\"\n\n\n\nThe character value ‚ÄúHello, World!‚Äù is assigned to the variable greeting, and the value is displayed by simply typing the variable name, which prints its content to the Console."
  },
  {
    "objectID": "danl-cw/danl-101-cw-02.html#question-4.",
    "href": "danl-cw/danl-101-cw-02.html#question-4.",
    "title": "R Basics II",
    "section": "Question 4.",
    "text": "Question 4.\n\nWrite an R code to calculate the range (difference between the maximum and minimum values) of the vector temp &lt;- c(22, 28, 31, 25, 29).\n\n\ntemp &lt;- c(22, 28, 31, 25, 29)\n\nAnswer:\n\nrange_value &lt;- max(temp) - min(temp)\nrange_value\n\n[1] 9\n\n\n\nThe range is calculated by subtracting the minimum value of the vector from the maximum value. The max() function gives the maximum value, and the min() function gives the minimum value."
  },
  {
    "objectID": "danl-cw/danl-101-cw-02.html#question-5.",
    "href": "danl-cw/danl-101-cw-02.html#question-5.",
    "title": "R Basics II",
    "section": "Question 5.",
    "text": "Question 5.\n\nWrite an R code to convert the character vector char_vec &lt;- c(\"1\", \"2\", \"3\", \"4\") into a numeric vector named num_vec.\n\n\nchar_vec &lt;- c(\"1\", \"2\", \"3\", \"4\")\n\nAnswer:\n\nnum_vec &lt;- as.numeric(char_vec)\nnum_vec\n\n[1] 1 2 3 4\n\n\n\nThe as.numeric() function is used to convert the elements of char_vec, which are characters, into numeric values. The resulting numeric vector is stored in num_vec."
  },
  {
    "objectID": "danl-cw/danl-101-cw-02.html#question-6.",
    "href": "danl-cw/danl-101-cw-02.html#question-6.",
    "title": "R Basics II",
    "section": "Question 6.",
    "text": "Question 6.\n\nWrite an R code to concatenate two character vectors, first_names &lt;- c(\"John\", \"Jane\") and last_names &lt;- c(\"Doe\", \"Smith\"), to create a vector full_names containing the full names using the str_c() function for vectorized string operations.\n\n\nfirst_names &lt;- c(\"John\", \"Jane\")\nlast_names &lt;- c(\"Doe\", \"Smith\")\n\nAnswer:\n\nlibrary(stringr)\nfull_names &lt;- str_c(first_names, last_names, sep = \" \")\nfull_names\n\n[1] \"John Doe\"   \"Jane Smith\"\n\n\n\nThe str_c() function from the one of the packages in tidyverse is used to concatenate two vectors (first_names and last_names) element-wise. The sep = \" \" argument ensures that a space is inserted between the first and last names."
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#fuels-rapid-growth-with-data-science",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#fuels-rapid-growth-with-data-science",
    "title": "Lecture 10",
    "section": "Fuels Rapid Growth with Data Science",
    "text": "Fuels Rapid Growth with Data Science\nAirBnB\n\n\n\n\n\n\nAirbnb started as a small business in San Francisco and grew into a major player in the sharing economy, valued at $38 billion in early 2019.\nFounded by Brian Chesky and Joe Gebbia, Airbnb began as a way for them to pay their rent by offering temporary lodging.\nAs of spring 2019, Airbnb had over 6 million properties listed in more than 80,000 cities worldwide, surpassing the combined listings of the top five hotel brands.\nAirbnb attributes much of its growth to data science, which it uses to gather insights and make informed business decisions."
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#big-data",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#big-data",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n\nBig data and analytics are likely to be significant components of future careers across various fields.\nBig data refers to enormous and complex data collections that traditional data management tools can‚Äôt handle effectively.\nFive key characteristics of big data (5 V‚Äôs):\n\nVolume\nVelocity\nValue\nVeracity\nVariety"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#big-data-1",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#big-data-1",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n1. Volume\n\nIn 2017, the digital universe contained an estimated 16.1 zettabytes of data.\nExpected to grow to 163 zettabytes by 2025.\nMuch new data will come from embedded systems in smart devices."
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#big-data-2",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#big-data-2",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n1. Volume\n\n\n\n\n\nName\nSymbol\nValue\n\n\n\n\nKilobyte\nkB\n10¬≥\n\n\nMegabyte\nMB\n10‚Å∂\n\n\nGigabyte\nGB\n10‚Åπ\n\n\nTerabyte\nTB\n10¬π¬≤\n\n\nPetabyte\nPB\n10¬π‚Åµ\n\n\nExabyte\nEB\n10¬π‚Å∏\n\n\nZettabyte\nZB\n10¬≤¬π\n\n\nYottabyte\nYB\n10¬≤‚Å¥\n\n\nBrontobyte*\nBB\n10¬≤‚Å∑\n\n\nGegobyte*\nGeB\n10¬≥‚Å∞\n\n\n\nNote: The asterisks (*) next to Brontobyte and Gegobyte in the original image have been preserved in this table. These likely indicate that these units are less commonly used or are proposed extensions to the standard system of byte units.\n\n\n\n\n\n\nIncrease in size of the global datasphere"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#big-data-3",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#big-data-3",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n2. Velocity\n\nRefers to the rate at which new data is generated.\nEstimated at 2.5 quintillion bytes each day.\n90% of the world‚Äôs data was generated in just the past two years."
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#big-data-4",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#big-data-4",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n3. Value\n\nRefers to the worth of data in decision-making.\nEmphasizes the need to quickly identify and process relevant data."
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#big-data-5",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#big-data-5",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n4. Veracity\n\nMeasures the quality of the data.\nConsiders accuracy, completeness, and currency of data.\nDetermines if the data can be trusted for good decision-making."
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#big-data-6",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#big-data-6",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n5. Variety\n\n\n\n\n\n\nData comes in various formats.\nStructured data: Has a predefined format, fits into traditional databases.\nUnstructured data: Not organized in a predefined manner, comes from sources like documents, social media, emails, photos, videos, etc."
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#sources-of-an-organizations-data",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#sources-of-an-organizations-data",
    "title": "Lecture 10",
    "section": "Sources of an Organization‚Äôs Data",
    "text": "Sources of an Organization‚Äôs Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#a-simple-taxonomy-of-data",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#a-simple-taxonomy-of-data",
    "title": "Lecture 10",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nCategorical Data\n\nCategorical Data:\n\nRepresents labels of multiple classes\nExamples: race, sex, age group, educational level\nAlso called discrete data\nFinite number of values with no continuum\nNumbers used are symbols, not for calculations"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#a-simple-taxonomy-of-data-1",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#a-simple-taxonomy-of-data-1",
    "title": "Lecture 10",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nCategorical Data\n\nTypes of Categorical Data:\n\nNominal Data:\n\nSimple codes assigned as labels\nNo inherent order\nCan be binomial (two values) or multinomial (three or more values)\nExamples: marital status, yes/no questions\n\nOrdinal Data:\n\nCodes represent rank order\nExamples: credit score (low, medium, high), age groups, educational levels"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#a-simple-taxonomy-of-data-2",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#a-simple-taxonomy-of-data-2",
    "title": "Lecture 10",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nNumeric Data\n\nNumeric Data:\n\nRepresents specific numeric values\nCan be integer or real (fractional) numbers\nAlso called continuous data\nExamples: age, income, distance, temperature"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#a-simple-taxonomy-of-data-3",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#a-simple-taxonomy-of-data-3",
    "title": "Lecture 10",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nNumeric Data\n\nTypes of Numeric Data:\n\nInterval Data:\n\nMeasured on interval scales\nNo absolute zero\nExample: Celsius temperature scale\n\nRatio Data:\n\nCommon in physical sciences and engineering\nHas a nonarbitrary zero value\nExamples: mass, length, time, Kelvin temperature scale"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#a-simple-taxonomy-of-data-4",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#a-simple-taxonomy-of-data-4",
    "title": "Lecture 10",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nCategorical vs.¬†Numeric\n\nKey Distinctions:\n\nCategorical (discrete) vs.¬†Numeric (continuous)\nPresence or absence of inherent order\nAbility to perform mathematical operations\nPresence of an absolute zero point"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#big-data-uses",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#big-data-uses",
    "title": "Lecture 10",
    "section": "Big Data Uses",
    "text": "Big Data Uses"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#fuels-rapid-growth-with-data-science-1",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#fuels-rapid-growth-with-data-science-1",
    "title": "Lecture 10",
    "section": "Fuels Rapid Growth with Data Science",
    "text": "Fuels Rapid Growth with Data Science\nAirBnB\n\n\n\n\n\n\nRiley Newman, one of Airbnb‚Äôs first employees, was a data scientist who helped shift the company‚Äôs focus from cold numeric data to understanding individual experiences and community trends.\nAirbnb uses data science to improve its search system, streamline the booking process, evaluate user experiences, and inform decisions on hiring practices, product offerings, and site design.\nThe company developed the Dataportal, an integrated system that allows employees to easily access and analyze data for decision-making."
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2024-0916.html#fuels-rapid-growth-with-data-science-2",
    "href": "danl-lec/danl-101-lec-09-2024-0916.html#fuels-rapid-growth-with-data-science-2",
    "title": "Lecture 10",
    "section": "Fuels Rapid Growth with Data Science",
    "text": "Fuels Rapid Growth with Data Science\nAirBnB\n\n\n\n\n\n\nAirbnb‚Äôs success in leveraging data is based on three key components:\n\nA solid data management program\nCreative data scientists\nA strong commitment to data-driven decision-making"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#fuels-rapid-growth-with-data-science",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#fuels-rapid-growth-with-data-science",
    "title": "Lecture 10",
    "section": "Fuels Rapid Growth with Data Science",
    "text": "Fuels Rapid Growth with Data Science\nAirBnB\n\n\n\n\n\n\nAirbnb started as a small business in San Francisco and grew into a major player in the sharing economy, valued at $77.23 billion in September 2024.\nFounded by Brian Chesky and Joe Gebbia, Airbnb began as a way for them to pay their rent by offering temporary lodging.\nAs of spring 2019, Airbnb had over 6 million properties listed in more than 80,000 cities worldwide, surpassing the combined listings of the top five hotel brands.\nAirbnb attributes much of its growth to data science, which it uses to gather insights and make informed business decisions."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#fuels-rapid-growth-with-data-science-1",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#fuels-rapid-growth-with-data-science-1",
    "title": "Lecture 10",
    "section": "Fuels Rapid Growth with Data Science",
    "text": "Fuels Rapid Growth with Data Science\nAirBnB\n\n\n\n\n\n\nRiley Newman, one of Airbnb‚Äôs first employees, was a data scientist who helped shift the company‚Äôs focus from cold numeric data to understanding individual experiences and community trends.\nAirbnb uses data science to improve its search system, streamline the booking process, evaluate user experiences, and inform decisions on hiring practices, product offerings, and site design.\nThe company developed the Dataportal, an integrated system that allows employees to easily access and analyze data for decision-making."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#fuels-rapid-growth-with-data-science-2",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#fuels-rapid-growth-with-data-science-2",
    "title": "Lecture 10",
    "section": "Fuels Rapid Growth with Data Science",
    "text": "Fuels Rapid Growth with Data Science\nAirBnB\n\n\n\n\n\n\nAirbnb‚Äôs success in leveraging data is based on three key components:\n\nA solid data management program\nCreative data scientists\nA strong commitment to data-driven decision-making"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#big-data",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#big-data",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n\nBig data and analytics are likely to be significant components of future careers across various fields.\nBig data refers to enormous and complex data collections that traditional data management tools can‚Äôt handle effectively.\nFive key characteristics of big data (5 V‚Äôs):\n\nVolume\nVelocity\nValue\nVeracity\nVariety"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#big-data-1",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#big-data-1",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n1. Volume\n\nIn 2017, the digital universe contained an estimated 16.1 zettabytes of data.\nExpected to grow to 163 zettabytes by 2025.\nMuch new data will come from embedded systems in smart devices."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#big-data-2",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#big-data-2",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n1. Volume\n\n\n\n\n\nName\nSymbol\nValue\n\n\n\n\nKilobyte\nkB\n10¬≥\n\n\nMegabyte\nMB\n10‚Å∂\n\n\nGigabyte\nGB\n10‚Åπ\n\n\nTerabyte\nTB\n10¬π¬≤\n\n\nPetabyte\nPB\n10¬π‚Åµ\n\n\nExabyte\nEB\n10¬π‚Å∏\n\n\nZettabyte\nZB\n10¬≤¬π\n\n\nYottabyte\nYB\n10¬≤‚Å¥\n\n\nBrontobyte*\nBB\n10¬≤‚Å∑\n\n\nGegobyte*\nGeB\n10¬≥‚Å∞\n\n\n\nNote: The asterisks (*) next to Brontobyte and Gegobyte in the original image have been preserved in this table. These likely indicate that these units are less commonly used or are proposed extensions to the standard system of byte units.\n\n\n\n\n\n\nIncrease in size of the global datasphere"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#big-data-3",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#big-data-3",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n2. Velocity\n\nRefers to the rate at which new data is generated.\nEstimated at 2.5 quintillion bytes each day.\n90% of the world‚Äôs data was generated in just the past two years."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#big-data-4",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#big-data-4",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n3. Value\n\nRefers to the worth of data in decision-making.\nEmphasizes the need to quickly identify and process relevant data."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#big-data-5",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#big-data-5",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n4. Veracity\n\nMeasures the quality of the data.\nConsiders accuracy, completeness, and currency of data.\nDetermines if the data can be trusted for good decision-making."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#big-data-6",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#big-data-6",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n5. Variety\n\n\n\n\n\n\nData comes in various formats.\nStructured data: Has a predefined format, fits into traditional databases.\nUnstructured data: Not organized in a predefined manner, comes from sources like documents, social media, emails, photos, videos, etc."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#a-simple-taxonomy-of-data",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#a-simple-taxonomy-of-data",
    "title": "Lecture 10",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nCategorical Data\n\nRepresents labels of multiple classes\nExamples: race, sex, age group, educational level\nAlso called discrete data\nFinite number of values with no continuum\nNumbers used are symbols, not for calculations"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#a-simple-taxonomy-of-data-1",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#a-simple-taxonomy-of-data-1",
    "title": "Lecture 10",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nCategorical Data\n\nTypes of Categorical Data:\n\nNominal Data:\n\nSimple codes assigned as labels\nNo inherent order\nCan be binomial (two values) or multinomial (three or more values)\nExamples: marital status, yes/no questions\n\nOrdinal Data:\n\nCodes represent rank order\nExamples: credit score (low, medium, high), age groups, educational levels"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#a-simple-taxonomy-of-data-2",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#a-simple-taxonomy-of-data-2",
    "title": "Lecture 10",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nNumeric Data\n\nRepresents specific numeric values\nCan be integer or real (fractional) numbers\nAlso called continuous data\nExamples: age, income, distance, temperature"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#a-simple-taxonomy-of-data-3",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#a-simple-taxonomy-of-data-3",
    "title": "Lecture 10",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nNumeric Data\n\nTypes of Numeric Data:\n\nInterval Data:\n\nMeasured on interval scales\nNo absolute zero\nExample: Celsius temperature scale\n\nRatio Data:\n\nCommon in physical sciences and engineering\nHas a nonarbitrary zero value\nExamples: mass, length, time, Kelvin temperature scale"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#a-simple-taxonomy-of-data-4",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#a-simple-taxonomy-of-data-4",
    "title": "Lecture 10",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nCategorical vs.¬†Numeric\n\nKey Distinctions:\n\nCategorical (discrete) vs.¬†Numeric (continuous)\nPresence or absence of inherent order\nAbility to perform mathematical operations\nPresence of an absolute zero point"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#sources-of-an-organizations-data",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#sources-of-an-organizations-data",
    "title": "Lecture 10",
    "section": "Sources of an Organization‚Äôs Data",
    "text": "Sources of an Organization‚Äôs Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#data-management-fuels-rapid-growth",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#data-management-fuels-rapid-growth",
    "title": "Lecture 10",
    "section": "Data Management Fuels Rapid Growth",
    "text": "Data Management Fuels Rapid Growth\nAirBnB\n\n\n\n\n\n\nAirbnb attributes much of its growth from a small San Francisco startup to a $77.23 billion company (as of September 2024) to its effective use of data science and management.\nThe company shifted from using basic ‚Äúcold numeric data‚Äù to leveraging complex data analysis for understanding individual user experiences and community trends."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#data-management-fuels-rapid-growth-1",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#data-management-fuels-rapid-growth-1",
    "title": "Lecture 10",
    "section": "Data Management Fuels Rapid Growth",
    "text": "Data Management Fuels Rapid Growth\nAirBnB\n\n\n\n\n\n\nAirbnb developed the Dataportal, an integrated system that centralizes data resources, making it easier for employees to:\n\nAccess and analyze data quickly\nInform decision-making across various business aspects\nMaintain data consistency and accuracy"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#data-management-fuels-rapid-growth-2",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#data-management-fuels-rapid-growth-2",
    "title": "Lecture 10",
    "section": "Data Management Fuels Rapid Growth",
    "text": "Data Management Fuels Rapid Growth\nAirBnB\n\n\n\n\n\n\nThe Dataportal solved internal data management challenges by:\n\nIntegrating multiple data tools (tables, dashboards, reports)\nReducing duplication of data resources\nProviding context and connections between different data sets"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#data-management-fuels-rapid-growth-3",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#data-management-fuels-rapid-growth-3",
    "title": "Lecture 10",
    "section": "Data Management Fuels Rapid Growth",
    "text": "Data Management Fuels Rapid Growth\nAirBnB\n\n\n\n\n\n\nAirbnb‚Äôs data management strategy supports:\n\nImprovement of its search and booking systems\nEvaluation of user experiences\nInformed decision-making in hiring, product development, and site design"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0918.html#data-management-fuels-rapid-growth-4",
    "href": "danl-lec/danl-101-lec-10-2024-0918.html#data-management-fuels-rapid-growth-4",
    "title": "Lecture 10",
    "section": "Data Management Fuels Rapid Growth",
    "text": "Data Management Fuels Rapid Growth\nAirBnB\n\n\n\n\n\n\nThe company‚Äôs success in data leverage is built on three pillars:\n\nA robust data management program (Dataportal)\nA team of creative data scientists\nA company-wide commitment to data-driven decision-making"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#data-management-fuels-rapid-growth",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#data-management-fuels-rapid-growth",
    "title": "Lecture 10",
    "section": "Data Management Fuels Rapid Growth",
    "text": "Data Management Fuels Rapid Growth\nAirBnB\n\n\n\n\n\n\nAirbnb attributes much of its growth from a small San Francisco startup to a $77.23 billion company (as of September 2024) to its effective use of data science and management.\nThe company shifted from using basic ‚Äúcold numeric data‚Äù to leveraging complex data analysis for understanding individual user experiences and community trends."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#data-management-fuels-rapid-growth-1",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#data-management-fuels-rapid-growth-1",
    "title": "Lecture 10",
    "section": "Data Management Fuels Rapid Growth",
    "text": "Data Management Fuels Rapid Growth\nAirBnB\n\n\n\n\n\n\nAirbnb developed the Dataportal, an integrated system that centralizes data resources, making it easier for employees to:\n\nAccess and analyze data quickly\nInform decision-making across various business aspects\nMaintain data consistency and accuracy"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#data-management-fuels-rapid-growth-2",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#data-management-fuels-rapid-growth-2",
    "title": "Lecture 10",
    "section": "Data Management Fuels Rapid Growth",
    "text": "Data Management Fuels Rapid Growth\nAirBnB\n\n\n\n\n\n\nThe Dataportal solved internal data management challenges by:\n\nIntegrating multiple data tools (tables, dashboards, reports)\nReducing duplication of data resources\nProviding context and connections between different data sets"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#data-management-fuels-rapid-growth-3",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#data-management-fuels-rapid-growth-3",
    "title": "Lecture 10",
    "section": "Data Management Fuels Rapid Growth",
    "text": "Data Management Fuels Rapid Growth\nAirBnB\n\n\n\n\n\n\nAirbnb‚Äôs data management strategy supports:\n\nImprovement of its search and booking systems\nEvaluation of user experiences\nInformed decision-making in hiring, product development, and site design"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#data-management-fuels-rapid-growth-4",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#data-management-fuels-rapid-growth-4",
    "title": "Lecture 10",
    "section": "Data Management Fuels Rapid Growth",
    "text": "Data Management Fuels Rapid Growth\nAirBnB\n\n\n\n\n\n\nThe company‚Äôs success in data leverage is built on three pillars:\n\nA robust data management program (Dataportal)\nA team of creative data scientists\nA company-wide commitment to data-driven decision-making"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#big-data",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#big-data",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n\nBig data and analytics are likely to be significant components of future careers across various fields.\nBig data refers to enormous and complex data collections that traditional data management tools can‚Äôt handle effectively.\nFive key characteristics of big data (5 V‚Äôs):\n\nVolume\nVelocity\nValue\nVeracity\nVariety"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#big-data-1",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#big-data-1",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n1. Volume\n\nIn 2017, the digital universe contained an estimated 16.1 zettabytes of data.\nExpected to grow to 163 zettabytes by 2025.\nMuch new data will come from embedded systems in smart devices."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#big-data-2",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#big-data-2",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n1. Volume\n\n\n\n\n\nName\nSymbol\nValue\n\n\n\n\nKilobyte\nkB\n10¬≥\n\n\nMegabyte\nMB\n10‚Å∂\n\n\nGigabyte\nGB\n10‚Åπ\n\n\nTerabyte\nTB\n10¬π¬≤\n\n\nPetabyte\nPB\n10¬π‚Åµ\n\n\nExabyte\nEB\n10¬π‚Å∏\n\n\nZettabyte\nZB\n10¬≤¬π\n\n\nYottabyte\nYB\n10¬≤‚Å¥\n\n\nBrontobyte*\nBB\n10¬≤‚Å∑\n\n\nGegobyte*\nGeB\n10¬≥‚Å∞\n\n\n\nNote: The asterisks (*) next to Brontobyte and Gegobyte in the original image have been preserved in this table. These likely indicate that these units are less commonly used or are proposed extensions to the standard system of byte units.\n\n\n\n\n\n\nIncrease in size of the global datasphere"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#big-data-3",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#big-data-3",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n2. Velocity\n\nRefers to the rate at which new data is generated.\nEstimated at 0.33 zetabytes each day (120 zetabytes annually).\n90% of the world‚Äôs data was generated in just the past two years."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#big-data-4",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#big-data-4",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n3. Value\n\nRefers to the worth of data in decision-making.\nEmphasizes the need to quickly identify and process relevant data.\nUsers may be able to find more patterns and interesting anomalies from ‚Äúbig‚Äù data than from ‚Äúsmall‚Äù data."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#big-data-5",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#big-data-5",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n4. Veracity\n\nMeasures the quality of the data.\nConsiders accuracy, completeness, and currency of data.\nDetermines if the data can be trusted for good decision-making."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#big-data-6",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#big-data-6",
    "title": "Lecture 10",
    "section": "Big Data",
    "text": "Big Data\n5. Variety\n\n\n\n\n\n\nData comes in various formats.\nStructured data: Has a predefined format, fits into traditional databases.\nUnstructured data: Not organized in a predefined manner, comes from sources like documents, social media, emails, photos, videos, etc."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#a-simple-taxonomy-of-data",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#a-simple-taxonomy-of-data",
    "title": "Lecture 10",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nData Types Overview\n\n\n\n\nCategorical Data: Data that can be divided into distinct categories based on some qualitative attribute.\n\nNominal Data\nOrdinal Data\n\n\n\n\nNumeric Data: Data that represents measurable quantities and can be subjected to mathematical algebra.\n\nInterval Data\nRatio Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#a-simple-taxonomy-of-data-1",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#a-simple-taxonomy-of-data-1",
    "title": "Lecture 10",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nCategorical Data - Nominal\n\n\n\nID\nAnimal\n\n\n\n\n1\nDog\n\n\n2\nCat\n\n\n3\nBird\n\n\n\n\nNominal Data: Categorical data where the categories have no intrinsic order or ranking.\nNo Order: Categories are simply different; there is no logical sequence.\nExamples:\n\nColors: Red, Blue, Green\nTypes of Animals: Dog, Cat, Bird"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#a-simple-taxonomy-of-data-2",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#a-simple-taxonomy-of-data-2",
    "title": "Lecture 10",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nCategorical Data - Ordinal\n\n\n\nID\nEducation Level\n\n\n\n\n1\nBachelor‚Äôs\n\n\n2\nMaster‚Äôs\n\n\n3\nPhD\n\n\n\n\nOrdinal Data: Categorical data where the categories have a meaningful order or ranking.\nOrder Matters: Categories can be ranked or ordered, but the differences between categories are not necessarily uniform.\nExamples:\n\nEducation Levels: High School, Bachelor‚Äôs, Master‚Äôs, PhD\nCustomer Satisfaction: Poor, Fair, Good, Excellent"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#a-simple-taxonomy-of-data-3",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#a-simple-taxonomy-of-data-3",
    "title": "Lecture 10",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nNumeric Data - Interval\n\n\n\nID\nTemperature (¬∞F)\n\n\n\n\n1\n70\n\n\n2\n80\n\n\n3\n90\n\n\n\n\nInterval Data: Numeric data where the differences between values are meaningful, but there is no true zero point.\nMeaningful Intervals: The difference between values is consistent.\nNo True Zero: Zero does not indicate the absence of the quantity.\nExamples:\n\nTemperature (¬∞F): Zero degrees does not mean no temperature.\nTime of Day in a 12-Hour Clock: Differences are meaningful, but there is no absolute zero."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#a-simple-taxonomy-of-data-4",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#a-simple-taxonomy-of-data-4",
    "title": "Lecture 10",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nNumeric Data - Ratio\n\n\n\nID\nHeight (cm)\nWeight (kg)\n\n\n\n\n1\n160\n55\n\n\n2\n175\n70\n\n\n3\n170\n65\n\n\n\n\nRatio Data: Numeric data with a true zero point, allowing for a full range of mathematical operations.\nMeaningful Ratios: Comparisons like twice as much or half as much are valid.\nTrue Zero: Zero indicates the absence of the quantity.\nExamples:\n\nHeight in Centimeters: Zero means no height.\nWeight in Kilograms: Zero means no weight."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#sources-of-an-organizations-data",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#sources-of-an-organizations-data",
    "title": "Lecture 10",
    "section": "Sources of an Organization‚Äôs Data",
    "text": "Sources of an Organization‚Äôs Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#introduction-to-data.frame",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#introduction-to-data.frame",
    "title": "Lecture 10",
    "section": "Introduction to data.frame",
    "text": "Introduction to data.frame\n\n\n\n\n\n\nDefinition: A data.frame is a table-like data structure in R used for storing data in a tabular format with rows and columns.\nStructure: Consists of:\n\nVariables (Columns)\nObservations (Rows)\nValues (Cells): Individual data points within each cell of the data.frame."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#introduction-to-data.frame-1",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#introduction-to-data.frame-1",
    "title": "Lecture 10",
    "section": "Introduction to data.frame",
    "text": "Introduction to data.frame\nVariables\n\nDefinition: Columns in a data.frame, representing a specific attribute or characteristic measured across different units of observation.\nExamples:\n\nStudent Data: Name, Age, Grade, Major\nEmployee Data: EmployeeID, Name, Age, Department"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2024-0920.html#introduction-to-data.frame-2",
    "href": "danl-lec/danl-101-lec-10-2024-0920.html#introduction-to-data.frame-2",
    "title": "Lecture 10",
    "section": "Introduction to data.frame",
    "text": "Introduction to data.frame\nObservations\n\nDefinition: Rows in a data.frame, each representing a single entity or unit for which data is collected and recorded.\nExamples:\n\nStudent Information: Each row represents an individual student.\nEmployee Information: Each row represents an individual employee.\nDaily S&P 500 Index Data: Each row represents a specific day.\nHousehold Survey Data: Each row represents a household."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#a-simple-taxonomy-of-data",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#a-simple-taxonomy-of-data",
    "title": "Lecture 11",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nData Types Overview\n\n\n\n\nCategorical Data: Data that can be divided into distinct categories based on some qualitative attribute.\n\nNominal Data\nOrdinal Data\n\n\n\n\nNumeric Data: Data that represents measurable quantities and can be subjected to mathematical algebra.\n\nInterval Data\nRatio Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#a-simple-taxonomy-of-data-1",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#a-simple-taxonomy-of-data-1",
    "title": "Lecture 11",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nCategorical Data - Nominal\n\n\n\n\nID\nAnimal\n\n\n\n\n1\nDog\n\n\n2\nCat\n\n\n3\nBird\n\n\n\n\nNominal Data: Categorical data where the categories have no intrinsic order or ranking.\nNo Order: Categories are simply different; there is no logical sequence.\nExamples:\n\nColors: Red, Blue, Green\nTypes of Animals: Dog, Cat, Bird"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#a-simple-taxonomy-of-data-2",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#a-simple-taxonomy-of-data-2",
    "title": "Lecture 11",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nCategorical Data - Ordinal\n\n\n\n\nID\nEducation Level\n\n\n\n\n1\nBachelor‚Äôs\n\n\n2\nMaster‚Äôs\n\n\n3\nPhD\n\n\n\n\nOrdinal Data: Categorical data where the categories have a meaningful order or ranking.\nOrder Matters: Categories can be ranked or ordered, but the differences between categories are not necessarily uniform.\nExamples:\n\nEducation Levels: High School, Bachelor‚Äôs, Master‚Äôs, PhD\nCustomer Satisfaction: Poor, Fair, Good, Excellent"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#a-simple-taxonomy-of-data-3",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#a-simple-taxonomy-of-data-3",
    "title": "Lecture 11",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nNumeric Data - Interval\n\n\n\n\nID\nTemperature (¬∞F)\n\n\n\n\n1\n70\n\n\n2\n80\n\n\n3\n90\n\n\n\n\nInterval Data: Numeric data where the differences between values are meaningful, but there is no true zero point.\nMeaningful Intervals: The difference between values is consistent.\nNo True Zero: Zero does not indicate the absence of the quantity.\nExamples:\n\nTemperature (¬∞F): Zero degrees does not mean no temperature.\nTime of Day in a 12-Hour Clock: Differences are meaningful, but there is no absolute zero."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#a-simple-taxonomy-of-data-4",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#a-simple-taxonomy-of-data-4",
    "title": "Lecture 11",
    "section": "A Simple Taxonomy of Data",
    "text": "A Simple Taxonomy of Data\nNumeric Data - Ratio\n\n\n\n\nID\nHeight (cm)\nWeight (kg)\n\n\n\n\n1\n160\n55\n\n\n2\n175\n70\n\n\n3\n170\n65\n\n\n\n\nRatio Data: Numeric data with a true zero point, allowing for a full range of mathematical operations.\nMeaningful Ratios: Comparisons like twice as much or half as much are valid.\nTrue Zero: Zero indicates the absence of the quantity.\nExamples:\n\nHeight in Centimeters: Zero means no height.\nWeight in Kilograms: Zero means no weight."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#sources-of-an-organizations-data",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#sources-of-an-organizations-data",
    "title": "Lecture 11",
    "section": "Sources of an Organization‚Äôs Data",
    "text": "Sources of an Organization‚Äôs Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#portals-that-provide-access-to-free-sources-of-useful-big-data",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#portals-that-provide-access-to-free-sources-of-useful-big-data",
    "title": "Lecture 11",
    "section": "Portals that provide access to free sources of useful (big) data",
    "text": "Portals that provide access to free sources of useful (big) data\n\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nAmazon Web Services (AWS) public data sets\nPortal to a huge repository of public data, including climate data, the million song dataset, and data from the 1000 Genomes project.\nAWS Datasets\n\n\nBureau of Labor Statistics (BLS)\nProvides access to data on inflation and prices, wages and benefits, employment, spending and time use, productivity, and workplace injuries\nBLS\n\n\nCIA World Factbook\nPortal to information on the economy, government, history, infrastructure, military, and population of 267 countries\nCIA World Factbook\n\n\nData.gov\nPortal providing access to over 186,000 government data sets, related to topics such as agriculture, education, health, and public safety\nData.gov\n\n\nData for Good from Facebook\nProvides access to anonymized data from Facebook to help non-profits and research communities with insights on crises, health, and well-being\nFacebook Data for Good\n\n\nFBI Uniform Crime Reports\nPortal to data on Crime in the United States, Law Enforcement Officers Killed and Assaulted, and Hate Crime Statistics\nFBI UCR\n\n\nJustia Federal District Court Opinions and Orders database\nA free searchable database of full-text opinions and orders from civil cases heard in U.S. Federal District Courts\nJustia\n\n\nGapminder\nPortal to data from the World Health Organization and World Bank on economic, medical, and social issues\nGapminder\n\n\nGoogle Finance\nPortal to 40 years of stock market data\nGoogle Finance\n\n\nHealthdata.gov\nPortal to 125 years of U.S. health care data, including national health care expenditures, claim-level Medicare data, and other topics\nHealthdata.gov\n\n\nNational Centers for Environmental Information (NOAA)\nPortal for accessing a variety of climate and weather data sets\nNCEI\n\n\nPew Research Center Internet & Technology\nPortal to research on U.S. politics, media and news, social trends, religion, Internet and technology, science, Hispanic, and global topics\nPew Internet\n\n\nU.S. Census Bureau\nPortal to a huge variety of government statistics and data relating to the U.S. economy and its population\nU.S. Census Bureau\n\n\nWorld Bank Open Data\nFree and open access to global development data, including world development indicators\nWorld Bank Open Data\n\n\nGoogle Dataset Search\nHelps find datasets stored across the web\nGoogle Dataset Search\n\n\nKaggle Datasets\nA community-driven platform with datasets from various fields, useful for machine learning and data science projects\nKaggle Datasets\n\n\nEuropean Union Open Data Portal\nProvides access to public data from EU institutions\nEU Open Data Portal\n\n\nUCI Machine Learning Repository\nA collection of databases, domain theories, and datasets used for machine learning research\nUCI ML Repository\n\n\nInternational Monetary Fund (IMF)\nProvides access to a range of economic data and reports on countries‚Äô economies\nIMF Data\n\n\nNOAA National Weather Service\nProvides weather, water, and climate data, forecasts and warnings\nNOAA NWS\n\n\nWorld Health Organization (WHO)\nPortal to data and statistics on global health issues\nWHO Data\n\n\nOECD Data\nProvides access to economic, environmental, and social data and indicators from OECD member countries\nOECD Data\n\n\nUnited Nations Data\nProvides access to global statistical data compiled by the United Nations\nUN Data\n\n\nHumanitarian Data Exchange (HDX)\nProvides humanitarian data from the United Nations, NGOs, and other organizations\nHDX\n\n\nNew York City Open Data\nProvides access to datasets from New York City, covering a wide range of topics such as public safety, transportation, and health\nNYC Open Data\n\n\nLos Angeles Open Data\nPortal for accessing public data from the City of Los Angeles, including transportation, public safety, and city services\nLA Open Data\n\n\nChicago Data Portal\nOffers access to datasets from the City of Chicago, including crime data, transportation, and health statistics\nChicago Data Portal\n\n\nData for Good from Canada\nProvides open access to datasets that address pressing social challenges across Canada\nData for Good Canada\n\n\nDemocratizing Data from data.org\nA platform providing access to high-impact datasets, tools, and resources aimed at solving critical global challenges\nDemocratizing Data\n\n\nSports Reference\nProvides comprehensive data on a wide variety of sports, including statistics, historical data, and player information\nSports Reference"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data",
    "title": "Lecture 11",
    "section": "Free Sources of Useful (Big) Data",
    "text": "Free Sources of Useful (Big) Data\nEconomics/Finance\n\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nBureau of Labor Statistics (BLS)\nProvides access to data on inflation and prices, wages and benefits, employment, spending and time use, productivity, and workplace injuries\nBLS\n\n\nFRED (Federal Reserve Economic Data)\nProvides access to a vast collection of U.S. economic data, including interest rates, GDP, inflation, employment, and more\nFRED\n\n\nYahoo Finance\nProvides comprehensive financial news, data, and analysis, including stock quotes, market data, and financial reports\nYahoo Finance\n\n\nIMF (International Monetary Fund)\nProvides access to a range of economic data and reports on countries‚Äô economies\nIMF Data\n\n\nWorld Bank Open Data\nFree and open access to global development data, including world development indicators\nWorld Bank Open Data\n\n\nOECD Data\nProvides access to economic, environmental, and social data and indicators from OECD member countries\nOECD Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data-1",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data-1",
    "title": "Lecture 11",
    "section": "Free Sources of Useful (Big) Data",
    "text": "Free Sources of Useful (Big) Data\nGovernment/Public Data\n\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nData.gov\nPortal providing access to over 186,000 government data sets, related to topics such as agriculture, education, health, and public safety\nData.gov\n\n\nCIA World Factbook\nPortal to information on the economy, government, history, infrastructure, military, and population of 267 countries\nCIA World Factbook\n\n\nU.S. Census Bureau\nPortal to a huge variety of government statistics and data relating to the U.S. economy and its population\nU.S. Census Bureau\n\n\nEuropean Union Open Data Portal\nProvides access to public data from EU institutions\nEU Open Data Portal\n\n\nNew York City Open Data\nProvides access to datasets from New York City, covering a wide range of topics such as public safety, transportation, and health\nNYC Open Data\n\n\nLos Angeles Open Data\nPortal for accessing public data from the City of Los Angeles, including transportation, public safety, and city services\nLA Open Data\n\n\nChicago Data Portal\nOffers access to datasets from the City of Chicago, including crime data, transportation, and health statistics\nChicago Data Portal"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data-2",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data-2",
    "title": "Lecture 11",
    "section": "Free Sources of Useful (Big) Data",
    "text": "Free Sources of Useful (Big) Data\nHealth, Climate/Environment, and Social Data\n\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nHealthdata.gov\nPortal to 125 years of U.S. health care data, including national health care expenditures, claim-level Medicare data, and other topics\nHealthdata.gov\n\n\nWorld Health Organization (WHO)\nPortal to data and statistics on global health issues\nWHO Data\n\n\nNational Centers for Environmental Information (NOAA)\nPortal for accessing a variety of climate and weather data sets\nNCEI\n\n\nNOAA National Weather Service\nProvides weather, water, and climate data, forecasts and warnings\nNOAA NWS\n\n\nFAO (Food and Agriculture Organization)\nProvides access to data on food and agriculture, including data on production, trade, food security, and sustainability\nFAOSTAT\n\n\nPew Research Center Internet & Technology\nPortal to research on U.S. politics, media and news, social trends, religion, Internet and technology, science, Hispanic, and global topics\nPew Research\n\n\nData for Good from Facebook\nProvides access to anonymized data from Facebook to help non-profits and research communities with insights on crises, health, and well-being\nFacebook Data for Good\n\n\nData for Good from Canada\nProvides open access to datasets that address pressing social challenges across Canada\nData for Good Canada"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data-3",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data-3",
    "title": "Lecture 11",
    "section": "Free Sources of Useful (Big) Data",
    "text": "Free Sources of Useful (Big) Data\nGeneral Data Repositories\n\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nAmazon Web Services (AWS) public data sets\nPortal to a huge repository of public data, including climate data, the million song dataset, and data from the 1000 Genomes project\nAWS Datasets\n\n\nGapminder\nPortal to data from the World Health Organization and World Bank on economic, medical, and social issues\nGapminder\n\n\nGoogle Dataset Search\nHelps find datasets stored across the web\nGoogle Dataset Search\n\n\nKaggle Datasets\nA community-driven platform with datasets from various fields, useful for machine learning and data science projects\nKaggle Datasets\n\n\nUCI Machine Learning Repository\nA collection of databases, domain theories, and datasets used for machine learning research\nUCI ML Repository\n\n\nUnited Nations Data\nProvides access to global statistical data compiled by the United Nations\nUN Data\n\n\nHumanitarian Data Exchange (HDX)\nProvides humanitarian data from the United Nations, NGOs, and other organizations\nHDX\n\n\nDemocratizing Data from data.org\nA platform providing access to high-impact datasets, tools, and resources aimed at solving critical global challenges\nDemocratizing Data\n\n\nJustia Federal District Court Opinions and Orders database\nA free searchable database of full-text opinions and orders from civil cases heard in U.S. Federal District Courts\nJustia"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data-4",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data-4",
    "title": "Lecture 11",
    "section": "Free Sources of Useful (Big) Data",
    "text": "Free Sources of Useful (Big) Data\n\nSocial Data\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nPew Research Center Internet & Technology\nPortal to research on U.S. politics, media and news, social trends, religion, Internet and technology, science, Hispanic, and global topics\nPew Internet\n\n\nData for Good from Facebook\nProvides access to anonymized data from Facebook to help non-profits and research communities with insights on crises, health, and well-being\nFacebook Data for Good\n\n\nData for Good from Canada\nProvides open access to datasets that address pressing social challenges across Canada\nData for Good Canada\n\n\n\nGeneral Data Repositories\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nAmazon Web Services (AWS) public data sets\nPortal to a huge repository of public data, including climate data, the million song dataset, and data from the 1000 Genomes project\nAWS Datasets\n\n\nGapminder\nPortal to data from the World Health Organization and World Bank on economic, medical, and social issues\nGapminder\n\n\nGoogle Dataset Search\nHelps find datasets stored across the web\nGoogle Dataset Search\n\n\nKaggle Datasets\nA community-driven platform with datasets from various fields, useful for machine learning and data science projects\nKaggle Datasets\n\n\nUCI Machine Learning Repository\nA collection of databases, domain theories, and datasets used for machine learning research\nUCI ML Repository\n\n\nUnited Nations Data\nProvides access to global statistical data compiled by the United Nations\nUN Data\n\n\nHumanitarian Data Exchange (HDX)\nProvides humanitarian data from the United Nations, NGOs, and other organizations\nHDX\n\n\nDemocratizing Data from data.org\nA platform providing access to high-impact datasets, tools, and resources aimed at solving critical global challenges\nDemocratizing Data\n\n\nJustia Federal District Court Opinions and Orders database\nA free searchable database of full-text opinions and orders from civil cases heard in U.S. Federal District Courts\nJustia"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data---economicsfinance",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data---economicsfinance",
    "title": "Lecture 11",
    "section": "Free Sources of Useful (Big) Data - Economics/Finance",
    "text": "Free Sources of Useful (Big) Data - Economics/Finance\n\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nBureau of Labor Statistics (BLS)\nProvides access to data on inflation and prices, wages and benefits, employment, spending and time use, productivity, and workplace injuries\nBLS\n\n\nFRED (Federal Reserve Economic Data)\nProvides access to a vast collection of U.S. economic data, including interest rates, GDP, inflation, employment, and more\nFRED\n\n\nGoogle Finance\nPortal to 40 years of stock market data\nGoogle Finance\n\n\nIMF (International Monetary Fund)\nProvides access to a range of economic data and reports on countries‚Äô economies\nIMF Data\n\n\nWorld Bank Open Data\nFree and open access to global development data, including world development indicators\nWorld Bank Open Data\n\n\nOECD Data\nProvides access to economic, environmental, and social data and indicators from OECD member countries\nOECD Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data---governmentpublic-data",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data---governmentpublic-data",
    "title": "Lecture 11",
    "section": "Free Sources of Useful (Big) Data - Government/Public Data",
    "text": "Free Sources of Useful (Big) Data - Government/Public Data\n\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nData.gov\nPortal providing access to over 186,000 government data sets, related to topics such as agriculture, education, health, and public safety\nData.gov\n\n\nCIA World Factbook\nPortal to information on the economy, government, history, infrastructure, military, and population of 267 countries\nCIA World Factbook\n\n\nU.S. Census Bureau\nPortal to a huge variety of government statistics and data relating to the U.S. economy and its population\nU.S. Census Bureau\n\n\nEuropean Union Open Data Portal\nProvides access to public data from EU institutions\nEU Open Data Portal\n\n\nNew York City Open Data\nProvides access to datasets from New York City, covering a wide range of topics such as public safety, transportation, and health\nNYC Open Data\n\n\nLos Angeles Open Data\nPortal for accessing public data from the City of Los Angeles, including transportation, public safety, and city services\nLA Open Data\n\n\nChicago Data Portal\nOffers access to datasets from the City of Chicago, including crime data, transportation, and health statistics\nChicago Data Portal"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data---health-and-climateenvironment",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data---health-and-climateenvironment",
    "title": "Lecture 11",
    "section": "Free Sources of Useful (Big) Data - Health and Climate/Environment",
    "text": "Free Sources of Useful (Big) Data - Health and Climate/Environment\n\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nHealthdata.gov\nPortal to 125 years of U.S. health care data, including national health care expenditures, claim-level Medicare data, and other topics\nHealthdata.gov\n\n\nWorld Health Organization (WHO)\nPortal to data and statistics on global health issues\nWHO Data\n\n\n\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nNational Centers for Environmental Information (NOAA)\nPortal for accessing a variety of climate and weather data sets\nNCEI\n\n\nNOAA National Weather Service\nProvides weather, water, and climate data, forecasts and warnings\nNOAA NWS"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data---social-data-and-general-data-repositories",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data---social-data-and-general-data-repositories",
    "title": "Lecture 11",
    "section": "Free Sources of Useful (Big) Data - Social Data and General Data Repositories",
    "text": "Free Sources of Useful (Big) Data - Social Data and General Data Repositories\n\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nPew Research Center Internet & Technology\nPortal to research on U.S. politics, media and news, social trends, religion, Internet and technology, science, Hispanic, and global topics\nPew Internet\n\n\nData for Good from Facebook\nProvides access to anonymized data from Facebook to help non-profits and research communities with insights on crises, health, and well-being\nFacebook Data for Good\n\n\nData for Good from Canada\nProvides open access to datasets that address pressing social challenges across Canada\nData for Good Canada\n\n\n\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nAmazon Web Services (AWS) public data sets\nPortal to a huge repository of public data, including climate data, the million song dataset, and data from the 1000 Genomes project\nAWS Datasets\n\n\nGapminder\nPortal to data from the World Health Organization and World Bank on economic, medical, and social issues\nGapminder\n\n\nGoogle Dataset Search\nHelps find datasets stored across the web\nGoogle Dataset Search\n\n\nKaggle Datasets\nA community-driven platform with datasets from various fields, useful for machine learning and data science projects\nKaggle Datasets\n\n\nUCI Machine Learning Repository\nA collection of databases, domain theories, and datasets used for machine learning research\nUCI ML Repository\n\n\nUnited Nations Data\nProvides access to global statistical data compiled by the United Nations\nUN Data\n\n\nHumanitarian Data Exchange (HDX)\nProvides humanitarian data from the United Nations, NGOs, and other organizations\nHDX\n\n\nDemocratizing Data from data.org\nA platform providing access to high-impact datasets, tools, and resources aimed at solving critical global challenges\nDemocratizing Data\n\n\nJustia Federal District Court Opinions and Orders database\nA free searchable database of full-text opinions and orders from civil cases heard in U.S. Federal District Courts\nJustia"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data--",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#free-sources-of-useful-big-data--",
    "title": "Lecture 11",
    "section": "Free Sources of Useful (Big) Data -",
    "text": "Free Sources of Useful (Big) Data -\nHealth and Climate/Environment\n\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nHealthdata.gov\nPortal to 125 years of U.S. health care data, including national health care expenditures, claim-level Medicare data, and other topics\nHealthdata.gov\n\n\nWorld Health Organization (WHO)\nPortal to data and statistics on global health issues\nWHO Data\n\n\n\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nNational Centers for Environmental Information (NOAA)\nPortal for accessing a variety of climate and weather data sets\nNCEI\n\n\nNOAA National Weather Service\nProvides weather, water, and climate data, forecasts and warnings\nNOAA NWS"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#challenges-of-big-data",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#challenges-of-big-data",
    "title": "Lecture 11",
    "section": "Challenges of Big Data",
    "text": "Challenges of Big Data\nKey Challenges in Big Data Management\n\nData Selection\n\nRelevance: Determining which subsets of data are pertinent to specific decision-making processes.\nQuality vs.¬†Quantity: Balancing the need for comprehensive data with the practicality of managing large volumes.\n\nStorage Solutions\n\nInfrastructure Needs: Evaluating whether to use on-premises servers, cloud storage, or hybrid models.\nScalability: Ensuring storage solutions can grow with the increasing data demands.\n\nRelevance and Decision-Making\n\nData Filtering: Implementing methods to extract meaningful information from noise.\nReal-Time Analytics: Developing systems capable of processing data quickly to support timely decisions.\n\nData Protection\n\nSecurity Protocols: Implementing encryption, access controls, and monitoring to prevent breaches.\nCompliance Requirements: Adhering to laws and regulations regarding data privacy and protection."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#challenges-of-big-data-1",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#challenges-of-big-data-1",
    "title": "Lecture 11",
    "section": "Challenges of Big Data",
    "text": "Challenges of Big Data\nInformation Overload\n\nDifficulty in Finding Information\n\nSearch Challenges: With so much data, traditional search methods become inefficient.\nIndexing Issues: Properly cataloging data to make retrieval efficient is complex.\n\nTrust Issues\n\nData Validity: Users may question the accuracy and timeliness of available data.\nSource Credibility: Differentiating between reliable and unreliable data sources."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#challenges-of-big-data-2",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#challenges-of-big-data-2",
    "title": "Lecture 11",
    "section": "Challenges of Big Data",
    "text": "Challenges of Big Data\nInformation Overload\n\nData from Diverse Sources\n\nIntegration Complexity: Combining data from internal and external sources can be technically challenging.\nData Formats: Managing different data types, such as structured, unstructured, and semi-structured data."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#challenges-of-big-data-3",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#challenges-of-big-data-3",
    "title": "Lecture 11",
    "section": "Challenges of Big Data",
    "text": "Challenges of Big Data\nCompliance and Regulations\n\nRisk of Non-Compliance\n\nLegal Penalties: Organizations may face fines, sanctions, or legal action.\nReputation Damage: Public trust can be eroded by non-compliance incidents.\n\nImpact on Organizations\n\nOperational Costs: Investing in compliance measures can be resource-intensive.\nProcess Adjustments: Policies and procedures may need significant changes to meet regulatory standards."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#challenges-of-big-data-4",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#challenges-of-big-data-4",
    "title": "Lecture 11",
    "section": "Challenges of Big Data",
    "text": "Challenges of Big Data\nCompliance and Regulations\n\nNeed for Vigilance\n\nEvolving Laws: Regulations frequently update, requiring continuous monitoring.\nEmployee Training: Staff must be educated on compliance requirements and best practices."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#challenges-of-big-data-5",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#challenges-of-big-data-5",
    "title": "Lecture 11",
    "section": "Challenges of Big Data",
    "text": "Challenges of Big Data\nPrivacy Concerns\n\nData Harvesting\n\nCollection Methods: Corporations gather personal data through various means, often without explicit user consent.\nScope of Data: Information ranges from basic demographics to detailed behavioral patterns.\n\nExtensive Profiling\n\nUser Tracking: Monitoring online activities to build comprehensive profiles.\nThird-Party Sharing: Data sold or shared with other organizations, amplifying privacy risks."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#technologies-used-to-manage-and-process-big-data",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#technologies-used-to-manage-and-process-big-data",
    "title": "Lecture 11",
    "section": "Technologies Used to Manage and Process Big Data",
    "text": "Technologies Used to Manage and Process Big Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#technologies-used-to-manage-and-process-big-data-1",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#technologies-used-to-manage-and-process-big-data-1",
    "title": "Lecture 11",
    "section": "Technologies Used to Manage and Process Big Data",
    "text": "Technologies Used to Manage and Process Big Data\n\nDefinition of Big Data\n\nData sets so large and complex that traditional data management tools are inadequate.\n\nThe Need for Advanced Technologies\n\nEmerging technologies are essential to manage, process, and analyze big data effectively.\n\nOverview of Topics\n\nData Warehouses\nExtract, Transform, Load (ETL) Process\nData Marts\nData Lakes\nHadoop"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#technologies-used-to-manage-and-process-big-data-2",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#technologies-used-to-manage-and-process-big-data-2",
    "title": "Lecture 11",
    "section": "Technologies Used to Manage and Process Big Data",
    "text": "Technologies Used to Manage and Process Big Data\nChallenges with Traditional Data Management\n\nLimitations\n\nTraditional software and hardware can‚Äôt handle the volume, velocity, and variety of big data.\n\nImpact\n\nInability to store massive data volumes efficiently.\nDifficulty in processing and analyzing data in a timely manner.\n\nSolution\n\nAdoption of new technologies specifically designed for big data management."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#data-warehouses-data-marts-and-data-lakes",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#data-warehouses-data-marts-and-data-lakes",
    "title": "Lecture 11",
    "section": "Data Warehouses, Data Marts, and Data Lakes",
    "text": "Data Warehouses, Data Marts, and Data Lakes\nData Warehouses\n\n\n\n\n\n\nDefinition\n\nA large database that holds business information from many sources across the enterprise.\n\nPurpose\n\nSupports decision-making processes by providing a comprehensive view of the organization‚Äôs data."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#data-warehouses-data-marts-and-data-lakes-1",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#data-warehouses-data-marts-and-data-lakes-1",
    "title": "Lecture 11",
    "section": "Data Warehouses, Data Marts, and Data Lakes",
    "text": "Data Warehouses, Data Marts, and Data Lakes\nData Warehouses Characteristics\n\n\n\n\n\n\n\nCharacteristic\nDescription\n\n\n\n\nLarge\nHolds billions of records and petabytes of data\n\n\nMultiple Sources\nData comes from many internal and external sources via the ETL process\n\n\nHistorical\nTypically contains data spanning 5 years or more\n\n\nCross-Organizational Access and Analysis\nData accessed and analyzed by users across the organization to support multiple business processes and decision-making\n\n\nSupports Various Analyses and Reporting\nEnables drill-down analysis, metric development, trend identification"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#data-warehouses-data-marts-and-data-lakes-2",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#data-warehouses-data-marts-and-data-lakes-2",
    "title": "Lecture 11",
    "section": "Data Warehouses, Data Marts, and Data Lakes",
    "text": "Data Warehouses, Data Marts, and Data Lakes\nData Warehouse Architecture\n\nData Sources\n\nInternal Systems: Online transaction processing systems, customer relationship management, enterprise resource planning.\nExternal Systems: Social media, government databases, etc.\n\nETL Process\n\nExtract, Transform, Load (to be discussed in detail).\n\nData Storage\n\nCentralized repository optimized for query and analysis.\n\nData Access\n\nUsed by various departments for reporting, analysis, and decision-making."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#data-warehouses-data-marts-and-data-lakes-3",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#data-warehouses-data-marts-and-data-lakes-3",
    "title": "Lecture 11",
    "section": "Data Warehouses, Data Marts, and Data Lakes",
    "text": "Data Warehouses, Data Marts, and Data Lakes\nExamples of Data Warehouse Usage\n\n\n\n\n\n\n\n\n\nWalmart\n\nEarly adopter; used data warehouse to gain a competitive advantage in supply chain management.\nHeld transaction data from over 11,000 stores and 25,000 suppliers.\nFirst commercial data warehouse to reach 1 terabyte in 1992.\nCollects data over 2.5 petabytes per hour in 2024."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#data-warehouses-data-marts-and-data-lakes-4",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#data-warehouses-data-marts-and-data-lakes-4",
    "title": "Lecture 11",
    "section": "Data Warehouses, Data Marts, and Data Lakes",
    "text": "Data Warehouses, Data Marts, and Data Lakes\nExamples of Data Warehouse Usage\n\n\n\n\n\n\n\n\n\nWHOOP Wearable Device\n\nCollects massive biometric data from athletes.\nData warehouse stores sensor data collected 100 times per second.\nProvides insights on strain, recovery, and sleep to optimize performance."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#extract-transform-load-etl-process",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#extract-transform-load-etl-process",
    "title": "Lecture 11",
    "section": "Extract, Transform, Load (ETL) Process",
    "text": "Extract, Transform, Load (ETL) Process\nOverview of ETL Process\n\nPurpose\n\nIntegral process for populating data warehouses with clean, consistent data.\n\nStages\n\nExtract\n\nCollecting data from multiple sources.\n\nTransform\n\nCleaning and converting data into a suitable format.\n\nLoad\n\nInserting transformed data into the data warehouse."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#extract-transform-load-etl-process-1",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#extract-transform-load-etl-process-1",
    "title": "Lecture 11",
    "section": "Extract, Transform, Load (ETL) Process",
    "text": "Extract, Transform, Load (ETL) Process\nExtract Stage\n\nData Sources\n\nVarious internal and external systems.\n\nProcess\n\nData Extraction: Pulling data from different systems.\nData Validation: Rejecting data that doesn‚Äôt meet quality standards (e.g., missing values, invalid formats).\n\nChallenges\n\nDealing with heterogeneous data formats and structures."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#extract-transform-load-etl-process-2",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#extract-transform-load-etl-process-2",
    "title": "Lecture 11",
    "section": "Extract, Transform, Load (ETL) Process",
    "text": "Extract, Transform, Load (ETL) Process\nTransform Stage\n\nPurpose\n\nConvert extracted data into a standardized format suitable for analysis.\n\nProcesses\n\nData Cleaning: Correcting errors and inconsistencies.\nData Integration: Combining data from different sources.\nData Aggregation: Summarizing data to reduce processing time.\nExample Transformation:\n\nConverting customer address information into a sales district or census tract."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#extract-transform-load-etl-process-3",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#extract-transform-load-etl-process-3",
    "title": "Lecture 11",
    "section": "Extract, Transform, Load (ETL) Process",
    "text": "Extract, Transform, Load (ETL) Process\nLoad Stage\n\nProcess\n\nData Loading: Inserting transformed data into the data warehouse.\nIndexing: Creating indices to improve query performance.\nConstraint Checking: Ensuring data integrity according to database schema.\n\nChallenges\n\nThe loading process for large data warehouses can take days.\n\nOutcome\n\nThe data warehouse is updated with high-quality, consistent data ready for analysis."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#data-marts",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#data-marts",
    "title": "Lecture 11",
    "section": "Data Marts",
    "text": "Data Marts\nDefinition of Data Marts\n\nSubset of Data Warehouse\n\nFocused on a specific business area or department.\n\nPurpose\n\nProvides relevant data to a specific group without the complexity of the entire data warehouse.\n\nAdvantages\n\nCost-Effective: Less expensive to implement and maintain.\nFaster Access: Optimized for departmental needs.\nSimplified Analysis: Easier to query and analyze due to reduced data volume."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#data-marts-1",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#data-marts-1",
    "title": "Lecture 11",
    "section": "Data Marts",
    "text": "Data Marts\nData Mart Use Cases\n\nDepartmental Focus\n\nFinance: Financial reporting and analysis.\nMarketing: Customer segmentation and campaign analysis.\nInventory: Stock levels and supply chain management.\n\nSmall to Medium-Sized Businesses\n\nAn affordable alternative to a full-scale data warehouse."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#data-marts-2",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#data-marts-2",
    "title": "Lecture 11",
    "section": "Data Marts",
    "text": "Data Marts\nData Marts vs.¬†Data Warehouses\n\n\n\n\n\n\n\n\nFeature\nData Mart\nData Warehouse\n\n\n\n\nScope\nSpecific department or business area\nEntire enterprise\n\n\nData Volume\nSmaller\nLarger\n\n\nComplexity\nLess complex\nMore complex\n\n\nImplementation Time\nShorter\nLonger\n\n\nCost\nLower\nHigher"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#data-lakes",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#data-lakes",
    "title": "Lecture 11",
    "section": "Data Lakes",
    "text": "Data Lakes\nDefinition of Data Lakes\n\n‚ÄúStore Everything‚Äù Approach\n\nStores all data in its raw, unaltered form.\n\nPurpose\n\nProvides a centralized repository for all data, accommodating future analytical needs.\n\nCharacteristics\n\nData Variety: Includes structured, semi-structured, and unstructured data.\nFlexibility: Data is available for any type of analysis at any time."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#data-lakes-1",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#data-lakes-1",
    "title": "Lecture 11",
    "section": "Data Lakes",
    "text": "Data Lakes\nData Lakes vs.¬†Data Warehouses\n\n\n\n\n\n\n\n\nFeature\nData Lake\nData Warehouse\n\n\n\n\nData Processing\nSchema-on-read (processed when accessed)\nSchema-on-write (processed before storage)\n\n\nData State\nRaw, unprocessed\nCleaned, transformed\n\n\nData Types\nAll data types\nPrimarily structured\n\n\nFlexibility\nHigh\nModerate"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#data-lakes-2",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#data-lakes-2",
    "title": "Lecture 11",
    "section": "Data Lakes",
    "text": "Data Lakes\nCase Study: Bechtel Corporation\n\n\n\n\n\n\nAbout Bechtel\n\nGlobal engineering, construction, and project management company.\n\nImplementation\n\nBuilt a 5-petabyte data lake consolidating years of project data."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#data-lakes-3",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#data-lakes-3",
    "title": "Lecture 11",
    "section": "Data Lakes",
    "text": "Data Lakes\nCase Study: Bechtel Corporation\n\nBenefits\n\nHistorical Insights: Access to data from hundreds of projects worldwide.\nImproved Forecasting: Better predictions of project outcomes.\nCost Reduction: Identifying inefficiencies to cut costs.\nCompetitive Advantage: Enhanced ability to win new contracts through data-driven insights."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#data-lakes-4",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#data-lakes-4",
    "title": "Lecture 11",
    "section": "Data Lakes",
    "text": "Data Lakes\nCase Study: Bechtel Corporation\n\n\n\n\n\n\nAbout Bechtel\n\nGlobal engineering, construction, and project management company.\n\nImplementation\n\nBuilt a 5-petabyte data lake consolidating years of project data."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#data-lakes-5",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#data-lakes-5",
    "title": "Lecture 11",
    "section": "Data Lakes",
    "text": "Data Lakes\nCase Study: Bechtel Corporation\n\nBenefits\n\nHistorical Insights: Access to data from hundreds of projects worldwide.\nImproved Forecasting: Better predictions of project outcomes.\nCost Reduction: Identifying inefficiencies to cut costs.\nCompetitive Advantage: Enhanced ability to win new contracts through data-driven insights."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop",
    "title": "Lecture 11",
    "section": "Hadoop",
    "text": "Hadoop\nIntroduction to Hadoop\n\n\n\n\n\n\nDefinition\n\nAn open-source software framework for storing and processing large data sets.\n\nComponents\n\nHadoop Distributed File System (HDFS): Distributed data storage.\nMapReduce: Data processing model."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-1",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-1",
    "title": "Lecture 11",
    "section": "Hadoop",
    "text": "Hadoop\nIntroduction to Hadoop\n\n\n\n\n\n\nPurpose\n\nEnables distributed processing of large data sets across clusters of computers."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-2",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-2",
    "title": "Lecture 11",
    "section": "Hadoop",
    "text": "Hadoop\nHadoop Architecture - HDFS\n\n\n\n\n\n\n\n\n\nHDFS\n\nDivides data into blocks and distributes them across different servers for processing.\nProvides a highly redundant computing environment\n\nAllows the application to keep running even if individual servers fail."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-3",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-3",
    "title": "Lecture 11",
    "section": "Hadoop",
    "text": "Hadoop\nHadoop Architecture - MapReduce\n\nMapReduce\n\nMap Phase: Filters and sorts data.\n\ne.g., Sorting customer orders based on their product IDs, with each group corresponding to a specific product ID.\n\nReduce Phase: Summarizes and aggregates results.\n\ne.g., Counting the number of orders within each group, thereby determining the frequency of each product ID."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-4",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-4",
    "title": "Lecture 11",
    "section": "Hadoop",
    "text": "Hadoop\nHow Hadoop Works\n\nData Distribution\n\nLarge data sets are split into smaller blocks.\n\nData Storage\n\nBlocks are stored across multiple servers in the cluster.\n\nProcessing with MapReduce\n\nMap Tasks: Executed on servers where data resides, minimizing data movement.\nReduce Tasks: Combine results from map tasks to produce final output.\n\nFault Tolerance\n\nData replication ensures processing continues even if servers fail."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-5",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-5",
    "title": "Lecture 11",
    "section": "Hadoop",
    "text": "Hadoop\nExtending Hadoop for Real-Time Processing\n\nLimitation of Hadoop\n\nHadoop was originally designed for batch processing.\n\nBatch Processing: Data or tasks are collected over a period of time and then processed all at once, typically at scheduled times or during periods of low activity.\n\n\nReal-Time Processing Limitation:\n\nHadoop cannot natively process real-time streaming data (e.g., stock prices flowing into stock exchanges, live sensor data)\n\nExtending Hadoop‚Äôs Capabilities\n\nBoth Apache Storm and Apache Spark can run on top of Hadoop clusters, utilizing HDFS for storage."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-6",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-6",
    "title": "Lecture 11",
    "section": "Hadoop",
    "text": "Hadoop\nApache Storm and Apache Spark\n\n\nApache Storm\n\nFunctionality:\n\nProcesses real-time data streams.\nHandles unbounded streams of data reliably and efficiently.\n\nUse Cases:\n\nReal-time analytics\nOnline machine learning\nContinuous computation\nReal-time data integration\n\n\n\nApache Spark\n\nFunctionality:\n\nProvides in-memory computations for increased speed.\nSupports both batch and streaming data processing through Spark Streaming.\n\nUse Cases:\n\nInteractive queries\nMachine learning"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-7",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-7",
    "title": "Lecture 11",
    "section": "Hadoop",
    "text": "Hadoop\nApache Storm and Spark\n\nApache Storm\n\nFunctionality: Processes real-time data streams.\nUse Cases: Real-time analytics, online machine learning, continuous computation.\n\nApache Spark\n\nFunctionality: Provides in-memory computations for speed.\nUse Cases: Batch processing, interactive queries, machine learning."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#technologies-used-to-manage-and-process-big-data-3",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#technologies-used-to-manage-and-process-big-data-3",
    "title": "Lecture 11",
    "section": "Technologies Used to Manage and Process Big Data",
    "text": "Technologies Used to Manage and Process Big Data\nFuture Outlook\n\nContinuous Evolution\n\nTechnologies will keep advancing to meet the growing demands of big data.\n\nIntegration of Tools\n\nGreater integration between systems for seamless data processing.\n\nAdoption of AI and Machine Learning\n\nEnhanced analytics capabilities for deeper insights."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#technologies-used-to-manage-and-process-big-data-4",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#technologies-used-to-manage-and-process-big-data-4",
    "title": "Lecture 11",
    "section": "Technologies Used to Manage and Process Big Data",
    "text": "Technologies Used to Manage and Process Big Data\nFuture Outlook\n\nContinuous Evolution\n\nTechnologies will keep advancing to meet the growing demands of big data.\n\nIntegration of Tools\n\nGreater integration between systems for seamless data processing.\n\nAdoption of AI and Machine Learning\n\nEnhanced analytics capabilities for deeper insights."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#data-warehouses-data-marts-and-data-lakes-5",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#data-warehouses-data-marts-and-data-lakes-5",
    "title": "Lecture 11",
    "section": "Data Warehouses, Data Marts, and Data Lakes",
    "text": "Data Warehouses, Data Marts, and Data Lakes\nExamples of Data Warehouse Usage\n\n\n\n\n\n\n\n\n\nAmerican Airlines\n\nFlight attendants access customer data to enhance in-flight service.\nAbility to resolve issues by offering free miles or travel vouchers based on customer history."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#challenges-of-big-data-6",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#challenges-of-big-data-6",
    "title": "Lecture 11",
    "section": "Challenges of Big Data",
    "text": "Challenges of Big Data\nPrivacy Concerns\n\nEthical Implications\n\nConsent and Transparency: Lack of clear communication about data usage.\nRight to Privacy: Debates over how much personal data companies should access and store."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#data-warehouses-data-marts-and-data-lakes-6",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#data-warehouses-data-marts-and-data-lakes-6",
    "title": "Lecture 11",
    "section": "Data Warehouses, Data Marts, and Data Lakes",
    "text": "Data Warehouses, Data Marts, and Data Lakes\nData Quality in Data Warehouses\n\nChallenges\n\nData Inconsistencies: Duplicate or missing data leading to incorrect analyses.\nDirty Data: Inaccurate, incomplete, or outdated information.\nMisleading statistics: ‚ÄúGarbage in, garbage out‚Äù\n\nImportance\n\nEnsuring high data quality is critical to avoid misleading conclusions.\n\nSolution\n\nImplement robust ETL processes to cleanse and standardize data."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#data-warehouses-data-marts-and-data-lakes-7",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#data-warehouses-data-marts-and-data-lakes-7",
    "title": "Lecture 11",
    "section": "Data Warehouses, Data Marts, and Data Lakes",
    "text": "Data Warehouses, Data Marts, and Data Lakes\nData Quality in Data Warehouses\n\nChallenges\n\nData Inconsistencies: Duplicate or missing data leading to incorrect analyses.\nDirty Data: Inaccurate, incomplete, or outdated information.\nMisleading statistics: ‚ÄúGarbage in, garbage out‚Äù\n\nImportance\n\nEnsuring high data quality is critical to avoid misleading conclusions.\n\nSolution\n\nImplement robust ETL processes to cleanse and standardize data."
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-8",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-8",
    "title": "Lecture 11",
    "section": "Hadoop",
    "text": "Hadoop\nUse Cases and Examples\n\nHadoop is used by various companies:\n\nYahoo!\nYelp\neBay\nEtsy\nX\nMeta\nVerizon Wireless\nWalmart"
  },
  {
    "objectID": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-9",
    "href": "danl-lec/danl-101-lec-11-2024-0923.html#hadoop-9",
    "title": "Lecture 11",
    "section": "Hadoop",
    "text": "Hadoop\nApache Storm and Spark\n\nApache Storm\n\nFunctionality: Processes real-time data streams.\nUse Cases: Real-time analytics, online machine learning, continuous computation.\n\nApache Spark\n\nFunctionality: Provides in-memory computations for speed.\nUse Cases: Batch processing, interactive queries, machine learning."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#technologies-used-to-manage-and-process-big-data-1",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#technologies-used-to-manage-and-process-big-data-1",
    "title": "Lecture 12",
    "section": "Technologies Used to Manage and Process Big Data",
    "text": "Technologies Used to Manage and Process Big Data\n\nDefinition of Big Data\n\nData sets so large and complex that traditional data management tools are inadequate.\n\nThe Need for Advanced Technologies\n\nEmerging technologies are essential to manage, process, and analyze big data effectively.\n\nOverview of Topics\n\nData Warehouses\nExtract, Transform, Load (ETL) Process\nData Marts\nData Lakes\nHadoop"
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#technologies-used-to-manage-and-process-big-data-2",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#technologies-used-to-manage-and-process-big-data-2",
    "title": "Lecture 12",
    "section": "Technologies Used to Manage and Process Big Data",
    "text": "Technologies Used to Manage and Process Big Data\nChallenges with Traditional Data Management\n\nLimitations\n\nTraditional software and hardware can‚Äôt handle the volume, velocity, and variety of big data.\n\nImpact\n\nInability to store massive data volumes efficiently.\nDifficulty in processing and analyzing data in a timely manner.\n\nSolution\n\nAdoption of new technologies specifically designed for big data management."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#data-warehouses-data-marts-and-data-lakes",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#data-warehouses-data-marts-and-data-lakes",
    "title": "Lecture 12",
    "section": "Data Warehouses, Data Marts, and Data Lakes",
    "text": "Data Warehouses, Data Marts, and Data Lakes\nData Warehouses\n\n\n\n\n\n\nDefinition\n\nA large database that holds business information from many sources across the enterprise.\n\nPurpose\n\nSupports decision-making processes by providing a comprehensive view of the organization‚Äôs data."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#data-warehouses-data-marts-and-data-lakes-1",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#data-warehouses-data-marts-and-data-lakes-1",
    "title": "Lecture 12",
    "section": "Data Warehouses, Data Marts, and Data Lakes",
    "text": "Data Warehouses, Data Marts, and Data Lakes\nData Warehouses Characteristics\n\n\n\n\n\n\n\nCharacteristic\nDescription\n\n\n\n\nLarge\nHolds billions of records and petabytes of data\n\n\nMultiple Sources\nData comes from many internal and external sources via the ETL process\n\n\nHistorical\nTypically contains data spanning 5 years or more\n\n\nCross-Organizational Access and Analysis\nData accessed and analyzed by users across the organization to support multiple business processes and decision-making\n\n\nSupports Various Analyses and Reporting\nEnables drill-down analysis, metric development, trend identification"
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#data-warehouses-data-marts-and-data-lakes-2",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#data-warehouses-data-marts-and-data-lakes-2",
    "title": "Lecture 12",
    "section": "Data Warehouses, Data Marts, and Data Lakes",
    "text": "Data Warehouses, Data Marts, and Data Lakes\nData Warehouse Architecture\n\nData Sources\n\nInternal Systems: Online transaction processing systems, customer relationship management, enterprise resource planning.\nExternal Systems: Social media, government databases, etc.\n\nETL Process\n\nExtract, Transform, Load (to be discussed in detail).\n\nData Storage\n\nCentralized repository optimized for query and analysis.\n\nData Access\n\nUsed by various departments for reporting, analysis, and decision-making."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#data-warehouses-data-marts-and-data-lakes-3",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#data-warehouses-data-marts-and-data-lakes-3",
    "title": "Lecture 12",
    "section": "Data Warehouses, Data Marts, and Data Lakes",
    "text": "Data Warehouses, Data Marts, and Data Lakes\nExamples of Data Warehouse Usage\n\n\n\n\n\n\n\n\n\nWalmart\n\nEarly adopter; used data warehouse to gain a competitive advantage in supply chain management.\nHeld transaction data from over 11,000 stores and 25,000 suppliers.\nFirst commercial data warehouse to reach 1 terabyte in 1992.\nCollects data over 2.5 petabytes per hour in 2024."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#data-warehouses-data-marts-and-data-lakes-4",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#data-warehouses-data-marts-and-data-lakes-4",
    "title": "Lecture 12",
    "section": "Data Warehouses, Data Marts, and Data Lakes",
    "text": "Data Warehouses, Data Marts, and Data Lakes\nExamples of Data Warehouse Usage\n\n\n\n\n\n\n\n\n\nWHOOP Wearable Device\n\nCollects massive biometric data from athletes.\nData warehouse stores sensor data collected 100 times per second.\nProvides insights on strain, recovery, and sleep to optimize performance."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#data-warehouses-data-marts-and-data-lakes-5",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#data-warehouses-data-marts-and-data-lakes-5",
    "title": "Lecture 12",
    "section": "Data Warehouses, Data Marts, and Data Lakes",
    "text": "Data Warehouses, Data Marts, and Data Lakes\nExamples of Data Warehouse Usage\n\n\n\n\n\n\n\n\n\nAmerican Airlines\n\nFlight attendants access customer data to enhance in-flight service.\nAbility to resolve issues by offering free miles or travel vouchers based on customer history."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#data-warehouses-data-marts-and-data-lakes-6",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#data-warehouses-data-marts-and-data-lakes-6",
    "title": "Lecture 12",
    "section": "Data Warehouses, Data Marts, and Data Lakes",
    "text": "Data Warehouses, Data Marts, and Data Lakes\nData Quality in Data Warehouses\n\nChallenges\n\nData Inconsistencies: Duplicate or missing data leading to incorrect analyses.\nDirty Data: Inaccurate, incomplete, or outdated information.\nMisleading statistics: ‚ÄúGarbage in, garbage out‚Äù\n\nImportance\n\nEnsuring high data quality is critical to avoid misleading conclusions.\n\nSolution\n\nImplement robust ETL processes to cleanse and standardize data."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#extract-transform-load-etl-process",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#extract-transform-load-etl-process",
    "title": "Lecture 12",
    "section": "Extract, Transform, Load (ETL) Process",
    "text": "Extract, Transform, Load (ETL) Process\nOverview of ETL Process\n\nPurpose\n\nIntegral process for populating data warehouses with clean, consistent data.\n\nStages\n\nExtract\n\nCollecting data from multiple sources.\n\nTransform\n\nCleaning and converting data into a suitable format.\n\nLoad\n\nInserting transformed data into the data warehouse."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#extract-transform-load-etl-process-1",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#extract-transform-load-etl-process-1",
    "title": "Lecture 12",
    "section": "Extract, Transform, Load (ETL) Process",
    "text": "Extract, Transform, Load (ETL) Process\nExtract Stage\n\nData Sources\n\nVarious internal and external systems.\n\nProcess\n\nData Extraction: Pulling data from different systems.\nData Validation: Rejecting data that doesn‚Äôt meet quality standards (e.g., missing values, invalid formats).\n\nChallenges\n\nDealing with heterogeneous data formats and structures."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#extract-transform-load-etl-process-2",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#extract-transform-load-etl-process-2",
    "title": "Lecture 12",
    "section": "Extract, Transform, Load (ETL) Process",
    "text": "Extract, Transform, Load (ETL) Process\nTransform Stage\n\nPurpose\n\nConvert extracted data into a standardized format suitable for analysis.\n\nProcesses\n\nData Cleaning: Correcting errors and inconsistencies.\nData Integration: Combining data from different sources.\nData Aggregation: Summarizing data to reduce processing time.\nExample Transformation:\n\nConverting customer address information into a sales district or census tract."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#extract-transform-load-etl-process-3",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#extract-transform-load-etl-process-3",
    "title": "Lecture 12",
    "section": "Extract, Transform, Load (ETL) Process",
    "text": "Extract, Transform, Load (ETL) Process\nLoad Stage\n\nProcess\n\nData Loading: Inserting transformed data into the data warehouse.\nIndexing: Creating indices to improve query performance.\nConstraint Checking: Ensuring data integrity according to database schema.\n\nChallenges\n\nThe loading process for large data warehouses can take days.\n\nOutcome\n\nThe data warehouse is updated with high-quality, consistent data ready for analysis."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#data-marts",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#data-marts",
    "title": "Lecture 12",
    "section": "Data Marts",
    "text": "Data Marts\nDefinition of Data Marts\n\nSubset of Data Warehouse\n\nFocused on a specific business area or department.\n\nPurpose\n\nProvides relevant data to a specific group without the complexity of the entire data warehouse.\n\nAdvantages\n\nCost-Effective: Less expensive to implement and maintain.\nFaster Access: Optimized for departmental needs.\nSimplified Analysis: Easier to query and analyze due to reduced data volume."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#data-marts-1",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#data-marts-1",
    "title": "Lecture 12",
    "section": "Data Marts",
    "text": "Data Marts\nData Mart Use Cases\n\nDepartmental Focus\n\nFinance: Financial reporting and analysis.\nMarketing: Customer segmentation and campaign analysis.\nInventory: Stock levels and supply chain management.\n\nSmall to Medium-Sized Businesses\n\nAn affordable alternative to a full-scale data warehouse."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#data-marts-2",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#data-marts-2",
    "title": "Lecture 12",
    "section": "Data Marts",
    "text": "Data Marts\nData Marts vs.¬†Data Warehouses\n\n\n\n\n\n\n\n\nFeature\nData Mart\nData Warehouse\n\n\n\n\nScope\nSpecific department or business area\nEntire enterprise\n\n\nData Volume\nSmaller\nLarger\n\n\nComplexity\nLess complex\nMore complex\n\n\nImplementation Time\nShorter\nLonger\n\n\nCost\nLower\nHigher"
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#data-lakes",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#data-lakes",
    "title": "Lecture 12",
    "section": "Data Lakes",
    "text": "Data Lakes\nDefinition of Data Lakes\n\n‚ÄúStore Everything‚Äù Approach\n\nStores all data in its raw, unaltered form.\n\nPurpose\n\nProvides a centralized repository for all data, accommodating future analytical needs.\n\nCharacteristics\n\nData Variety: Includes structured, semi-structured, and unstructured data.\nFlexibility: Data is available for any type of analysis at any time."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#data-lakes-1",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#data-lakes-1",
    "title": "Lecture 12",
    "section": "Data Lakes",
    "text": "Data Lakes\nData Lakes vs.¬†Data Warehouses\n\n\n\n\n\n\n\n\nFeature\nData Lake\nData Warehouse\n\n\n\n\nData Processing\nSchema-on-read (processed when accessed)\nSchema-on-write (processed before storage)\n\n\nData State\nRaw, unprocessed\nCleaned, transformed\n\n\nData Types\nAll data types\nPrimarily structured\n\n\nFlexibility\nHigh\nModerate"
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#data-lakes-2",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#data-lakes-2",
    "title": "Lecture 12",
    "section": "Data Lakes",
    "text": "Data Lakes\nCase Study: Bechtel Corporation\n\n\n\n\n\n\nAbout Bechtel\n\nGlobal engineering, construction, and project management company.\n\nImplementation\n\nBuilt a 5-petabyte data lake consolidating years of project data."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#data-lakes-3",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#data-lakes-3",
    "title": "Lecture 12",
    "section": "Data Lakes",
    "text": "Data Lakes\nCase Study: Bechtel Corporation\n\nBenefits\n\nHistorical Insights: Access to data from hundreds of projects worldwide.\nImproved Forecasting: Better predictions of project outcomes.\nCost Reduction: Identifying inefficiencies to cut costs.\nCompetitive Advantage: Enhanced ability to win new contracts through data-driven insights."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#hadoop",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#hadoop",
    "title": "Lecture 12",
    "section": "Hadoop",
    "text": "Hadoop\nIntroduction to Hadoop\n\n\n\n\n\n\nDefinition\n\nAn open-source software framework for storing and processing large data sets.\n\nComponents\n\nHadoop Distributed File System (HDFS): Distributed data storage.\nMapReduce: Data processing model."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#hadoop-1",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#hadoop-1",
    "title": "Lecture 12",
    "section": "Hadoop",
    "text": "Hadoop\nIntroduction to Hadoop\n\n\n\n\n\n\nPurpose\n\nEnables distributed processing of large data sets across clusters of computers."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#hadoop-2",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#hadoop-2",
    "title": "Lecture 12",
    "section": "Hadoop",
    "text": "Hadoop\nHadoop Architecture - HDFS\n\n\n\n\n\n\n\n\n\nHDFS\n\nDivides data into blocks and distributes them across different servers for processing.\nProvides a highly redundant computing environment\n\nAllows the application to keep running even if individual servers fail."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#hadoop-3",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#hadoop-3",
    "title": "Lecture 12",
    "section": "Hadoop",
    "text": "Hadoop\nHadoop Architecture - MapReduce\n\nMapReduce\n\nMap Phase: Filters and sorts data.\n\ne.g., Sorting customer orders based on their product IDs, with each group corresponding to a specific product ID.\n\nReduce Phase: Summarizes and aggregates results.\n\ne.g., Counting the number of orders within each group, thereby determining the frequency of each product ID."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#hadoop-4",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#hadoop-4",
    "title": "Lecture 12",
    "section": "Hadoop",
    "text": "Hadoop\nHadoop Architecture - MapReduce"
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#hadoop-5",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#hadoop-5",
    "title": "Lecture 12",
    "section": "Hadoop",
    "text": "Hadoop\nHow Hadoop Works\n\nData Distribution\n\nLarge data sets are split into smaller blocks.\n\nData Storage\n\nBlocks are stored across multiple servers in the cluster.\n\nProcessing with MapReduce\n\nMap Tasks: Executed on servers where data resides, minimizing data movement.\nReduce Tasks: Combine results from map tasks to produce final output.\n\nFault Tolerance\n\nData replication ensures processing continues even if servers fail."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#hadoop-6",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#hadoop-6",
    "title": "Lecture 12",
    "section": "Hadoop",
    "text": "Hadoop\nExtending Hadoop for Real-Time Processing\n\nLimitation of Hadoop\n\nHadoop was originally designed for batch processing.\n\nBatch Processing: Data or tasks are collected over a period of time and then processed all at once, typically at scheduled times or during periods of low activity.\n\n\nReal-Time Processing Limitation:\n\nHadoop cannot natively process real-time streaming data (e.g., stock prices flowing into stock exchanges, live sensor data)\n\nExtending Hadoop‚Äôs Capabilities\n\nBoth Apache Storm and Apache Spark can run on top of Hadoop clusters, utilizing HDFS for storage."
  },
  {
    "objectID": "index.html#bullet-homework-1",
    "href": "index.html#bullet-homework-1",
    "title": "DANL 101-05: Introduction to Data Analytics, Fall 2024",
    "section": "\\(\\bullet\\,\\) Homework üíª",
    "text": "\\(\\bullet\\,\\) Homework üíª"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html",
    "href": "danl-hw/danl-101-hw-02.html",
    "title": "Homework Assignment 2",
    "section": "",
    "text": "Please answer all of the following questions thoroughly, ensuring that none are left unanswered.\nFor Homework Assignment 2, the use of any generative artificial intelligence (AI) tools is strictly prohibited.\nOnce you have completed the assignment, click the ‚ÄúSubmit‚Äù button at the bottom of this page to have it evaluated.\n\nAfter clicking ‚ÄúSubmit‚Äù button, wait for the message, ‚ÄúData submitted successfully!‚Äù.\nA confirmation email will be sent to the email address that you provide on this homework page once your submission is received.\n\nYou may submit multiple times, but only your most recent submission will be evaluated.\nThe due is October 8, 5:00 P.M., 2024, Monday, Eastern Time.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#hadoop-7",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#hadoop-7",
    "title": "Lecture 12",
    "section": "Hadoop",
    "text": "Hadoop\nApache Storm and Apache Spark\n\n\nApache Storm\n\nFunctionality:\n\nProcesses real-time data streams.\nHandles unbounded streams of data reliably and efficiently.\n\nUse Cases:\n\nReal-time analytics\nOnline machine learning\nContinuous computation\nReal-time data integration\n\n\n\nApache Spark\n\nFunctionality:\n\nProvides in-memory computations for increased speed.\nSupports both batch and streaming data processing through Spark Streaming.\n\nUse Cases:\n\nInteractive queries\nMachine learning"
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#relational-databases",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#relational-databases",
    "title": "Lecture 12",
    "section": "Relational Databases",
    "text": "Relational Databases\n\nSometimes, one data set is scattered across multiple files.\n\nThe size of the files can be huge.\nThe data collection process can be scattered across time and space.\nE.g., data.frame for county-level data and data.frame for geographic information, such as longitude and latitude.\n\nSometimes we want to combine two or more data.frame based on common data values in those data.frame.\n\nThis task is known in the database world as performing a ‚Äújoin.‚Äù"
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#relational-databases-1",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#relational-databases-1",
    "title": "Lecture 12",
    "section": "Relational Databases",
    "text": "Relational Databases\n\n\n\n\n\n\nThe relational database model is a simple but highly useful way to organize data into collections of two-dimensional tables called relations."
  },
  {
    "objectID": "danl-lec/danl-101-lec-12-2024-0925.html#relational-databases-2",
    "href": "danl-lec/danl-101-lec-12-2024-0925.html#relational-databases-2",
    "title": "Lecture 12",
    "section": "Relational Databases",
    "text": "Relational Databases\nCharacteristics\n\nData is organized into collections of two-dimensional tables called relations.\nEach row in the table represents an entity and each column represents an attribute of that entity.\nEach row in a table is uniquely identified by a key.\nThe key variable enables relationships between the tables to be defined.\nUser queries are used to perform operations on the database like adding, changing, or deleting data and selecting, and joining existing data in existing tables."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#hadoop",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#hadoop",
    "title": "Lecture 13",
    "section": "Hadoop",
    "text": "Hadoop\nIntroduction to Hadoop\n\n\n\n\n\n\nDefinition\n\nAn open-source software framework for storing and processing large data sets.\n\nComponents\n\nHadoop Distributed File System (HDFS): Distributed data storage.\nMapReduce: Data processing model."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#hadoop-1",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#hadoop-1",
    "title": "Lecture 13",
    "section": "Hadoop",
    "text": "Hadoop\nIntroduction to Hadoop\n\n\n\n\n\n\nPurpose\n\nEnables distributed processing of large data sets across clusters of computers."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#hadoop-2",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#hadoop-2",
    "title": "Lecture 13",
    "section": "Hadoop",
    "text": "Hadoop\nHadoop Architecture - HDFS\n\n\n\n\n\n\n\n\n\nHDFS\n\nDivides data into blocks and distributes them across different servers for processing.\nProvides a highly redundant computing environment\n\nAllows the application to keep running even if individual servers fail."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#hadoop-3",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#hadoop-3",
    "title": "Lecture 13",
    "section": "Hadoop",
    "text": "Hadoop\nHadoop Architecture - MapReduce\n\nMapReduce\n\nMap Phase: Filters and sorts data.\n\ne.g., Sorting customer orders based on their product IDs, with each group corresponding to a specific product ID.\n\nReduce Phase: Summarizes and aggregates results.\n\ne.g., Counting the number of orders within each group, thereby determining the frequency of each product ID."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#hadoop-4",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#hadoop-4",
    "title": "Lecture 13",
    "section": "Hadoop",
    "text": "Hadoop\nHadoop Architecture - MapReduce"
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#hadoop-5",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#hadoop-5",
    "title": "Lecture 13",
    "section": "Hadoop",
    "text": "Hadoop\nHow Hadoop Works\n\nData Distribution\n\nLarge data sets are split into smaller blocks.\n\nData Storage\n\nBlocks are stored across multiple servers in the cluster.\n\nProcessing with MapReduce\n\nMap Tasks: Executed on servers where data resides, minimizing data movement.\nReduce Tasks: Combine results from map tasks to produce final output.\n\nFault Tolerance\n\nData replication ensures processing continues even if servers fail."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#hadoop-6",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#hadoop-6",
    "title": "Lecture 13",
    "section": "Hadoop",
    "text": "Hadoop\nExtending Hadoop for Real-Time Processing\n\nLimitation of Hadoop\n\nHadoop is originally designed for batch processing.\n\nBatch Processing: Data or tasks are collected over a period of time and then processed all at once, typically at scheduled times or during periods of low activity.\nResults come after the entire dataset is analyzed.\n\n\nReal-Time Processing Limitation:\n\nHadoop cannot natively process real-time streaming data (e.g., stock prices flowing into stock exchanges, live sensor data)\n\nExtending Hadoop‚Äôs Capabilities\n\nBoth Apache Storm and Apache Spark can run on top of Hadoop clusters, utilizing HDFS for storage."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#hadoop-7",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#hadoop-7",
    "title": "Lecture 13",
    "section": "Hadoop",
    "text": "Hadoop\nApache Storm and Apache Spark\n\n\nApache Storm\n\nFunctionality:\n\nProcesses real-time data streams.\nHandles unbounded streams of data reliably and efficiently.\n\nUse Cases:\n\nReal-time analytics\nOnline machine learning\nContinuous computation\nReal-time data integration\n\n\n\nApache Spark\n\nFunctionality:\n\nProvides in-memory computations for increased speed.\nSupports both batch and streaming data processing through Spark Streaming.\n\nUse Cases:\n\nInteractive queries for quick, on-the-fly data analysis\nMachine learning"
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#references",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#references",
    "title": "Lecture 13",
    "section": "References",
    "text": "References\n\n\nWhat is a Data Warehouse?\nWhat is a Data Mart?\nWhat is a Data Lake?\nWhat is Hadoop?\nWhat is (Apache) Hadoop?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#data-transformation",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#data-transformation",
    "title": "Lecture 13",
    "section": "Data Transformation",
    "text": "Data Transformation\n\n\nDATA_FRAME |&gt; filter(LOGICAL_CONDITIONS)\nDATA_FRAME |&gt; arrange(VARIABLES)\nDATA_FRAME |&gt; select(VARIABLES)\nDATA_FRAME |&gt; rename(NEW_VARIABLE = EXISTING_VARIABLE)\nDATA_FRAME |&gt; mutate(NEW_VARIABLE = ... )\nThe subsequent arguments describe what to do with the data.frame, mostly using the variable names.\nThe result is a data.frame."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#data-transformation-1",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#data-transformation-1",
    "title": "Lecture 13",
    "section": "Data Transformation",
    "text": "Data Transformation\n\nTo use the (native) pipe operator (|&gt;), we should set the option as follows:\n\nTools &gt; Global Options &gt; Code from the side menu &gt; Choose ‚ÄúUse native pipe operator, |&gt;‚Äù."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#data-transformation-2",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#data-transformation-2",
    "title": "Lecture 13",
    "section": "Data Transformation",
    "text": "Data Transformation\ndplyr basics\n\nDATA_FRAME |&gt; filter(LOGICAL_CONDITIONS)\nDATA_FRAME |&gt; arrange(VARIABLES)\nDATA_FRAME |&gt; select(VARIABLES)\nDATA_FRAME |&gt; rename(NEW_VARIABLE = EXISTING_VARIABLE)\nDATA_FRAME |&gt; mutate(NEW_VARIABLE = ... )\nThe subsequent arguments describe what to do with the data.frame, mostly using the variable names.\nThe result is a data.frame."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-1",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-1",
    "title": "Lecture 13",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\njan1 &lt;- flights |&gt; \n  filter(month == 1, day == 1)\n\ndec25 &lt;- flights |&gt; \n  filter(month == 12, day == 25)\n\nclass(flights$month == 1)\n\nfilter() allows us to subset observations based on the value of logical conditions, which are either TRUE or FALSE."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-2",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-2",
    "title": "Lecture 13",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nLogicals and Conditions\n\n\n\n\n\n\n\n\nLogical variables have either TRUE or FALSE value.\nConditions are expressions that evaluate as logical\nWhat logical operations do is combining logical conditions, which returns a logical value when executed."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-3",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-3",
    "title": "Lecture 13",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nLogical Operations\n\n\n\n\n\n\nx is the left-hand circle, y is the right-hand circle, and the shaded region show which parts each operator selects."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-4",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-4",
    "title": "Lecture 13",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nlogical conditions with equality and inequality"
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-5",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-5",
    "title": "Lecture 13",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nlogical conditions\n\n\n\ndf &lt;- data.frame(\n  num = c(8, 9, 10, 11),\n  chr = c(\"A\", \"C\", \"B\", \"A\"))\n\n\n\n\n\n\n\n\ndf |&gt; filter(num &gt; 8 & \n             num &lt; 11)\n                \ndf |&gt; filter(num &gt; 8,\n             num &lt; 11)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-6",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-6",
    "title": "Lecture 13",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nlogical conditions\n\n\n\ndf &lt;- data.frame(\n  num = c(8, 9, 10, 11),\n  chr = c(\"A\", \"C\", \"B\", \"A\"))\n\n\n\n\n\n\n\n\ndf |&gt; filter(num &lt; 10 & \n             chr == \"A\")\n\ndf |&gt; filter(num &lt; 10, \n             chr == \"A\")"
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-7",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-7",
    "title": "Lecture 13",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nlogical conditions\n\n\n\ndf &lt;- data.frame(\n  num = c(8, 9, 10, 11),\n  chr = c(\"A\", \"C\", \"B\", \"A\"))\n\n\n\n\n\n\n\n\ndf |&gt; filter(num &lt; 10 | \n             chr == \"A\")"
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-8",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-8",
    "title": "Lecture 13",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\n%in% operator\n\n\nWhen the or operator | is repeatedly used, we can consider using the %in% operator instead.\n\n\n\n\nflights |&gt; \n  filter( month == 10 | \n          month == 11 | \n          month == 12 )\n\nflights |&gt; \n  filter(month %in% c(10, 11, 12))"
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-9",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-9",
    "title": "Lecture 13",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nMissing values (NA)\n\n\nAlmost any operation involving an unknown value (NA) will also be unknown.\n\nNA &gt; 5\n10 == NA\nNA + 10\nNA / 2\n\nNA == NA"
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-10",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-10",
    "title": "Lecture 13",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nMissing values (NA)\n\n\nLet x be Mary‚Äôs age. We don‚Äôt know how old she is.\nLet y be John‚Äôs age. We don‚Äôt know how old he is.\nAre John and Mary the same age?\n\n\nx &lt;- NA\ny &lt;- NA\nx == y"
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-11",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#filter-observations-with-filter-11",
    "title": "Lecture 13",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nis.na()\n\n\nIf we want to determine if a value is missing, use is.na().\nIf we want to preserve missing values, ask filter() for them explicitly.\n\n\n\n\nx &lt;- NA\nis.na(x) # is x NA?\n\ny &lt;- \"missing\"\nis.na(y) # is y NA?\n\ndf &lt;- data.frame(y = c(1, NA, 3))\n\ndf |&gt; \n  filter(y &gt; 1)\n\ndf |&gt; \n  filter( is.na(y) | y &gt; 1 )"
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#find-all-unique-observations-with-distinct-1",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#find-all-unique-observations-with-distinct-1",
    "title": "Lecture 13",
    "section": "Find all unique observations with distinct()",
    "text": "Find all unique observations with distinct()\n\n\n# Remove duplicate observations, \n#  if any\nflights |&gt; \n  distinct()\n\n# Find all unique \n#  origin and destination pairs\nflights |&gt; \n  distinct(origin, dest)\n\n# If we want to keep other variables\nflights |&gt; \n  distinct(origin, dest, \n           .keep_all = TRUE)\n\n\n\ndistinct() finds all the unique observations in a data.frame.\n\nWe can also optionally provide variable names to distinct()."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#arrange-observations-with-arrange-1",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#arrange-observations-with-arrange-1",
    "title": "Lecture 13",
    "section": "Arrange observations with arrange()",
    "text": "Arrange observations with arrange()\nflights |&gt; \n  arrange(year, month, day)\n\n# re-order observations by `dep_delay` in descending order.\nflights |&gt; \n  arrange([?])\n\narrange() sorts out observations.\n\nIf we provide more than one variable name, each additional variable will be used to break ties in the values of preceding variables.\n\nUse desc() to re-order by a column in descending order.\n\nAdding - before a numeric variable (-NUMERIC_VARIABLE) also works."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#pipe-operator",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#pipe-operator",
    "title": "Lecture 13",
    "section": "Pipe (|>) Operator",
    "text": "Pipe (|&gt;) Operator\n\n\ntidyverse functions work well with the pipe, |&gt;, because the first argument of a tidyverse function is a data.frame and the output is a data.frame.\n\nCtrl + Shift + M for Windows; command + Shift + M for Mac.\n\nThe pipe (|&gt;) takes the thing on its left and passes it along to the function on its right so that\n\nf(x, y) is equivalent to x |&gt; f(y).\ne.g., left_join(DATA_FRAME_1, DATA_FRAME_2) is equivalent to DATA_FRAME_1 |&gt;  left_join(DATA_FRAME_2).\n\nThe easiest way to pronounce the pipe (|&gt;) is ‚Äúthen‚Äù.\n\nThe pipe (|&gt;) is super useful when we have a chain of data transforming operations to do."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#pipe-operator-1",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#pipe-operator-1",
    "title": "Lecture 13",
    "section": "Pipe (|>) Operator",
    "text": "Pipe (|&gt;) Operator\n\nTo use the (native) pipe operator (|&gt;), we should set the option as follows:\n\nTools &gt; Global Options &gt; Code from the side menu &gt; Choose ‚ÄúUse native pipe operator, |&gt;‚Äù."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#joining-relational-data.frames-with-left_join-1",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#joining-relational-data.frames-with-left_join-1",
    "title": "Lecture 13",
    "section": "Joining Relational data.frames with left_join()",
    "text": "Joining Relational data.frames with left_join()\n\n\n\n\n\nx &lt;- data.frame(\n    key = c(1, 2, 3),\n    val_y = c('x1', 'x2', 'x3')\n)\n\ny &lt;- data.frame(\n    key = c(1, 2, 4),\n    val_y = c('y1', 'y2', 'y3')\n)\n\n\n\nThe colored column represents the ‚Äúkey‚Äù variable.\nThe grey column represents the ‚Äúvalue‚Äù column."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#relational-databases",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#relational-databases",
    "title": "Lecture 13",
    "section": "Relational Databases",
    "text": "Relational Databases\n\n\n\nx |&gt;\n  left_join(y)\n\nA left join keeps all observations in x.\n\nThe left join is most commonly used.\n\nNote: NA stands for ‚Äúnot available‚Äù (i.e., a missing value)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#apache-storm-and-apache-spark-1",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#apache-storm-and-apache-spark-1",
    "title": "Lecture 13",
    "section": "Apache Storm and Apache Spark",
    "text": "Apache Storm and Apache Spark\nMedscape: Real-Time Medical News for Healthcare Professionals\n\n\nA medical news app for smartphones and tablets designed to keep healthcare professionals informed.\n\nProvides up-to-date medical news and expert perspectives.\n\n\n\n\n\n\n\n\n\n\n\n\nReal-Time Updates:\n\nUses Apache Storm to process about 500 million tweets per day.\nAutomatic Twitter feed integration helps users track important medical trends shared by physicians and medical commentators."
  },
  {
    "objectID": "danl-cw/danl-101-cw-03.html",
    "href": "danl-cw/danl-101-cw-03.html",
    "title": "left_join()",
    "section": "",
    "text": "Install the nycflights13 R package and load it into your R session in your Posit Cloud project.\n\nAnswer:\n\n# Install the nycflights13 package\ninstall.packages(\"nycflights13\")\n\n# Load the package into your R session\nlibrary(nycflights13)\n\nAnswer: In this step, we first install the nycflights13 package using install.packages(), which contains datasets related to flights in and out of New York City in 2013. Once installed, we load the package into the R session with library(nycflights13), making the flights and airlines data.frames available for analysis."
  },
  {
    "objectID": "danl-cw/danl-101-cw-03.html#question-1.",
    "href": "danl-cw/danl-101-cw-03.html#question-1.",
    "title": "Joining data.frames",
    "section": "",
    "text": "Install the R package, nycflights13, and then load this R package.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-03.html#question-2.",
    "href": "danl-cw/danl-101-cw-03.html#question-2.",
    "title": "Joining data.frames",
    "section": "Question 2.",
    "text": "Question 2.\n\nThe package nycflights13 provides two data.frames, flights and airlines, for which they are related via the carrier variable.\n\ncarrier: Two letter abbreviation indicating a full name of airline.\n\nBy using the left_join()function, create a new data.frame, flight_airline, that includes all the observations and variables in the flights data.frame as well as the name value corresponding to the value in the carrier variable in the flights data.frame.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-03.html#question-1",
    "href": "danl-cw/danl-101-cw-03.html#question-1",
    "title": "left_join()",
    "section": "",
    "text": "Install the nycflights13 R package and load it into your R session in your Posit Cloud project.\n\nAnswer:\n\n# Install the nycflights13 package\ninstall.packages(\"nycflights13\")\n\n# Load the package into your R session\nlibrary(nycflights13)\n\nAnswer: In this step, we first install the nycflights13 package using install.packages(), which contains datasets related to flights in and out of New York City in 2013. Once installed, we load the package into the R session with library(nycflights13), making the flights and airlines data.frames available for analysis."
  },
  {
    "objectID": "danl-cw/danl-101-cw-03.html#question-2",
    "href": "danl-cw/danl-101-cw-03.html#question-2",
    "title": "left_join()",
    "section": "Question 2",
    "text": "Question 2\n\nThe nycflights13 package provides two data.frames: flights and airlines, which are related by the carrier variable.\n\ncarrier: A two-letter abbreviation indicating the full name of the airline.\n\nUse the left_join() function to create a new data.frame, flight_airline, that includes all observations and variables from the flights data.frame, along with the name variable from the airlines data.frame that corresponds to the carrier variable in the flights data.frame.\n\nAnswer:\n\nlibrary(tidyverse)\n\n# Perform left join to merge flights and airlines data.frames\nflight_airline &lt;- flights |&gt; left_join(airlines)\n\n# View the first few rows of the new data.frame\nhead(flight_airline)\n\n# A tibble: 6 √ó 20\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n6  2013     1     1      554            558        -4      740            728\n# ‚Ñπ 12 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, name &lt;chr&gt;\n\n\nAnswer: Here, we use the left_join() function from the one of the packages in tidyverse. The left_join() function merges two data.frames based on a common key variable‚Äîin this case, the carrier variable, which is present in both the flights and airlines data.frames. This operation adds the name variable (airline name) from the airlines data.frame to the flights data.frame, while keeping all observations and variables from flights. The result is stored in flight_airline."
  },
  {
    "objectID": "danl-lec/danl-101-lec-13-2024-0927.html#relational-data",
    "href": "danl-lec/danl-101-lec-13-2024-0927.html#relational-data",
    "title": "Lecture 13",
    "section": "Relational Data",
    "text": "Relational Data\n\n\n\nx |&gt;\n  left_join(y)\n\nA left join keeps all observations in x.\n\nThe left join is most commonly used.\n\nNote: NA stands for ‚Äúnot available‚Äù (i.e., a missing value)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#pipe-operator",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#pipe-operator",
    "title": "Lecture 14",
    "section": "Pipe (|>) Operator",
    "text": "Pipe (|&gt;) Operator\n\n\ntidyverse functions work well with the pipe, |&gt;, because the first argument of a tidyverse function is a data.frame and the output is a data.frame.\n\nCtrl + Shift + M for Windows; command + Shift + M for Mac.\n\nThe pipe (|&gt;) takes the thing on its left and passes it along to the function on its right so that\n\nf(x, y) is equivalent to x |&gt; f(y).\ne.g., left_join(DATA.FRAME_1, DATA.FRAME_2) is equivalent to DATA.FRAME_1 |&gt;  left_join(DATA.FRAME_2).\n\nThe easiest way to pronounce the pipe (|&gt;) is ‚Äúthen‚Äù.\n\nThe pipe (|&gt;) is super useful when we have a chain of data transforming operations to do."
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#pipe-operator-1",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#pipe-operator-1",
    "title": "Lecture 14",
    "section": "Pipe (|>) Operator",
    "text": "Pipe (|&gt;) Operator\n\nTo use the (native) pipe operator (|&gt;), we should set the option as follows:\n\nTools &gt; Global Options &gt; Code from the side menu &gt; Choose ‚ÄúUse native pipe operator, |&gt;‚Äù."
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#joining-relational-data.frames-with-left_join-1",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#joining-relational-data.frames-with-left_join-1",
    "title": "Lecture 14",
    "section": "Joining Relational data.frames with left_join()",
    "text": "Joining Relational data.frames with left_join()\n\n\n\n\n\nx &lt;- data.frame(\n    key = c(1, 2, 3),\n    val_x = c('x1', 'x2', 'x3')\n)\n\ny &lt;- data.frame(\n    key = c(1, 2, 4),\n    val_y = c('y1', 'y2', 'y3')\n)\n\n\n\nThe colored column represents the ‚Äúkey‚Äù variable.\nThe grey column represents the ‚Äúvalue‚Äù column."
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#relational-data",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#relational-data",
    "title": "Lecture 14",
    "section": "Relational Data",
    "text": "Relational Data\n\n\n\nx |&gt;\n  left_join(y)\n\nA left join keeps all observations in x.\n\nThe left join is most commonly used.\n\nNote: NA stands for ‚Äúnot available‚Äù (i.e., a missing value)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#data-transformation",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#data-transformation",
    "title": "Lecture 14",
    "section": "Data Transformation",
    "text": "Data Transformation\n\n\nDATA.FRAME |&gt; filter(LOGICAL_CONDITIONS)\nDATA.FRAME |&gt; arrange(VARIABLES)\nDATA.FRAME |&gt; select(VARIABLES)\nDATA.FRAME |&gt; rename(NEW_VARIABLE = EXISTING_VARIABLE)\nDATA.FRAME |&gt; mutate(NEW_VARIABLE = ... )\nThe subsequent arguments describe what to do with the data.frame, mostly using the variable names.\nThe result is a data.frame."
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-1",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-1",
    "title": "Lecture 14",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\njan1 &lt;- flights |&gt; \n  filter(month == 1, day == 1)\n\ndec25 &lt;- flights |&gt; \n  filter(month == 12, day == 25)\n\nclass(flights$month == 1)\n\nfilter() allows us to subset observations based on the value of logical conditions, which are either TRUE or FALSE."
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-2",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-2",
    "title": "Lecture 14",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nLogicals and Conditions\n\n\n\n\n\n\n\n\nLogical variables have either TRUE or FALSE value.\nConditions are expressions that evaluate as logical.\nWhat logical operations do is combining logical conditions, which returns a logical value when executed."
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-3",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-3",
    "title": "Lecture 14",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nLogical Operations\n\n\nx is the left-hand circle, y is the right-hand circle, and the shaded region show which parts each operator selects."
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-4",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-4",
    "title": "Lecture 14",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nlogical conditions with equality and inequality"
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-5",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-5",
    "title": "Lecture 14",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nlogical conditions\n\n\n\ndf &lt;- data.frame(\n  num = c(8, 9, 10, 11),\n  chr = c(\"A\", \"C\", \"B\", \"A\"))\n\n\n\n\n\n\n\n\ndf |&gt; filter(num &gt; 8 & \n             num &lt; 11)\n                \ndf |&gt; filter(num &gt; 8,\n             num &lt; 11)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-6",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-6",
    "title": "Lecture 14",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nlogical conditions\n\n\n\ndf &lt;- data.frame(\n  num = c(8, 9, 10, 11),\n  chr = c(\"A\", \"C\", \"B\", \"A\"))\n\n\n\n\n\n\n\n\ndf |&gt; filter(num &lt; 10 & \n             chr == \"A\")\n\ndf |&gt; filter(num &lt; 10, \n             chr == \"A\")"
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-7",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-7",
    "title": "Lecture 14",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nlogical conditions\n\n\n\ndf &lt;- data.frame(\n  num = c(8, 9, 10, 11),\n  chr = c(\"A\", \"C\", \"B\", \"A\"))\n\n\n\n\n\n\n\n\ndf |&gt; filter(num &lt; 10 | \n             chr == \"A\")"
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-8",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-8",
    "title": "Lecture 14",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\n\nMissing values (NA)\n\n\nAlmost any operation involving an unknown value (NA) will also be unknown.\n\nNA &gt; 5\n10 == NA\nNA + 10\nNA / 2\n\nNA == NA"
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-9",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-9",
    "title": "Lecture 14",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\n\nMissing values (NA)\n\n\nLet x be Mary‚Äôs age. We don‚Äôt know how old she is.\nLet y be John‚Äôs age. We don‚Äôt know how old he is.\nAre John and Mary the same age?\n\n\nx &lt;- NA\ny &lt;- NA\nx == y"
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-10",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-10",
    "title": "Lecture 14",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\n\nis.na()\n\n\nIf we want to determine if a value is missing, use is.na().\nIf we want to preserve missing values, ask filter() for them explicitly.\n\n\n\n\nx &lt;- NA\nis.na(x) # is x NA?\n\ny &lt;- \"missing\"\nis.na(y) # is y NA?\n\ndf &lt;- data.frame(y = c(1, NA, 3))\n\ndf |&gt; \n  filter(y &gt; 1)\n\ndf |&gt; \n  filter( is.na(y) | y &gt; 1 )"
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-11",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#filter-observations-with-filter-11",
    "title": "Lecture 14",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nis.na()\n\n\nIf we want to determine if a value is missing, use is.na().\nIf we want to preserve missing values, ask filter() for them explicitly.\n\n\n\n\nx &lt;- NA\nis.na(x) # is x NA?\n\ny &lt;- \"missing\"\nis.na(y) # is y NA?\n\ndf &lt;- data.frame(y = c(1, NA, 3))\n\ndf |&gt; \n  filter(y &gt; 1)\n\ndf |&gt; \n  filter( is.na(y) | y &gt; 1 )"
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#find-all-unique-observations-with-distinct-1",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#find-all-unique-observations-with-distinct-1",
    "title": "Lecture 14",
    "section": "Find all unique observations with distinct()",
    "text": "Find all unique observations with distinct()\n\n\n# Remove duplicate observations, \n#  if any\nflights |&gt; \n  distinct()\n\n# Find all unique \n#  origin and destination pairs\nflights |&gt; \n  distinct(origin, dest)\n\n\n\ndistinct() finds all the unique observations in a data.frame.\n\nWe can also optionally provide variable names to distinct()."
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html#arrange-observations-with-arrange-1",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html#arrange-observations-with-arrange-1",
    "title": "Lecture 14",
    "section": "Arrange observations with arrange()",
    "text": "Arrange observations with arrange()\nflights |&gt; \n  arrange(year, month, day)\n\n# re-order observations by `dep_delay` in descending order.\nflights |&gt; \n  arrange([?])\n\narrange() sorts out observations.\n\nIf we provide more than one variable name, each additional variable will be used to break ties in the values of preceding variables.\n\nUse desc(VARIABLE) to re-order by a VARIABLE in descending order.\n\nAdding - before a numeric variable (-NUMERIC_VARIABLE) also works."
  },
  {
    "objectID": "danl-cw/danl-101-cw-04.html",
    "href": "danl-cw/danl-101-cw-04.html",
    "title": "filter(), arrange(), and distinct()",
    "section": "",
    "text": "Find all flights that had an arrival delay of two or more hours\nFind all flights that flew to Houston (IAH or HOU)\nFind all flights that departed in summer (July, August, and September)\nFind all flights that arrived more than two hours late, but didn‚Äôt leave late\nFind all flights that departed between midnight and 6am (inclusive)\n\nAnswer:\n\nlibrary(tidyverse)\nflights &lt;- nycflights13::flights\n\n# Flights with arrival delay of 2 or more hours\ndelayed_flights &lt;- flights |&gt; filter(arr_delay &gt;= 120)  # The unit of the `arr_delay` variable is in a minute.\n\n# Flights to Houston (IAH or HOU)\nhouston_flights &lt;- flights |&gt; filter( dest == \"IAH\" | dest == \"HOU\" )\n\n# Flights that departed in summer (July, August, September)\nsummer_flights &lt;- flights |&gt; filter( month == 7 | month == 8 | month == 9 )\n\n# Flights that arrived more than two hours late but didn‚Äôt leave late\nlate_arrival_on_time_departure &lt;- flights |&gt; filter( arr_delay &gt; 120 & dep_delay &lt;= 0 )\n\n# Flights that departed between midnight and 6am (inclusive)\nearly_morning_flights &lt;- flights |&gt; filter( (dep_time &gt;= 0 & dep_time &lt;= 600) | dep_time == 2400 )\n\n\nfilter(arr_delay &gt;= 120): Finds flights with an arrival delay of two or more hours.\nfilter( dest == \"IAH\" | dest == \"HOU\" ): Filters flights flying to Houston by checking if the dest variable matches ‚ÄúIAH‚Äù or ‚ÄúHOU‚Äù.\nfilter( month == 7 | month == 8 | month == 9 ): Filters flights based on the month variable for July, August, and September.\nfilter(arr_delay &gt; 120 & dep_delay &lt;= 0): Filters flights that arrived more than two hours late but left on time or early.\nfilter( (dep_time &gt;= 0 & dep_time &lt;= 600) | dep_time == 2400): Filters flights departing between midnight and 6am (using military time). The condition dep_time == 2400 is included because, in this data.frame, midnight is represented as 2400 rather than 0.\n\nThis last question involves more advanced techniques, so it won‚Äôt be included in the exams at this level."
  },
  {
    "objectID": "danl-cw/danl-101-cw-04.html#question-1",
    "href": "danl-cw/danl-101-cw-04.html#question-1",
    "title": "filter(), arrange(), and distinct()",
    "section": "",
    "text": "Find all flights that had an arrival delay of two or more hours\nFind all flights that flew to Houston (IAH or HOU)\nFind all flights that departed in summer (July, August, and September)\nFind all flights that arrived more than two hours late, but didn‚Äôt leave late\nFind all flights that departed between midnight and 6am (inclusive)\n\nAnswer:\n\nlibrary(tidyverse)\nflights &lt;- nycflights13::flights\n\n# Flights with arrival delay of 2 or more hours\ndelayed_flights &lt;- flights |&gt; filter(arr_delay &gt;= 120)  # The unit of the `arr_delay` variable is in a minute.\n\n# Flights to Houston (IAH or HOU)\nhouston_flights &lt;- flights |&gt; filter( dest == \"IAH\" | dest == \"HOU\" )\n\n# Flights that departed in summer (July, August, September)\nsummer_flights &lt;- flights |&gt; filter( month == 7 | month == 8 | month == 9 )\n\n# Flights that arrived more than two hours late but didn‚Äôt leave late\nlate_arrival_on_time_departure &lt;- flights |&gt; filter( arr_delay &gt; 120 & dep_delay &lt;= 0 )\n\n# Flights that departed between midnight and 6am (inclusive)\nearly_morning_flights &lt;- flights |&gt; filter( (dep_time &gt;= 0 & dep_time &lt;= 600) | dep_time == 2400 )\n\n\nfilter(arr_delay &gt;= 120): Finds flights with an arrival delay of two or more hours.\nfilter( dest == \"IAH\" | dest == \"HOU\" ): Filters flights flying to Houston by checking if the dest variable matches ‚ÄúIAH‚Äù or ‚ÄúHOU‚Äù.\nfilter( month == 7 | month == 8 | month == 9 ): Filters flights based on the month variable for July, August, and September.\nfilter(arr_delay &gt; 120 & dep_delay &lt;= 0): Filters flights that arrived more than two hours late but left on time or early.\nfilter( (dep_time &gt;= 0 & dep_time &lt;= 600) | dep_time == 2400): Filters flights departing between midnight and 6am (using military time). The condition dep_time == 2400 is included because, in this data.frame, midnight is represented as 2400 rather than 0.\n\nThis last question involves more advanced techniques, so it won‚Äôt be included in the exams at this level."
  },
  {
    "objectID": "danl-cw/danl-101-cw-04.html#question-2",
    "href": "danl-cw/danl-101-cw-04.html#question-2",
    "title": "filter(), arrange(), and distinct()",
    "section": "Question 2",
    "text": "Question 2\n\nHow many flights have a missing dep_time?\n\nAnswer:\n\nmissing_dep_time_flights &lt;- flights |&gt; filter(is.na(dep_time))\nn_missing_dep_time &lt;- nrow(missing_dep_time_flights)\nn_missing_dep_time\n\n[1] 8255\n\n\nWe use filter(is.na(dep_time)) to find flights where the dep_time is missing, and nrow() to count the number of such flights."
  },
  {
    "objectID": "danl-cw/danl-101-cw-04.html#question-3",
    "href": "danl-cw/danl-101-cw-04.html#question-3",
    "title": "filter(), arrange(), and distinct()",
    "section": "Question 3",
    "text": "Question 3\n\nSort flights to find the most delayed flights.\n\nAnswer:\n\n# either dep_delay, arr_delay, or both can be used for this task\nmost_delayed_flights &lt;- flights |&gt; arrange(desc(dep_delay)) \n\narrange(desc(dep_delay)) sorts flights in descending order of departure delay (dep_delay), placing the flights with the longest departure delays at the top."
  },
  {
    "objectID": "danl-cw/danl-101-cw-04.html#question-4",
    "href": "danl-cw/danl-101-cw-04.html#question-4",
    "title": "filter(), arrange(), and distinct()",
    "section": "Question 4",
    "text": "Question 4\n\nWas there a flight on every day of 2013?\n\nAnswer:\n\n# checking there is only one unique value in year variable, that is 2013.\nflights |&gt; distinct(year) # tibble is another name of data.frame in R tidyverse\n\n# A tibble: 1 √ó 1\n   year\n  &lt;int&gt;\n1  2013\n\nflights_per_day &lt;- flights |&gt; distinct(month, day)\nnum_days_2013 &lt;- nrow(flights_per_day)\nnum_days_2013 == 365\n\n[1] TRUE\n\n\n\nWe use distinct(month, day) to find unique combinations of month and day, and then count the number of distinct days using nrow(). We check if this equals 365 to determine if there was a flight on every day of the year.\n\nnrow() returns the number of observations in a data.frame."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01-a.html",
    "href": "danl-hw/danl-101-hw-01-a.html",
    "title": "Homework Assignment 1 - Example Answers",
    "section": "",
    "text": "The following provides the descriptive statistics for each part of the homework, as well as the final score of HW1:"
  },
  {
    "objectID": "danl-hw/danl-101-hw-01-a.html#question-1",
    "href": "danl-hw/danl-101-hw-01-a.html#question-1",
    "title": "Homework Assignment 1 - Example Answers",
    "section": "Question 1",
    "text": "Question 1\nCompute the weighted mean of the vector scores &lt;- c(85, 90, 88, 92, 87) with corresponding weights weights &lt;- c(1, 2, 1, 1, 3).\nAnswer:\n\n# Define the scores vector\nscores &lt;- c(85, 90, 88, 92, 87)\n\n# Define the corresponding weights vector\nweights &lt;- c(1, 2, 1, 1, 3)\n\n# Compute the weighted mean by summing the products of scores and weights and dividing by the sum of weights\nweighted_mean &lt;- sum(scores * weights) / sum(weights)\n\nTherefore the weighted mean is 88.25.\n\nTo clarify the difference between the arithmetic mean and the weighted mean:\n\nArithmetic mean: This is the simple average where all values are treated equally. You sum all the values and divide by the number of values.\nWeighted mean: This takes into account the weights assigned to each value. Each value is multiplied by its corresponding weight, and then the sum of these products is divided by the total sum of the weights.\n\nExample:\n\nLet‚Äôs say you have a vector of values: x &lt;- c(2, 4, 6). And corresponding weights: w &lt;- c(1, 2, 3).\nFor the arithmetic mean, you would ignore the weights and simply find the average of the values:\n\n(Arithmetic mean) = (2 + 4 + 6) / 3 = 4\n\nFor the weighted mean, you would multiply each value by its corresponding weight and then divide by the sum of the weights:\n\n(Weighted mean) = ( (1 * 2) + (2 * 4) + (3 * 6) ) / ( 1 + 2 + 3 ) = 4.67"
  },
  {
    "objectID": "danl-hw/danl-101-hw-01-a.html#question-2",
    "href": "danl-hw/danl-101-hw-01-a.html#question-2",
    "title": "Homework Assignment 1 - Example Answers",
    "section": "Question 2",
    "text": "Question 2\nCompute the interquartile range (IQR) of the following vector x &lt;- c(5, 7, 6, 9, 100, 8, 5, 7, 6) manually, without using the IQR() function.\nAnswer:\n\n# Define the data vector\nx &lt;- c(5, 7, 6, 9, 100, 8, 5, 7, 6)\n\n# Compute the first quartile (Q1)\nq1 &lt;- quantile(x, 0.25)\n\n# Compute the third quartile (Q3)\nq3 &lt;- quantile(x, 0.75)\n\n# Calculate the interquartile range (IQR)\niqr_value &lt;- q3 - q1\n\nTherefore the IQR is 2."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01-a.html#question-3",
    "href": "danl-hw/danl-101-hw-01-a.html#question-3",
    "title": "Homework Assignment 1 - Example Answers",
    "section": "Question 3",
    "text": "Question 3\nDetect the outliers in the vector x &lt;- c(5, 7, 6, 9, 100, 8, 5, 7, 6) using the 1.5*IQR rule.\nAnswer:\n\n# Calculate the lower bound for outliers using Q1 and the IQR\nlower_bound &lt;- q1 - 1.5 * iqr_value\n\n# Calculate the upper bound for outliers using Q3 and the IQR\nupper_bound &lt;- q3 + 1.5 * iqr_value\n\n# Find any values in the data vector that are below the lower bound (lower outliers)\noutliers_lower &lt;- x[ x &lt; lower_bound ]\n\n# Find any values in the data vector that are above the upper bound (upper outliers)\noutliers_upper &lt;- x[ x &gt; upper_bound ]\n\nThere is one single value, 100, that belongs to outliers_upper. There is no lower outlier.\n\nThis rule is described in this lecture slide.\nAlthough we primarily use filter() with data.frame, understanding vector indexing is a fundamental skill in data analysis.\n\nLecture 9 covers vector indexing."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01-a.html#question-4",
    "href": "danl-hw/danl-101-hw-01-a.html#question-4",
    "title": "Homework Assignment 1 - Example Answers",
    "section": "Question 4",
    "text": "Question 4\nCalculate the skewness of the vector x &lt;- c(3, 5, 8, 12, 14, 15, 18, 20) without using any external R package. Skewness is defined as: \\[\n\\text{Skewness} \\,=\\, \\frac{n}{(n-1)(n-2)}\\sum\\left(\\frac{x_{i}-\\bar{x}}{s}\\right)^{3}\n\\] where \\(s\\) is the standard deviation of the vector x.\nAnswer:\n\n# Define the data vector\nx &lt;- c(3, 5, 8, 12, 14, 15, 18, 20)\n\n# Calculate the number of elements (n) in the vector\nn &lt;- length(x)\n\n# Compute the mean of the vector\nmean_x &lt;- mean(x)\n\n# Compute the standard deviation of the vector\nsd_x &lt;- sd(x)\n\n# Calculate skewness using the formula provided\nskewness &lt;- ( n / ( (n-1) * (n-2) ) ) * sum( ( (x - mean_x)/sd_x )^3 )\n\nTherefore skewness is approximately -0.2337.\n\nYou do not need to memorize the formula for skewness in our course.\nThe question is about translating a complex formula into R code."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01-a.html#question-5",
    "href": "danl-hw/danl-101-hw-01-a.html#question-5",
    "title": "Homework Assignment 1 - Example Answers",
    "section": "Question 5",
    "text": "Question 5\nCalculate mode_v, the mode of a numeric vector v &lt;- c(2, 3, 5, 5, 6, 7, 3) using the mfv() function provided by the R package modeest.\nAnswer:\n\n# Define the vector of data\nv &lt;- c(2, 3, 5, 5, 6, 7, 3, 5)\n\n# Use the modeest package's mfv() function to calculate the mode\nmode_v &lt;- modeest::mfv(v)\n\nTo use modeest::mfv(), we first install the modeest package:\n\n# Install the modeest package\ninstall.packages(\"modeest\")\n\nThe notation modeest::mfv() indicates that we are using the mfv() function from the modeest package. The :: operator specifies which package the function or the object is coming from."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01-a.html#question-6",
    "href": "danl-hw/danl-101-hw-01-a.html#question-6",
    "title": "Homework Assignment 1 - Example Answers",
    "section": "Question 6",
    "text": "Question 6\nCalculate, z, the vector for the standardized values in the vector x &lt;- c(10, 20, 30, 40, 50). The standardized value of the individual value, \\(z_{i}\\), is defined as:\n\\[\nz_{i} \\,=\\, \\frac{x_{i} - \\bar{x}}{s},\n\\] where\n\\(\\quad\\) - \\(x_{i}\\): \\(i^{th}\\) value in the vector \\(x\\)\n\\(\\quad\\) - \\(\\bar{x}\\): the mean of values in \\(x\\)\n\\(\\quad\\) - \\(s\\): the standard deviation of values in \\(x\\)\n\\(\\quad\\) - \\(z_{i}\\): \\(i^{th}\\) value in the vector \\(z\\), the vector of the standardized values in \\(x\\).\nAnswer:\n\n# Define the data vector\nx &lt;- c(10, 20, 30, 40, 50)\n\n# Calculate the standardized values (z-scores) for each element in x\nz &lt;- (x - mean(x)) / sd(x)\n\n\nPlease note that the R objects mean_x and sd_x defined in Question 4 are not used in this question."
  },
  {
    "objectID": "danl-lec/danl-101-lec-14-2024-0930.html",
    "href": "danl-lec/danl-101-lec-14-2024-0930.html",
    "title": "Lecture 14",
    "section": "",
    "text": "tidyverse functions work well with the pipe, |&gt;, because the first argument of a tidyverse function is a data.frame and the output is a data.frame.\n\nCtrl + Shift + M for Windows; command + Shift + M for Mac.\n\nThe pipe (|&gt;) takes the thing on its left and passes it along to the function on its right so that\n\nf(x, y) is equivalent to x |&gt; f(y).\ne.g., left_join(DATA.FRAME_1, DATA.FRAME_2) is equivalent to DATA.FRAME_1 |&gt;  left_join(DATA.FRAME_2).\n\nThe easiest way to pronounce the pipe (|&gt;) is ‚Äúthen‚Äù.\n\nThe pipe (|&gt;) is super useful when we have a chain of data transforming operations to do.\n\n\n\n\n\n\nTo use the (native) pipe operator (|&gt;), we should set the option as follows:\n\nTools &gt; Global Options &gt; Code from the side menu &gt; Choose ‚ÄúUse native pipe operator, |&gt;‚Äù.\n\n\n\n\n\n\n\n\n\n\nx &lt;- data.frame(\n    key = c(1, 2, 3),\n    val_x = c('x1', 'x2', 'x3')\n)\n\ny &lt;- data.frame(\n    key = c(1, 2, 4),\n    val_y = c('y1', 'y2', 'y3')\n)\n\n\n\nThe colored column represents the ‚Äúkey‚Äù variable.\nThe grey column represents the ‚Äúvalue‚Äù column.\n\n\n\n\n\n\n\nx |&gt;\n  left_join(y)\n\nA left join keeps all observations in x.\n\nThe left join is most commonly used.\n\nNote: NA stands for ‚Äúnot available‚Äù (i.e., a missing value)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1002.html#data-transformation",
    "href": "danl-lec/danl-101-lec-15-2024-1002.html#data-transformation",
    "title": "Lecture 15",
    "section": "Data Transformation",
    "text": "Data Transformation\n\n\nDATA.FRAME |&gt; filter(LOGICAL_CONDITIONS)\nDATA.FRAME |&gt; arrange(VARIABLES)\nDATA.FRAME |&gt; distinct(VARIABLES)\nDATA.FRAME |&gt; select(VARIABLES)\nDATA.FRAME |&gt; rename(NEW_VARIABLE = EXISTING_VARIABLE)\nDATA.FRAME |&gt; mutate(NEW_VARIABLE = ... )\nThe subsequent arguments describe what to do with the data.frame, mostly using the variable names.\nThe result is a data.frame."
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1002.html#filter-observations-with-filter-1",
    "href": "danl-lec/danl-101-lec-15-2024-1002.html#filter-observations-with-filter-1",
    "title": "Lecture 15",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nMissing values (NA)\n\n\nAlmost any operation involving an unknown value (NA) will also be unknown.\n\nNA &gt; 5\n10 == NA\nNA + 10\nNA / 2\n\nNA == NA"
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1002.html#filter-observations-with-filter-2",
    "href": "danl-lec/danl-101-lec-15-2024-1002.html#filter-observations-with-filter-2",
    "title": "Lecture 15",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nMissing values (NA)\n\n\nLet x be Mary‚Äôs age. We don‚Äôt know how old she is.\nLet y be John‚Äôs age. We don‚Äôt know how old he is.\nAre John and Mary the same age?\n\n\nx &lt;- NA\ny &lt;- NA\nx == y"
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1002.html#filter-observations-with-filter-3",
    "href": "danl-lec/danl-101-lec-15-2024-1002.html#filter-observations-with-filter-3",
    "title": "Lecture 15",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\nis.na()\n\n\nIf we want to determine if a value is missing, use is.na().\nIf we want to preserve missing values, ask filter() for them explicitly.\n\n\n\n\nx &lt;- NA\nis.na(x) # is x NA?\n\ny &lt;- \"missing\"\nis.na(y) # is y NA?\n\ndf &lt;- data.frame(y = c(1, NA, 3))\n\ndf |&gt; \n  filter(y &gt; 1)\n\ndf |&gt; \n  filter( is.na(y) | y &gt; 1 )"
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1002.html#find-all-unique-observations-with-distinct-1",
    "href": "danl-lec/danl-101-lec-15-2024-1002.html#find-all-unique-observations-with-distinct-1",
    "title": "Lecture 15",
    "section": "Find all unique observations with distinct()",
    "text": "Find all unique observations with distinct()\n\n\n# Remove duplicate observations, \n#  if any\nflights |&gt; \n  distinct()\n\n# Find all unique \n#  origin and destination pairs\nflights |&gt; \n  distinct(origin, dest)\n\n\n\ndistinct() finds all the unique observations in a data.frame.\n\nWe can also optionally provide variable names to distinct()."
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1002.html#arrange-observations-with-arrange-1",
    "href": "danl-lec/danl-101-lec-15-2024-1002.html#arrange-observations-with-arrange-1",
    "title": "Lecture 15",
    "section": "Arrange observations with arrange()",
    "text": "Arrange observations with arrange()\nflights |&gt; \n  arrange(year, month, day)\n\narrange() sorts out observations.\n\nIf we provide more than one variable name, each additional variable will be used to break ties in the values of preceding variables."
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1002.html#select-variables-with-select-1",
    "href": "danl-lec/danl-101-lec-15-2024-1002.html#select-variables-with-select-1",
    "title": "Lecture 15",
    "section": "Select variables with select()",
    "text": "Select variables with select()\nBasic\n\n\nIt‚Äôs not uncommon to get datasets with hundreds or thousands of variables.\nselect() allows us to narrow in on the variables we‚Äôre actually interested in.\nWe can select variables by their names.\n\n\nflights |&gt; \n  select(year, month, day)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1002.html#select-variables-with-select-2",
    "href": "danl-lec/danl-101-lec-15-2024-1002.html#select-variables-with-select-2",
    "title": "Lecture 15",
    "section": "Select variables with select()",
    "text": "Select variables with select()\nVAR_1:VAR_2\nflights |&gt; \n  select(year:day)\n\n\nWith select(VAR_1:VAR_2), we can select all the variables between VARIABLE_1 and VARIABLE_2, inclusively."
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1002.html#select-variables-with-select-3",
    "href": "danl-lec/danl-101-lec-15-2024-1002.html#select-variables-with-select-3",
    "title": "Lecture 15",
    "section": "Select variables with select()",
    "text": "Select variables with select()\nRemoval\nflights |&gt; \n  select(-year)\n\n\nWith select(-VARIABLES), we can remove variables."
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1002.html#rename-variables-with-rename-1",
    "href": "danl-lec/danl-101-lec-15-2024-1002.html#rename-variables-with-rename-1",
    "title": "Lecture 15",
    "section": "Rename variables with rename()",
    "text": "Rename variables with rename()\nflights |&gt; \n  rename( tail_num = tailnum )\n\n\nrename() can be used to rename variables:\n\nDATA_FRAME |&gt; rename(NEW_VARIABLE = EXISTING_VARIABLE)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1002.html#add-new-variables-with-mutate-1",
    "href": "danl-lec/danl-101-lec-15-2024-1002.html#add-new-variables-with-mutate-1",
    "title": "Lecture 15",
    "section": "Add new variables with mutate()",
    "text": "Add new variables with mutate()\nArithmetic operations\n\n\nmutate() is useful to add new variables that are functions of existing variables.\n\nNew variables can be a result of arithmetic operations.\nArithmetic operators: +, -, *, /, ^\n\n\n\nflights |&gt; \n  select(dep_delay, arr_delay) |&gt; \n  mutate(gain = dep_delay - arr_delay)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1002.html#add-new-variables-with-mutate-2",
    "href": "danl-lec/danl-101-lec-15-2024-1002.html#add-new-variables-with-mutate-2",
    "title": "Lecture 15",
    "section": "Add new variables with mutate()",
    "text": "Add new variables with mutate()\nArithmetic operations\n\n\nWe can add more than one variables\n\n\nflights |&gt; \n  select(dep_delay, arr_delay, air_time) |&gt; \n  mutate(gain = dep_delay - arr_delay,\n         hours = air_time / 60)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1002.html#add-new-variables-with-mutate-3",
    "href": "danl-lec/danl-101-lec-15-2024-1002.html#add-new-variables-with-mutate-3",
    "title": "Lecture 15",
    "section": "Add new variables with mutate()",
    "text": "Add new variables with mutate()\nUseful functions\ndf &lt;- data.frame( x = c(1:10) ) |&gt; \n  mutate(x_log = log(x),\n         x_exp = exp(x),\n         x_sqrt = sqrt(x),\n         x_fct = factor(x),\n         x_chr = as.character(x),\n         x_num = as.numeric(x),\n         x_int = as.integer(x) )\n\nWe can use math functions as well as as.DATATYPE functions:\n\nFor example, log(), exp(), sqrt(), factor(), as.character(), as.numeric(), and as.integer()."
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1002.html#arrange-observations-with-arrange-2",
    "href": "danl-lec/danl-101-lec-15-2024-1002.html#arrange-observations-with-arrange-2",
    "title": "Lecture 15",
    "section": "Arrange observations with arrange()",
    "text": "Arrange observations with arrange()\nDescending order with desc()\n# re-order observations by `dep_delay` in descending order.\nflights |&gt; \n  arrange(desc(dep_delay))\n  \nflights |&gt; \n  arrange(-dep_delay)\n\nUse desc(VARIABLE) to re-order by a VARIABLE in descending order.\n\nAdding - before a numeric variable (-NUMERIC_VARIABLE) also works."
  },
  {
    "objectID": "danl-cw/danl-101-cw-05.html",
    "href": "danl-cw/danl-101-cw-05.html",
    "title": "Quiz 1",
    "section": "",
    "text": "Descriptive Statistics\nThe following provides the percentage of the correct answers for each question in Quiz 1:\n\n\n\n\n\n\n\n\n\n\nQuestion 1. data.frame\nIn a data frame, what form does an observation take?\nAnswer: Row\n\nThis slide in Lecture 7 explains what makes a data.frame tidy. In our course, all given data.frames are tidy.\n\nIt‚Äôs been a while since we discussed variable-column, observation-row, and value-cell terminologies in a tidy data.frame, but these concepts are crucial for conducting data analysis.\n\nIn a data.frame:\n\nA variable takes a coulmn\nAn observation takes a row\nA value takes a cell\n\n\n\n\n\nQuestion 2. nrow()\n\n___(df)\n\n\nFill in the blank (___) to calculate the number of observations in the data.frame, df.\n\nAnswer: nrow\n\nnrow(df)\n\n\nThis slide in Lecture 8 and a couple of class R scripts explain nrow().\nYou might have difficulty in this question if you do not recall nrow().\n\nFull credit is given to answers that imply counting observations.\n\n\n\n\n\nQuestion 3. &gt;= (Greater-than-or-equal-to operator)\n\ndf_filtered &lt;- df |&gt; filter(num __ 9)\n\n\nFill in the blank (___) to keep observations, in which the value of the num variable is greater than or equal to 9.\n\nAnswer: &gt;=\n\ndf_filtered &lt;- df |&gt; filter(num &gt;= 9)\n\n\nThis slide in Lecture 14 and a couple of class R scripts explain this inequality operator.\n\n\n\n\nQuestion 4. ! (Negation operator)\n\nnon_dec &lt;-  df |&gt; filter( ___(month == 12) )\n\n\nFill in the blank (___) to keep observations, in which the value of the month variable is not equal to 12 in the data.frame df.\n\nAnswer: !\n\nnon_dec &lt;-  df |&gt; filter( !(month == 12) )\n\n\nThis slide in Lecture 14 and Line 56-57 in this class R script explain a negation operator, ! (not).\nA more natural way to write this line is using != (not-equal operator):\n\n\nnon_dec &lt;-  df |&gt; filter( month != 12 )\n\n\n\n\nQuestion 5. & (And operator)\n\ndf_filtered &lt;- df |&gt; filter(subject == \"DANL\" ___ number == 101)\n\n\nFill in the blank (___) to keep observations, in which the value of the subject variable is ‚ÄúDANL‚Äù and the value of the number variable is 101.\n\nAnswer: & (,)\n\ndf_filtered &lt;- df |&gt; filter(subject == \"DANL\" & number == 101)\ndf_filtered &lt;- df |&gt; filter(subject == \"DANL\", number == 101)\n\n\nThis slide and this slide in Lecture 14 explain logical operation, & (and).\n\n\n\n\nDiscussion\nWelcome to our Quiz 1 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Quiz 1.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Quiz 1 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-cw/danl-101-cw-05.html#question-1",
    "href": "danl-cw/danl-101-cw-05.html#question-1",
    "title": "select() and rename()",
    "section": "Question 1",
    "text": "Question 1\nCreate a new data.frame, df that keeps only the following five variables‚ÄîFiscal_Year, Agency_Name, First_Name, Last_Name, and Base_Salary‚Äîfrom the data.frame nyc_payroll_new.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-05.html#question-2",
    "href": "danl-cw/danl-101-cw-05.html#question-2",
    "title": "select() and rename()",
    "section": "Question 2",
    "text": "Question 2\nGiven the data.frame df with a variable named Agency_Name, how would you rename it to Agency?\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-05.html#question-3",
    "href": "danl-cw/danl-101-cw-05.html#question-3",
    "title": "select() and rename()",
    "section": "Question 3",
    "text": "Question 3\nHow would you remove the Fiscal_Year variable using select()?\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-05.html#question-4",
    "href": "danl-cw/danl-101-cw-05.html#question-4",
    "title": "select(), rename(), and mutate()",
    "section": "Question 4",
    "text": "Question 4\nHow would you remove the Fiscal_Year variable using select()?\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-05.html#question-5",
    "href": "danl-cw/danl-101-cw-05.html#question-5",
    "title": "select(), rename(), and mutate()",
    "section": "Question 5",
    "text": "Question 5\nHow would you select only Agency_Name (or Agency) and Base_Salary and then create a new variable Bonus which is 10% of Base_Salary?\nAnswer:"
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1004.html#data-transformation",
    "href": "danl-lec/danl-101-lec-15-2024-1004.html#data-transformation",
    "title": "Lecture 15",
    "section": "",
    "text": "DATA.FRAME |&gt; filter(LOGICAL_CONDITIONS)\nDATA.FRAME |&gt; arrange(VARIABLES)\nDATA.FRAME |&gt; distinct(VARIABLES)\nDATA.FRAME |&gt; select(VARIABLES)\nDATA.FRAME |&gt; rename(NEW_VARIABLE = EXISTING_VARIABLE)\nThe subsequent arguments describe what to do with the data.frame, mostly using the variable names.\nThe result is a data.frame."
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1004.html#filter-observations-with-filter-1",
    "href": "danl-lec/danl-101-lec-15-2024-1004.html#filter-observations-with-filter-1",
    "title": "Lecture 15",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\n\nMissing values (NA)\n\n\nAlmost any operation involving an unknown value (NA) will also be unknown.\n\nNA &gt; 5\n10 == NA\nNA + 10\nNA / 2\n(1 + NA + 3) / 3\nmean( c(1, NA, 3) )\nsd( c(1, NA, 3) )"
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1004.html#filter-observations-with-filter-2",
    "href": "danl-lec/danl-101-lec-15-2024-1004.html#filter-observations-with-filter-2",
    "title": "Lecture 15",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\n\nMissing values (NA)\n\n\nLet x be Mary‚Äôs age. We don‚Äôt know how old she is.\nLet y be John‚Äôs age. We don‚Äôt know how old he is.\nAre John and Mary the same age?\n\n\nx &lt;- NA\ny &lt;- NA\nx == y"
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1004.html#filter-observations-with-filter-3",
    "href": "danl-lec/danl-101-lec-15-2024-1004.html#filter-observations-with-filter-3",
    "title": "Lecture 15",
    "section": "Filter observations with filter()",
    "text": "Filter observations with filter()\n\nis.na()\n\n\nIf we want to determine if a value is missing, use is.na().\nIf we want to preserve missing values, ask filter() for them explicitly.\n\n\n\n\nx &lt;- NA\nis.na(x) # is x NA?\n\ny &lt;- \"missing\"\nis.na(y) # is y NA?\n\nv1 &lt;- c(1, NA, 3)\nis.na(v1) # is v1 NA?\n\ndf &lt;- data.frame(v1 = c(1, NA, 3),\n                 v2 = c(1, 2, 3))\n\ndf |&gt; \n  filter( is.na(v1) )\n\ndf |&gt; \n  filter( !is.na(v1) )"
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1004.html#find-all-unique-observations-with-distinct-1",
    "href": "danl-lec/danl-101-lec-15-2024-1004.html#find-all-unique-observations-with-distinct-1",
    "title": "Lecture 15",
    "section": "Find all unique observations with distinct()",
    "text": "Find all unique observations with distinct()\n\n\ndf &lt;- data.frame(\n  v1 = c(\"USA\", \"Korea\", \"USA\"),\n  v2 = c(\"D.C.\", \"Seoul\", \"D.C.\") \n  v3 = c(\"Georgetown\", \"Gangnam\", \n                       \"Georgetown\") \n  )\n\n# Remove duplicate observations\ndf |&gt; \n  distinct()\n\n# Remove duplicate observations, \n# if any\n\nflights |&gt; \n  distinct()\n\n\n\ndistinct() can find all the unique observations in a data.frame."
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1004.html#arrange-observations-with-arrange-1",
    "href": "danl-lec/danl-101-lec-15-2024-1004.html#arrange-observations-with-arrange-1",
    "title": "Lecture 15",
    "section": "Arrange observations with arrange()",
    "text": "Arrange observations with arrange()\n# arrange observations by `dep_delay` in ascending order.\nflights |&gt; \n  arrange(dep_delay)\n\narrange() sorts out observations."
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1004.html#arrange-observations-with-arrange-2",
    "href": "danl-lec/danl-101-lec-15-2024-1004.html#arrange-observations-with-arrange-2",
    "title": "Lecture 15",
    "section": "Arrange observations with arrange()",
    "text": "Arrange observations with arrange()\nDescending order with desc()\n# arrange observations by `dep_delay` in descending order.\nflights |&gt; \n  arrange(desc(dep_delay))\n  \nflights |&gt; \n  arrange(-dep_delay)\n\nUse desc(VARIABLE) to re-order by a VARIABLE in descending order.\n\nAdding - before a numeric variable (-NUMERIC_VARIABLE) also works."
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1004.html#select-variables-with-select-1",
    "href": "danl-lec/danl-101-lec-15-2024-1004.html#select-variables-with-select-1",
    "title": "Lecture 15",
    "section": "Select variables with select()",
    "text": "Select variables with select()\nBasic\n\n\nIt‚Äôs not uncommon to get datasets with hundreds or thousands of variables.\nselect() allows us to narrow in on the variables we‚Äôre actually interested in.\nWe can select variables by their names.\n\n\nflights |&gt; \n  select(year, month, day)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1004.html#select-variables-with-select-2",
    "href": "danl-lec/danl-101-lec-15-2024-1004.html#select-variables-with-select-2",
    "title": "Lecture 15",
    "section": "Select variables with select()",
    "text": "Select variables with select()\nRemoval\nflights |&gt; \n  select(-year)\n\n\nWith select(-VARIABLES), we can remove variables."
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1004.html#select-variables-with-select-3",
    "href": "danl-lec/danl-101-lec-15-2024-1004.html#select-variables-with-select-3",
    "title": "Lecture 15",
    "section": "Select variables with select()",
    "text": "Select variables with select()\nRemoval\nflights |&gt; \n  select(-year)\n\n\nWith select(-VARIABLES), we can remove variables."
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1004.html#rename-variables-with-rename-1",
    "href": "danl-lec/danl-101-lec-15-2024-1004.html#rename-variables-with-rename-1",
    "title": "Lecture 15",
    "section": "Rename variables with rename()",
    "text": "Rename variables with rename()\nflights |&gt; \n  rename( tail_num = tailnum )\n\n\nrename() can be used to rename variables:\n\nDATA_FRAME |&gt; rename(NEW_VARIABLE = EXISTING_VARIABLE)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1004.html#find-all-unique-observations-with-distinct-2",
    "href": "danl-lec/danl-101-lec-15-2024-1004.html#find-all-unique-observations-with-distinct-2",
    "title": "Lecture 15",
    "section": "Find all unique observations with distinct()",
    "text": "Find all unique observations with distinct()\n# Find all unique \n#  origin and destination pairs\nflights |&gt; \n  distinct(origin, dest)\n\nWe can also provide variable names to distinct()."
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1004.html#arrange-observations-with-arrange-3",
    "href": "danl-lec/danl-101-lec-15-2024-1004.html#arrange-observations-with-arrange-3",
    "title": "Lecture 15",
    "section": "Arrange observations with arrange()",
    "text": "Arrange observations with arrange()\n\n\n\ndf &lt;- data.frame(\n  year = c(2024, 2021, 2024, 2024),\n  month = c(7, 10, 7, 4),\n  day = c(20, 19, 15, 9)\n)\n\n\n\n\n\n\n\n\ndf |&gt; \n  arrange(year, month, day)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf we provide more than one variable name, each additional variable will be used to break ties in the values of preceding variables."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01-a.html#truefalse",
    "href": "danl-hw/danl-101-hw-01-a.html#truefalse",
    "title": "Homework Assignment 1 - Example Answers",
    "section": "True/False",
    "text": "True/False\n\nData analytics aims to replace traditional business and economics courses. (False)\n\nData analytics is seen as a complement to traditional business and economics courses, enhancing decision-making with data-driven insights rather than replacing foundational business knowledge. \n\nData analysts are the only professionals who benefit from data analytics skills. (False)\n\nMany professionals, including marketers, financial analysts, healthcare professionals, and even educators, benefit from data analytics skills as they apply to various fields. \n\nPython and R are the only programming languages used in data science. (False)\n\nWhile Python and R are popular in data science, other languages like SQL, MATLAB, and even JavaScript are also used depending on the application. \n\nThe use of generative AI requires a deep understanding of the subject matter to apply it effectively. (True)\n\nTo use generative AI effectively, it is essential to have a solid understanding of the subject area to interpret and apply the results accurately. \n\nMachine learning algorithms need to be explicitly programmed for each task they perform. (False)\n\nMachine learning algorithms learn patterns from data, meaning they don‚Äôt need explicit programming for each task. Instead, they adapt and improve their performance based on the data provided."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01-a.html#multiple-choice",
    "href": "danl-hw/danl-101-hw-01-a.html#multiple-choice",
    "title": "Homework Assignment 1 - Example Answers",
    "section": "Multiple Choice",
    "text": "Multiple Choice\n\nWhich of the following skills is NOT typically covered in traditional business or economics classes?\n\nFinding and cleaning datasets\nWhy?: Data cleaning and preparation are often covered in data analytics but not typically in traditional business or economics courses. \n\nWhich of the following is a key reason why R is widely used in data analysis?\n\nIt is specifically designed for statistical computing\nWhy?: R was created for statistical analysis and is widely used because of its extensive libraries for data analysis and statistical modeling. \n\nWhich question would you ask to analyze season ticket renewals in sports analytics?\n\nWhich type of fan engages most with team merchandise?\nWhy?: This question helps to understand fan loyalty and engagement, which are important factors in predicting season ticket renewals.\n\n\n\nWhile the above might be the most appropriate answer to this question, I also give full credit to the following responses:\n\nWhat factors drive last-minute individual seat ticket purchases?\n\nWhat are the financial benefits of dynamic pricing? \n\n\n\n\nWhich of the following is a benefit of using Git in software development?\n\nIt tracks changes and helps manage multiple versions of a project\nWhy?: Git is a version control system that tracks changes and allows developers to manage multiple versions of a project, making collaboration more efficient. \n\nWhich of the following is a key application of data analytics in the retail sector?\n\nEnhancing physical store layouts based on customer behavior\nWhy?: Data analytics helps retailers optimize store layouts by analyzing customer movement patterns, ultimately improving the customer experience and sales."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01-a.html#short-eassay",
    "href": "danl-hw/danl-101-hw-01-a.html#short-eassay",
    "title": "Homework Assignment 1 - Example Answers",
    "section": "Short Eassay",
    "text": "Short Eassay\n\nWhy are R and Python considered important tools for data analytics?\n\nR and Python are popular because they have a wide range of libraries and packages for data manipulation, visualization, and machine learning. They also support a large user community and are open-source, making them accessible and adaptable. \n\nExplain why understanding the output of Generative AI tools like ChatGPT is important for data analysts or data scientists.\n\nData analysts need to interpret the output of generative AI tools to ensure that the generated information is relevant, accurate, and aligned with the specific context of their analysis. This understanding helps prevent misinterpretation and misuse of AI-generated insights. \n\nHow does dynamic ticket pricing work in sports analytics?\n\nDynamic ticket pricing adjusts the price of tickets in real-time based on demand, opponent strength, weather conditions, and other factors. This approach maximizes revenue by charging more when demand is high and less when demand is low. \n\nHow do business intelligence (BI) tools assist in decision-making for businesses?\n\nBI tools help businesses collect, process, and visualize data to support informed decision-making. They provide insights into trends, performance metrics, and areas of improvement, enabling businesses to make data-driven decisions."
  },
  {
    "objectID": "danl-lec/danl-101-lec-16-2024-1007.html#arrange-observations-with-arrange-1",
    "href": "danl-lec/danl-101-lec-16-2024-1007.html#arrange-observations-with-arrange-1",
    "title": "Lecture 16",
    "section": "Arrange observations with arrange()",
    "text": "Arrange observations with arrange()\n# arrange observations by `dep_delay` in ascending order.\nflights |&gt; \n  arrange(dep_delay)\n\narrange() sorts out observations."
  },
  {
    "objectID": "danl-lec/danl-101-lec-16-2024-1007.html#arrange-observations-with-arrange-2",
    "href": "danl-lec/danl-101-lec-16-2024-1007.html#arrange-observations-with-arrange-2",
    "title": "Lecture 16",
    "section": "Arrange observations with arrange()",
    "text": "Arrange observations with arrange()\nDescending order with desc()\n# arrange observations by `dep_delay` in descending order.\nflights |&gt; \n  arrange(desc(dep_delay))\n  \nflights |&gt; \n  arrange(-dep_delay)\n\nUse desc(VARIABLE) to re-order by a VARIABLE in descending order.\n\nAdding - before a numeric variable (-NUMERIC_VARIABLE) also works."
  },
  {
    "objectID": "danl-lec/danl-101-lec-16-2024-1007.html#arrange-observations-with-arrange-3",
    "href": "danl-lec/danl-101-lec-16-2024-1007.html#arrange-observations-with-arrange-3",
    "title": "Lecture 16",
    "section": "Arrange observations with arrange()",
    "text": "Arrange observations with arrange()\n\n\n\ndf &lt;- data.frame(\n  year = c(2024, 2021, 2024, 2024),\n  month = c(7, 10, 7, 4),\n  day = c(20, 19, 15, 9)\n)\n\n\n\n\n\n\n\n\ndf |&gt; \n  arrange(year, month, day)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf we provide more than one variable name, each additional variable will be used to break ties in the values of preceding variables."
  },
  {
    "objectID": "danl-lec/danl-101-lec-16-2024-1007.html#find-all-unique-observations-with-distinct-1",
    "href": "danl-lec/danl-101-lec-16-2024-1007.html#find-all-unique-observations-with-distinct-1",
    "title": "Lecture 16",
    "section": "Find all unique observations with distinct()",
    "text": "Find all unique observations with distinct()\n\n\ndf &lt;- data.frame(\n  v1 = c(\"USA\", \"Korea\", \"USA\"),\n  v2 = c(\"D.C.\", \"Seoul\", \"D.C.\") \n  v3 = c(\"Georgetown\", \"Gangnam\", \n                       \"Georgetown\") \n  )\n\n# Remove duplicate observations\ndf |&gt; \n  distinct()\n\n# Remove duplicate observations, \n# if any\n\nflights |&gt; \n  distinct()\n\n\n\ndistinct() can find all the unique observations in a data.frame."
  },
  {
    "objectID": "danl-lec/danl-101-lec-16-2024-1007.html#find-all-unique-observations-with-distinct-2",
    "href": "danl-lec/danl-101-lec-16-2024-1007.html#find-all-unique-observations-with-distinct-2",
    "title": "Lecture 16",
    "section": "Find all unique observations with distinct()",
    "text": "Find all unique observations with distinct()\n# Find all unique \n#  origin and destination pairs\nflights |&gt; \n  distinct(origin, dest)\n\nWe can also provide variable names to distinct()."
  },
  {
    "objectID": "danl-lec/danl-101-lec-16-2024-1007.html#select-variables-with-select-1",
    "href": "danl-lec/danl-101-lec-16-2024-1007.html#select-variables-with-select-1",
    "title": "Lecture 16",
    "section": "Select variables with select()",
    "text": "Select variables with select()\nBasic\n\n\nIt‚Äôs not uncommon to get datasets with hundreds or thousands of variables.\nselect() allows us to narrow in on the variables we‚Äôre actually interested in.\nWe can select variables by their names.\n\n\nflights |&gt; \n  select(year, month, day)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-16-2024-1007.html#select-variables-with-select-2",
    "href": "danl-lec/danl-101-lec-16-2024-1007.html#select-variables-with-select-2",
    "title": "Lecture 16",
    "section": "Select variables with select()",
    "text": "Select variables with select()\nRemoval\nflights |&gt; \n  select(-year)\n\n\nWith select(-VARIABLES), we can remove variables."
  },
  {
    "objectID": "danl-lec/danl-101-lec-16-2024-1007.html#rename-variables-with-rename-1",
    "href": "danl-lec/danl-101-lec-16-2024-1007.html#rename-variables-with-rename-1",
    "title": "Lecture 16",
    "section": "Rename variables with rename()",
    "text": "Rename variables with rename()\nflights |&gt; \n  rename( tail_num = tailnum )\n\n\nrename() can be used to rename variables:\n\nDATA_FRAME |&gt; rename(NEW_VARIABLE = EXISTING_VARIABLE)"
  },
  {
    "objectID": "danl-cw/danl-101-cw-06.html",
    "href": "danl-cw/danl-101-cw-06.html",
    "title": "select() and rename()",
    "section": "",
    "text": "For this Classwork 6, consider the following data.frame, nyc_payroll_new.\nlibrary(tidyverse)\nnyc_payroll_new &lt;- read_csv(\"https://bcdanl.github.io/data/nyc_payroll_2024.csv\")\nFor detailed descriptions of the variables in this data.frame, please refer to the following link: Citywide Payroll Data (Fiscal Year)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-15-2024-1004.html",
    "href": "danl-lec/danl-101-lec-15-2024-1004.html",
    "title": "Lecture 15",
    "section": "",
    "text": "DATA.FRAME |&gt; filter(LOGICAL_CONDITIONS)\nDATA.FRAME |&gt; arrange(VARIABLES)\nDATA.FRAME |&gt; distinct(VARIABLES)\nDATA.FRAME |&gt; select(VARIABLES)\nDATA.FRAME |&gt; rename(NEW_VARIABLE = EXISTING_VARIABLE)\nThe subsequent arguments describe what to do with the data.frame, mostly using the variable names.\nThe result is a data.frame."
  },
  {
    "objectID": "danl-cw/danl-101-cw-06.html#question-1",
    "href": "danl-cw/danl-101-cw-06.html#question-1",
    "title": "select() and rename()",
    "section": "Question 1",
    "text": "Question 1\nCreate a new data.frame, df that keeps only the following five variables‚ÄîFiscal_Year, Agency_Name, First_Name, Last_Name, and Base_Salary‚Äîfrom the data.frame nyc_payroll_new.\nAnswer:\nHere, we use the select() function from one of the packages in tidyverse to choose only the specified variables (Fiscal_Year, Agency_Name, First_Name, Last_Name, and Base_Salary) from the nyc_payroll_new data.frame. The result is assigned to a new data.frame name df containing only these variables, reducing the dataset for further analysis."
  },
  {
    "objectID": "danl-cw/danl-101-cw-06.html#question-2",
    "href": "danl-cw/danl-101-cw-06.html#question-2",
    "title": "select() and rename()",
    "section": "Question 2",
    "text": "Question 2\nGiven the data.frame df with a variable named Agency_Name, how would you rename it to Agency?\nAnswer:\nThe rename() function allows us to change the name of an existing variable. In this case, we rename the Agency_Name variable to Agency in the df data.frame. The result is a new data.frame, df_renamed, where Agency_Name is now simply Agency."
  },
  {
    "objectID": "danl-cw/danl-101-cw-06.html#question-3",
    "href": "danl-cw/danl-101-cw-06.html#question-3",
    "title": "select() and rename()",
    "section": "Question 3",
    "text": "Question 3\nHow would you remove the Fiscal_Year variable using select()?\nAnswer:\nTo remove a column from a data.frame, we use the select() function with the - sign before the variable name. In this case, select(-Fiscal_Year) removes the Fiscal_Year variable from the df data.frame, resulting in df_dropped, which contains all variables except Fiscal_Year."
  },
  {
    "objectID": "danl-cw/danl-101-cw-07.html",
    "href": "danl-cw/danl-101-cw-07.html",
    "title": "Quiz 1 - Addendum",
    "section": "",
    "text": "Descriptive Statistics\nThe following provides the percentage of the correct answers for each question in Quiz 1 - Addendum:\n\n\n\n\n\n\n\n\n\n\nQuestion 1. data.frame\nIn a data frame, what form does a variable take?\nAnswer: Column\n\nThis slide in Lecture 7 explains what makes a data.frame tidy. In our course, all given data.frames are tidy.\n\nIt‚Äôs been a while since we discussed variable-column, observation-row, and value-cell terminologies in a tidy data.frame, but these concepts are crucial for conducting data analysis.\n\nIn a data.frame:\n\nA variable takes a column\nAn observation takes a row\nA value takes a cell\n\n\n\n\n\nQuestion 2. left_join()\n\ndf_joined &lt;- df_1 |&gt; ___(df_2)\n\n\nFill in the blank (___) to join the two related data.frames, df_1 and df_2, in a way that keeps all observations and variables in the data.frame df_1.\n\nAnswer: left_join\n\ndf_joined &lt;- df_1 |&gt; left_join(df_2)\n\n\nThis slide in Lecture 14 and this slide in Lecture 12 explain join and left_join().\n\n\n\n\nQuestion 3. == (Equality operator)\n\ndf_filtered &lt;- df |&gt; filter(num __ 9) \n\n\nFill in the blank (___) to keep observations, in which the value of the num variable is equal to 9.\n\nAnswer: ==\n\ndf_filtered &lt;- df |&gt; filter(num == 9) \n\n\nThis slide and many examples from class R scripts explain this equality operator.\n\n\n\n\nQuestion 4. != (Not-equal operator)\n\nnon_dec &lt;- df |&gt; filter(month ___ 12)\n\n\nFill in the blank (___) to keep observations, in which the value of the month is not equal to 12 in the data.frame df\n\nAnswer: !=\n\nnon_dec &lt;- df |&gt; filter(month != 12)\n\n\nThis slide and Line 63-64 in this class R script in Lecture 14 explain a not-equal operator, != (not equal to).\n\n\n\n\nQuestion 5. | (Or operator)\n\ndf_filtered &lt;- df |&gt; filter(subject == \"DANL\" ___ subject == \"ECON\")\n\n\nFill in the blank (___) to keep observations, in which the value of the subject variable is either ‚ÄúDANL‚Äù or ‚ÄúECON‚Äù\n\nAnswer: |\n\ndf_filtered &lt;- df |&gt; filter(subject == \"DANL\" | subject == \"ECON\")\n\n\nThis slide and this slide in Lecture 14 explain logical operation, | (or).\nPlease note that | is not the letter ‚ÄúI‚Äù or ‚Äúl,‚Äù but a vertical bar character.\nOn a keyboard, | is located above the Enter/Return key.\n\n\n\n\nDiscussion\nWelcome to our Quiz 1 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Quiz 1.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Quiz 1 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02-a.html",
    "href": "danl-hw/danl-101-hw-02-a.html",
    "title": "Homework Assignment 2 - Example Answers",
    "section": "",
    "text": "The following provides the descriptive statistics for each part of the homework, as well as the final score of HW2:"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02-a.html#true-or-false",
    "href": "danl-hw/danl-101-hw-02-a.html#true-or-false",
    "title": "Homework Assignment 2 - Example Answers",
    "section": "True or False",
    "text": "True or False\n\nA data lake stores data in its raw, unaltered form and uses a schema-on-read approach. (True/False)\n\nAnswer: True\nExplanation: A data lake does store data in its raw, unaltered form. It employs a schema-on-read approach, meaning the data‚Äôs structure is interpreted when it is accessed, not when it is stored. This allows for flexibility in analyzing data in various ways without predefined schemas.\n\n\nApache Hadoop can natively process real-time streaming data without any extensions. (True/False)\n\nAnswer: False\nExplanation: Apache Hadoop is primarily designed for batch processing of large data sets. It does not natively support real-time streaming data processing. To handle streaming data, extensions like Apache Spark Streaming or Apache Storm are used alongside Hadoop.\n\n\nThe Extract, Transform, Load (ETL) process involves extracting data from multiple sources, transforming it into a suitable format, and loading it into a data warehouse. (True/False)\n\nAnswer: True\nExplanation: The ETL process stands for Extract, Transform, Load. It involves: ‚Ä¢ Extracting data from various sources. ‚Ä¢ Transforming the data into a suitable format, which includes cleaning and integrating data. ‚Ä¢ Loading the transformed data into a data warehouse for analysis.\n\n\nData marts are subsets of data warehouses that are focused on specific business areas or departments. (True/False)\n\nAnswer: True\nExplanation: A data mart is a focused subset of a data warehouse, tailored for the specific needs of a particular business area or department. This allows teams to access relevant data more efficiently without sifting through the entire data warehouse.\n\n\n‚ÄòStructured data‚Äô refers to data that is not organized in a predefined manner and comes from sources like social media, emails, and videos. (True/False)\n\nAnswer: False\nExplanation: Structured data is highly organized and formatted in a way so it‚Äôs easily searchable in relational databases (e.g., tables with rows and columns). Data from social media, emails, and videos are examples of unstructured data, which lacks a predefined data model."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02-a.html#multiple-choice",
    "href": "danl-hw/danl-101-hw-02-a.html#multiple-choice",
    "title": "Homework Assignment 2 - Example Answers",
    "section": "Multiple Choice",
    "text": "Multiple Choice\n\nWhich of the following is NOT one of the five key characteristics of big data (the 5 V‚Äôs)?\n‚Ä¢ Volume ‚Ä¢ Variety ‚Ä¢ Validity ‚Ä¢ Velocity\n\nAnswer: Validity\nExplanation: The traditional 5 V‚Äôs of big data are: 1. Volume: The amount of data. 2. Velocity: The speed of data processing. 3. Variety: The different types of data. 4. Veracity: The uncertainty of data. 5. Value: The usefulness of the data.\nValidity is not traditionally included in the 5 V‚Äôs of big data.\n\n\nIn the context of data types, temperature measured in degrees Fahrenheit is an example of:\n‚Ä¢ Nominal Data ‚Ä¢ Ordinal Data ‚Ä¢ Interval Data ‚Ä¢ Ratio Data\n\nAnswer: Interval Data\nExplanation: Interval data is numerical data where the intervals between values are meaningful, but there is no true zero point. Temperature in degrees Fahrenheit is interval data because zero degrees does not represent the absence of temperature, and differences between temperatures are consistent.\n\n\nWhich of the following best describes a ‚Äòdata mart‚Äô?\n‚Ä¢ A centralized repository for all data across an enterprise. ‚Ä¢ A subset of a data warehouse focused on a specific business line or team. ‚Ä¢ A collection of unstructured data stored in its raw form. ‚Ä¢ An open-source framework for distributed storage and processing of big data.\n\nAnswer: A subset of a data warehouse focused on a specific business line or team.\nExplanation: A data mart is a smaller, more focused version of a data warehouse, designed to meet the needs of a specific business line or team. It contains a subset of the organization‚Äôs data relevant to a particular group.\n\n\nWhich of the following is a challenge associated with big data privacy concerns?\n‚Ä¢ Difficulty in finding information due to information overload ‚Ä¢ Extensive profiling and user tracking without explicit consent ‚Ä¢ Legal penalties for non-compliance with regulations ‚Ä¢ Integration complexity of diverse data sources\n\nAnswer: Extensive profiling and user tracking without explicit consent\nExplanation: One of the major privacy concerns with big data is the potential for extensive profiling and user tracking without explicit consent, which can lead to misuse of personal information and breaches of privacy.\n\n\nWhat is the primary function of the ‚ÄòTransform‚Äô stage in the ETL process?\n‚Ä¢ Extracting data from various sources ‚Ä¢ Loading data into the data warehouse ‚Ä¢ Converting data into a suitable format for analysis ‚Ä¢ Deleting obsolete data\n\nAnswer: Converting data into a suitable format for analysis\nExplanation: The Transform stage involves cleaning, normalizing, and converting the extracted data into a format suitable for analysis and loading into the data warehouse. It ensures data consistency and quality."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02-a.html#short-essay",
    "href": "danl-hw/danl-101-hw-02-a.html#short-essay",
    "title": "Homework Assignment 2 - Example Answers",
    "section": "Short Essay",
    "text": "Short Essay\n\nExplain how Airbnb‚Äôs data management strategy, particularly the development of the Dataportal, contributed to its rapid growth.\n\nAnswer:\nAirbnb‚Äôs development of the Dataportal‚Äîa centralized data repository‚Äîwas pivotal to its rapid growth by democratizing data access across the organization; it enabled employees of all technical levels to make data-driven decisions without heavy reliance on data specialists, leading to improved efficiency, enhanced collaboration between departments, accelerated innovation through rapid testing and iteration, and scalability in handling increasing data volumes, all of which optimized decision-making and operations and significantly contributed to Airbnb‚Äôs swift expansion in a competitive market.\n\n\nDescribe the Extract, Transform, Load (ETL) process and explain its importance in populating data warehouses.\n\nAnswer:\nThe Extract, Transform, Load (ETL) process involves extracting data from various sources like databases or data files; transforming the data by cleaning and converting it to ensure consistency and reliability; and loading it into a data warehouse for efficient analysis; this process is crucial for populating data warehouses because it consolidates data from multiple sources into a unified view, enhances data quality through cleansing and standardization, increases efficiency by reducing errors, ensures timeliness by keeping data warehouses updated for real-time analytics, and offers scalability to handle growing data volumes, ultimately enabling accurate reporting and strategic decision-making.\n\n\nExplain how Hadoop enables the processing of large data sets and discuss the roles of HDFS and MapReduce in this framework.\n\nAnswer:\nHadoop enables the processing of large data sets by distributing storage and computation across clusters of computers; the Hadoop Distributed File System (HDFS) splits large files into blocks and distributes them across servers, offering scalability by adding more servers and providing fault tolerance through data replication, while MapReduce enables parallel data processing across the cluster by processing input into key-value pairs (filtering and sorting data) in the Map phase and aggregating results in the Reduce phase, enhancing computation speed and handling task failures; together, HDFS and MapReduce allow Hadoop to manage vast amounts of data through distributed storage and processing, process data where it is stored to improve speed, reduce costs by using commodity hardware, and easily expand capacity by adding servers, providing a scalable and efficient solution for storing and analyzing large data sets to gain valuable insights."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02-a.html#question-1",
    "href": "danl-hw/danl-101-hw-02-a.html#question-1",
    "title": "Homework Assignment 2 - Example Answers",
    "section": "Question 1",
    "text": "Question 1\nHow can you filter the data.frame nyc_payroll_new to calculate descriptive statistics (mean and standard deviation) of Base_Salary for workers in the Work_Location_Borough ‚ÄúMANHATTAN‚Äù? Similarly, how can you filter the data.frame nyc_payroll_new to calculate these statistics for workers in the Work_Location_Borough ‚ÄúQUEENS‚Äù?\nProvide the R code for performing these calculations and then report the mean and standard deviation of Base_Salary for workers in both ‚ÄúMANHATTAN‚Äù and ‚ÄúQUEENS‚Äù.\nAnswer:\n\n# Filter the dataset for records where the work location is MANHATTAN\ndf_manhattan &lt;- nyc_payroll_new |&gt; \n  filter(Work_Location_Borough == \"MANHATTAN\")\n\n# Generate descriptive statistics (including mean and standard deviation) for Base_Salary for workers in MANHATTAN\nskim(df_manhattan$Base_Salary) # or skim(df_manhattan)\n\n\nData summary\n\n\nName\ndf_manhattan$Base_Salary\n\n\nNumber of rows\n3271\n\n\nNumber of columns\n1\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndata\n0\n1\n42531.71\n44957\n1\n33.18\n37182\n80000\n221000\n‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ\n\n\n\n\n\n\n# Filter the dataset for records where the work location is QUEENS\ndf_queens &lt;- nyc_payroll_new |&gt; \n  filter(Work_Location_Borough == \"QUEENS\")\n\n# Generate descriptive statistics (including mean and standard deviation) for Base_Salary for workers in QUEENS\nskim(df_queens$Base_Salary) # or skim(df_queens)\n\n\nData summary\n\n\nName\ndf_queens$Base_Salary\n\n\nNumber of rows\n476\n\n\nNumber of columns\n1\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndata\n0\n1\n55289.07\n41187.32\n10.85\n32141\n54462.5\n85292\n221268\n‚ñá‚ñá‚ñÉ‚ñÅ‚ñÅ"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02-a.html#question-2",
    "href": "danl-hw/danl-101-hw-02-a.html#question-2",
    "title": "Homework Assignment 2 - Example Answers",
    "section": "Question 2",
    "text": "Question 2\nHow can you filter the data.frame nyc_payroll_new to show only the records where the Base_Salary is greater than or equal to $100,000?\nAnswer:\n\n# Filter the dataset for records where Base_Salary is greater than or equal to $100,000\nq2 &lt;- nyc_payroll_new |&gt; \n  filter(Base_Salary &gt;= 100000)"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02-a.html#question-3",
    "href": "danl-hw/danl-101-hw-02-a.html#question-3",
    "title": "Homework Assignment 2 - Example Answers",
    "section": "Question 3",
    "text": "Question 3\nHow can you select only distinct combinations of Agency_Name and Title_Description?\nAnswer:\n\n# Select distinct combinations of Agency_Name and Title_Description from the dataset\nq3 &lt;- nyc_payroll_new |&gt; \n  distinct(Agency_Name, Title_Description)"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02-a.html#question-4",
    "href": "danl-hw/danl-101-hw-02-a.html#question-4",
    "title": "Homework Assignment 2 - Example Answers",
    "section": "Question 4",
    "text": "Question 4\nHow would you arrange the data by Regular_Gross_Paid in descending order, showing the highest paid employees first?\nAnswer:\n\n# Arrange the dataset by Regular_Gross_Paid in descending order (highest paid employees first)\nq4 &lt;- nyc_payroll_new |&gt; \n  arrange(desc(Regular_Gross_Paid))"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02-a.html#question-5",
    "href": "danl-hw/danl-101-hw-02-a.html#question-5",
    "title": "Homework Assignment 2 - Example Answers",
    "section": "Question 5",
    "text": "Question 5\nHow can you select and rename the Title_Description variable to Title?\nAnswer:\n\n# Rename the Title_Description variable to Title in the dataset\nq5 &lt;- nyc_payroll_new |&gt; \n  rename(Title = Title_Description)"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02-a.html#question-6",
    "href": "danl-hw/danl-101-hw-02-a.html#question-6",
    "title": "Homework Assignment 2 - Example Answers",
    "section": "Question 6",
    "text": "Question 6\nHow can you filter the data to show only records for the ‚ÄúPOLICE DEPARTMENT‚Äù Agency_Name and arrange it by Total_OT_Paid in ascending order?\nAnswer:\n\n# Filter the dataset for records where Agency_Name is \"POLICE DEPARTMENT\" and arrange by Total_OT_Paid in ascending order\nq6 &lt;- nyc_payroll_new |&gt; \n  filter(Agency_Name == \"POLICE DEPARTMENT\") |&gt; \n  arrange(Total_OT_Paid)"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02-a.html#question-7",
    "href": "danl-hw/danl-101-hw-02-a.html#question-7",
    "title": "Homework Assignment 2 - Example Answers",
    "section": "Question 7",
    "text": "Question 7\nHow can you filter the data to include only those records where the Pay_Basis is ‚Äúper Annum‚Äù and then select only the First_Name, Last_Name, and Base_Salary variables?\nAnswer:\n\n# Filter the dataset for records where Pay_Basis is \"per Annum\" and select specific columns: First_Name, Last_Name, and Base_Salary\nq7 &lt;- nyc_payroll_new |&gt; \n  filter(Pay_Basis == \"per Annum\") |&gt; \n  select(First_Name, Last_Name, Base_Salary)"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02-a.html#question-8",
    "href": "danl-hw/danl-101-hw-02-a.html#question-8",
    "title": "Homework Assignment 2 - Example Answers",
    "section": "Question 8",
    "text": "Question 8\nHow would you arrange the data.frame by Work_Location_Borough in ascending order and Base_Salary in descending order?\nAnswer:\n\n# Arrange the dataset by Work_Location_Borough in ascending order and Base_Salary in descending order\nq8 &lt;- nyc_payroll_new |&gt; \n  arrange(Work_Location_Borough, -Base_Salary)\n\n\n\n\n\n\n\n\n\nNote that sorting observations by a character variable in ascending order means sorting them in an alphabetical order.\nNote that sorting observations by a character variable in descending order means sorting them in a reverse-alphabetical order."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02-a.html#question-9",
    "href": "danl-hw/danl-101-hw-02-a.html#question-9",
    "title": "Homework Assignment 2 - Example Answers",
    "section": "Question 9",
    "text": "Question 9\nHow can you filter the nyc_payroll_new data.frame to remove observations where the Base_Salary variable has NA values? After filtering, how would you calculate the total number of remaining observations?\nAnswer:\n\n# Filter the dataset to remove observations where Base_Salary is NA\nq9 &lt;- nyc_payroll_new |&gt; \n  filter(!is.na(Base_Salary))\n\n# Calculate the total number of remaining observations after filtering\nnrow(q9)\n\n[1] 5000"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prize-in-physics-and-chemistry-in-2024",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prize-in-physics-and-chemistry-in-2024",
    "title": "Lecture 17",
    "section": "Nobel Prize in Physics and Chemistry in 2024",
    "text": "Nobel Prize in Physics and Chemistry in 2024\nThe Royal Swedish Academy of Sciences has decided to award the 2024 Nobel Prize in Physics to U.S. scientist John J. Hopfield and British-Canadian Geoffrey E. Hinton for discoveries and inventions in ____________________, a field that enables computers to learn from and make predictions or decisions based on data, which paved the way for the artificial intelligence boom."
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prize-in-physics-and-chemistry-in-2024-1",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prize-in-physics-and-chemistry-in-2024-1",
    "title": "Lecture 17",
    "section": "Nobel Prize in Physics and Chemistry in 2024",
    "text": "Nobel Prize in Physics and Chemistry in 2024"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prizes-laying-the-foundations-for-ml",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prizes-laying-the-foundations-for-ml",
    "title": "Lecture 17",
    "section": "2024 Nobel Prizes: Laying the Foundations for ML",
    "text": "2024 Nobel Prizes: Laying the Foundations for ML\nThe Breakthroughs Behind AI‚Äôs Modern Revolution\n\n\nRecognizes groundbreaking contributions to ML and AI\n\nHopfield and Hinton: Deep learning and neural network architecture\nHassabis and Jumper: AI and protein folding breakthroughs\n\nWhy It Matters: These discoveries laid the foundation for the ML revolution we are living through today"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prizes-laying-the-foundations-for-ml-1",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prizes-laying-the-foundations-for-ml-1",
    "title": "Lecture 17",
    "section": "2024 Nobel Prizes: Laying the Foundations for ML",
    "text": "2024 Nobel Prizes: Laying the Foundations for ML\nDeep Learning\n\n\nGeoffrey Hinton‚Äôs Innovations:\n\nDeveloped backpropagation, a key algorithm for training deep neural networks\n\nDeep learning: Multi-layered networks that autonomously learn complex patterns\nImpact on AI:\n\nEnabled machines to learn from data without explicit instructions\nCore technology behind language models (like ChatGPT), image recognition, and more"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prizes-laying-the-foundations-for-ml-2",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prizes-laying-the-foundations-for-ml-2",
    "title": "Lecture 17",
    "section": "2024 Nobel Prizes: Laying the Foundations for ML",
    "text": "2024 Nobel Prizes: Laying the Foundations for ML\nML Today\n\n\nThe Scale of Modern AI:\n\nDeep neural networks now contain billions to trillions of parameters\nHugging Face: Open-source community for ML and AI\n\nApplications: Voice assistants, self-driving cars, medical diagnostics, and so on.\nImportance of Data and Computing Power:\n\nThe explosion in data and cloud computing has fueled rapid progress in AI\nAI models like GPT-4 are direct descendants of Hopfield and Hinton‚Äôs early work"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prizes-laying-the-foundations-for-ml-3",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prizes-laying-the-foundations-for-ml-3",
    "title": "Lecture 17",
    "section": "2024 Nobel Prizes: Laying the Foundations for ML",
    "text": "2024 Nobel Prizes: Laying the Foundations for ML\nDemis Hassabis‚Äôs Story: From Chess to AI Mastery\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBoardgame Master Enters the Protein Olympics:\nEarly Life:\n\nStarted playing chess at age 4, achieved master level at 13\nTransitioned to programming and video game development as a teenager"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prizes-laying-the-foundations-for-ml-4",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prizes-laying-the-foundations-for-ml-4",
    "title": "Lecture 17",
    "section": "2024 Nobel Prizes: Laying the Foundations for ML",
    "text": "2024 Nobel Prizes: Laying the Foundations for ML\nDemis Hassabis‚Äôs Story: From Chess to AI Mastery\n\n\n\n\n\n\n\n\n\n\nCo-founded DeepMind in 2010, a company that revolutionized AI for boardgames\nDeepMind‚Äôs Global Attention:\n\nSold to Google in 2014\nIn 2016, DeepMind‚Äôs AI defeated the world champion of Go, a breakthrough in AI‚Äôs problem-solving abilities"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prizes-laying-the-foundations-for-ml-5",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prizes-laying-the-foundations-for-ml-5",
    "title": "Lecture 17",
    "section": "2024 Nobel Prizes: Laying the Foundations for ML",
    "text": "2024 Nobel Prizes: Laying the Foundations for ML\nDemis Hassabis‚Äôs Story: From Chess to AI Mastery\n\n\n\n\n\n\n\n\n\nAI‚Äôs True Purpose for Hassabis:\n\nGames were just a stepping stone to developing AI for more meaningful applications, like predicting protein structures"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prizes-laying-the-foundations-for-ml-6",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#nobel-prizes-laying-the-foundations-for-ml-6",
    "title": "Lecture 17",
    "section": "2024 Nobel Prizes: Laying the Foundations for ML",
    "text": "2024 Nobel Prizes: Laying the Foundations for ML\nThe Future of Machine Learning\n\n\nWhat‚Äôs Next?:\n\nAI is rapidly evolving, expanding into areas like business, economics, climate science, healthcare, personalized medicine, and so on.\nChallenges include transparency, ethics, and responsible AI development\n\nEthical Considerations:\n\nHow do we ensure AI benefits humanity and minimizes harm?\n\nFinal Thoughts:\n\nAs AI continues to grow, it holds the potential to solve many of humanity‚Äôs greatest challenges"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#questions-6-8",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#questions-6-8",
    "title": "Lecture 17",
    "section": "Questions 6-8",
    "text": "Questions 6-8\nFor Questions 6-8, consider the following data.frame, twitter_data, displayed below:"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-6",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-6",
    "title": "Lecture 17",
    "section": "Question 6",
    "text": "Question 6\nWhat type of variable is Country in the dataset?\n\nNominal\nOrdinal\nInterval\nRatio\n\nCountry: Country of residence"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-7",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-7",
    "title": "Lecture 17",
    "section": "Question 7",
    "text": "Question 7\nWhat type of variable is LastLoginHour in the dataset?\n\nNominal\nOrdinal\nInterval\nRatio\n\nLastLoginHour: Time of last login in hours since midnight"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-8",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-8",
    "title": "Lecture 17",
    "section": "Question 8",
    "text": "Question 8\nWhat type of variable is SatisfactionLevel in the dataset?\n\nNominal\nOrdinal\nInterval\nRatio\n\nSatisfactionLevel: User satisfaction level"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-14",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-14",
    "title": "Lecture 17",
    "section": "Question 14",
    "text": "Question 14\nWhich of the following R code correctly assigns the data.frame nycflights13::airlines to the variable airlines_df? (Note that airlines_df is simply the name of the R object and can be any valid name in R.)\n\nnycflights13::airlines &lt;- airlines_df\nairlines_df &lt;- nycflights13::airlines\nnycflights13::airlines &gt;= airlines_df\nairlines_df == nycflights13::airlines\nAll of the above"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-15",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-15",
    "title": "Lecture 17",
    "section": "Question 15",
    "text": "Question 15\nWrite the R code to create a new variable called total and assign to it the sum of 8 and 12 in R.\nAnswer: ______________________________________________"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-16",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-16",
    "title": "Lecture 17",
    "section": "Question 16",
    "text": "Question 16\nGiven the data.frame df with variables height and name, which of the following expressions returns a vector containing the values in the height variable?\n\ndf:height\ndf::height\ndf$height\nBoth b and c"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-17",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-17",
    "title": "Lecture 17",
    "section": "Question 17",
    "text": "Question 17\nThe expression as.numeric(\"456\") will return the numeric value 456.\n\nTrue\nFalse"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-18",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-18",
    "title": "Lecture 17",
    "section": "Question 18",
    "text": "Question 18\nWhat is the result of the expression (1 + 2 * 3) ^ 2 in R?\n\n36\n49\n81"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-19",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-19",
    "title": "Lecture 17",
    "section": "Question 19",
    "text": "Question 19\nGiven vectors a &lt;- c(2, 4, 6) and b &lt;- c(1, 3, 5), what is the result of a + b?\n\nc(3, 7, 11)\nc(2, 4, 6, 1, 3, 5)\nc(1, 2, 3, 4, 5, 6)\nError"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-20",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-20",
    "title": "Lecture 17",
    "section": "Question 20",
    "text": "Question 20\nTo use the function read_csv() from the readr package, one of the packages in tidyverse, you first need to load the package using the R code ________.\n\nlibrary(readr)\nlibrary(skimr)\nlibrary(tidyverse)\nAll of the above\nBoth a and c\nBoth b and c\nBoth a and c"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-21",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-21",
    "title": "Lecture 17",
    "section": "Question 21",
    "text": "Question 21\nConsider the following data.frame df0:\n\n\n\n\n\nx\ny\n\n\n\n\nNa\n7\n\n\n2\nNA\n\n\n3\n9\n\n\n\n\n\nWhat is the result of mean(df0$y)?\n\n7\nNA\n8\n9"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#questions-22-23",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#questions-22-23",
    "title": "Lecture 17",
    "section": "Questions 22-23",
    "text": "Questions 22-23\nConsider the following data.frame df for Questions 22-23:\n\n\n\n\n\nid\nname\nage\nscore\n\n\n\n\n1\nAnna\n22\n90\n\n\n2\nBen\n28\n85\n\n\n3\nCarl\nNA\n95\n\n\n4\nDana\n35\nNA\n\n\n5\nElla\n40\n80"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-22",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-22",
    "title": "Lecture 17",
    "section": "Question 22",
    "text": "Question 22\nWhich of the following code snippets filters observations where score is strictly between 85 and 95 (i.e., excluding 85 and 95)?\n\ndf |&gt; filter(score &gt;= 85 | score &lt;= 95)\ndf |&gt; filter(score &gt; 85 | score &lt; 95)\ndf |&gt; filter(score &gt; 85 & score &lt; 95)\ndf |&gt; filter(score &gt;= 85 & score &lt;= 95)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-23",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-23",
    "title": "Lecture 17",
    "section": "Question 23",
    "text": "Question 23\nWhich of the following expressions correctly keeps observations from df where the age variable does not have any missing values?\n\ndf |&gt; filter(is.na(age))\ndf |&gt; filter(!is.na(age))\ndf |&gt; filter(age == NA)\ndf |&gt; filter(age != NA)\nBoth a and c\nBoth b and d"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-24",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-24",
    "title": "Lecture 17",
    "section": "Question 24",
    "text": "Question 24\nConsider the following data.frame df3:\n\n\n\n\n\nid\nvalue\n\n\n\n\n1\n15\n\n\n1\n15\n\n\n2\n25\n\n\n3\n35\n\n\n3\n35\n\n\n4\n45\n\n\n5\n55\n\n\n\n\n\nWhich of the following code snippets returns a data.frame of unique id values from df3?\n\ndf3 |&gt; select(id) |&gt; distinct()\ndf3 |&gt; distinct(value)\ndf3 |&gt; distinct(id)\nBoth a and c"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-25",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-25",
    "title": "Lecture 17",
    "section": "Question 25",
    "text": "Question 25\nWhich of the following code snippets correctly renames the variable name to first_name in df?\n\ndf |&gt; rename(first_name = name)\ndf |&gt; rename(name = first_name)\ndf |&gt; rename(\"name\" = \"first_name\")\ndf |&gt; rename_variable(name = first_name)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-26",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-26",
    "title": "Lecture 17",
    "section": "Question 26",
    "text": "Question 26\nWhich of the following code snippets correctly removes the score variable from df?\n\ndf |&gt; select(-score)\ndf |&gt; select(-\"score\")\ndf |&gt; select(!score)\ndf |&gt; select(, -score)\ndf |&gt; select(desc(score))"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-27",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-27",
    "title": "Lecture 17",
    "section": "Question 27",
    "text": "Question 27\nWhich of the following code snippets filters observations where age is not NA, then arranges them in ascending order of age, and then selects the name and age variables?\n\ndf |&gt; filter(!is.na(age)) |&gt; arrange(age) |&gt; select(name, age)\ndf |&gt; select(name, age) |&gt; arrange(age) |&gt; filter(!is.na(age))\ndf |&gt; arrange(age) |&gt; filter(!is.na(age)) |&gt; select(name, age)\ndf |&gt; filter(is.na(age)) |&gt; arrange(desc(age)) |&gt; select(name, age)\nAll of the above"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-28",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-28",
    "title": "Lecture 17",
    "section": "Question 28",
    "text": "Question 28\nConsider the two related data.frames, students and majors:\n\n\n\ndf_1\n\n\n\n\n\n\nstudent_id\nname\nage\n\n\n\n\n1\nBrad\n20\n\n\n2\nJason\n22\n\n\n4\nMarcie\n21\n\n\n\n\n\n\n\ndf_2\n\n\n\n\n\n\nstudent_id\nmajor\n\n\n\n\n1\nBusiness Administration\n\n\n2\nEconomics\n\n\n3\nData Analytics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstudent_id\nmajor\nname\nage\n\n\n\n\n1\nBusiness Administration\nBrad\n20\n\n\n2\nEconomics\nJason\n22\n\n\n3\nData Analytics\nNA\nNA\n\n\n\n\n\n\n\n\n\n\nstudents |&gt; left_join(majors)\nmajors |&gt; left_join(students)\nBoth a and b"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-29",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-29",
    "title": "Lecture 17",
    "section": "Question 29",
    "text": "Question 29\nIn R, what does the function sd(x) compute, and why can it be more useful than var(x)?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-17-2024-1011.html#question-30",
    "href": "danl-lec/danl-101-lec-17-2024-1011.html#question-30",
    "title": "Lecture 17",
    "section": "Question 30",
    "text": "Question 30\nList at least four applications of data analytics in sports analytics mentioned in the lecture, and briefly describe each one."
  }
]